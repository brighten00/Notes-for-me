# 背不起來
* redundant 多餘的

# is-a (是一種)

# 待分類
* DNS load-blance
* CDN應用

# KIND(全名是 Kubernetes In Docker)
顧名思義就是把 Kubernetes 的節點都用 Docker 的方式叫起來運行，
每一個 Docker Container 就是一個 Kubernetes 節點，可以充當 Worker 也可以充當 Master.
使用方面非常簡單，使用 KIND 的指令搭配一個設定檔案就可以輕鬆地建立起 Kubernetes 叢集

# K3D
K3D 是由 Rancher 所開發 K3S 的 Docker 版本， 
而 K3D 直接將 K3S 給移植到 Docker 之中，讓使用者可以更方便的創建一個 K3S 叢集

# universal 
* universal control panel
* universal cluster agent
* universal workflow
* universal MQ
* universal storage

# Adaptor筆記目標
* Misc大雜燴=>語法倉儲 == 基本語法, 獨特處code倉儲
* 語言 == 語法倉儲, intergate
* db == 語法倉儲, 運作原理, 可靠性
* intergrate == 生態 + pkgManager + 編譯安裝

# 搜尋能力
* awesome找生態
* open source (oss)
* gnu
* Swiss Army knife
* hub 找社群,代管
* online 找服務
* one line系列(待發掘正確名稱,通常就是bash方案,非固化需求)

# `Swiss Army Knife` terminal tool
* `ffmpeg`影像 [好棒棒的GUI](https://github.com/mifi/lossless-cut)
* `m-cli`mac [link](https://github.com/rgcr/m-cli)
* `sox`聲音
* `nc`網路

# Turnkey
一站式方案，是一種專案類型，指的是賣方將專案架設好並調整完成，  
在`可立即使用`的情況下賣給買家，是科技業中一種常見的技術轉移方式

# 思想
* 原始的行為 && 賦予的意義
* 邏輯上的距離
* 搞清楚`誰驅動誰`, 否則只是見樹不見林(依賴倒置)
* 邏輯上的接觸不良
* 固化需求 <--> 非固化需求 tradeOff
* 有時`觀念`轉不過來的`廢話`
* 多對多思維
* 反直覺 && 預期性 (反指標驅動)
* 用反直覺,對付該`群`的直覺,但又`不造成sideEffect`的心法
* 取得信任=>大家都知道,你居然不知道(拿??事騙他)
* 脫離在一隻腳已經入坑內的方式(有沒有第三種方式)
* explore == `regression` then find `anti-intuition`
* `分離關注點` then `多對多`
* 學語言學現代 ex:現代java pdf
* 取捨tradeOff 對應情境
* 各Tier之間其實就是 `晚出現的` Adapt `早出現的` (待思考)
* 什麼教育訓練該買? 教育訓練 == 大家都知道,就你不知道的transform
* 厲害的人不是你做了什麼, 是你讓人家覺得你做了什麼
* 現實生活`事`,`物`,`人`在`漏斗`的哪一階段
* 用程式輔助`達成規範`, 而不是限制
* 交付文件學技術

# 固化需求 <--> 非固化需求
* 前者domain驅動
* 後者筆記驅動
* 感覺越新的技術,越是為了滿足非固化需求
* `產品`重型框架(http) => `task`輕型框架(stdio,http) => `雜事`腳本(stdio)
* 深公司 => 固化需求, 廣公司 => 非固化需求

# 有時`觀念`轉不過來的`廢話`
* 2進制 跟 存放在記憶體 是兩回事

# 邏輯上的接觸不良
* 機械的東西故障原因90%都是`接觸不良`,程式就是`邏輯上的接觸不良`
* 缺少env變數,檔案存在,型別錯誤,namespace遺失,權限錯誤,父不存在就對子操作

# 多對多思維
* 網路 Relation: linux bridge(interface) <==> 網段[ip區間] <==> ip <==> port <==>  process 這幾者的關係
* 銷售技巧 <==> 顧客
* 職位[SRE,HA] <==> 軟體Layer[Infra,Storage,Monitor]

# 專業一點的命名(~~強迫症~~)
* Tier 層級
* Anchors 錨點
* Manifest 清單
* Archive 封存
* Audit 審計
* Boilerplate 樣板
* Artifacts 所有軟體開發過程中的有形產物都可以叫artifact
* Audit 審計
* Topology 拓墣
* Utils 常用的
* Miscellaneous 雜項
* Criteria 準則
* Individual 個人
* Modernization 現代化
* XXXXXlet(小的xxxx) ex:servlet, cmdlet ,kubelet
* Verbose 冗長的  ex:verbose = 0，在stdio没有任何输出

# 常用英文(~~雞掰話~~)
* Trade-Off 權衡,平衡,取捨
* FollowUp 跟進
* Think out loud 把自己內心所想的直接講出來的意思
* Baseline 基準線
* RoadMap 技術路線
* is-a (是一種)
* SideEffect 副作用
* POC 概念性驗證
* ConCall 視訊會議
* TechOutlook 技術展望
* Briefing 簡報
* resentation 介紹
* offload 卸載
* [github-slang](https://p3t.lu/posts/github-slang/)
* latency延遲,潛在
* Porting 移植

# 特殊文件
* JD 招攬啟示上的描述(面試)
* [RFI(甲方招商資訊收集)/RFP(甲方招商規格)](https://leohu4901.pixnet.net/blog/post/96502694)
* Proposal提案,需求(通常是乙方建議作法)
* SOW 商務簽合約的依據規格,工作內容描述,工作說明書(or 當日進度,在職負責)
* WBS (執行細節,時程畫押)
* WIP 在製品。指的是正在加工，尚未完成的產品
* 系統架構圖

# 各種合約
* SLA:未達服務品質就要`賠償`
* MA:維護合約(往往須按當初產品成交價(註：部分廠商則要求以List Price計算)的12%、15%、甚至20%的比例為基準
 
# 系統級命名
* CMDB:組態管理工具(通常是實作itil的核心)
* SDLC:版控,票務,repo 這些個人覺得都算這類系統
* RTDM:Real-Time Data Monitoring Software
* LIMS:實驗室資訊管理系統

# 規範,共識
* ITIL:資訊業的管理規範(也驅動了所有 內控 設計,有些會計事務所負責導入thisTO企業)
* XDG:fs規範，用來指定文件和文件格式，文件位置
* IANA:port使用共識
* OOCSS:CSS的規範,減少對 HTML 結構的依賴 ,增加 CSS class 重複性的使用 . 
* CRISP-DM(Data Mining LifeCycle): 把數據挖掘實踐定義為6個標準階段，分別是`商業理解`、`數據理解`、`數據準備`、`建立模型`、`模型評估`和`模型發佈`
* Ansible Collection:[感覺是ansible目錄底下的規範, alaxy上應該都是吃這個規範](https://xdays.me/ansible%E6%95%99%E7%A8%8B%E4%B9%8Bcollection/)
* J2EE
* PEP 8: py的
* PSR:php規範
* JSR:j系列規範
* XA規範: 分布式事務處理 (DTP)的規範
* [CommonJS:模塊規範](https://javascript.ruanyifeng.com/nodejs/module.html)
* [DBA命名](https://codertw.com/%E4%BC%BA%E6%9C%8D%E5%99%A8/172938/)

# 這叫做什麼????
* bpm(eventWorkFlow/eventListen/eventEmit) <===> Trigger/Action <===> 推播(出)/蒐集(入) <===> Agent(Client) # 感覺很多軟硬整合的東西應該都是基於這個架構, 甚至所有大型軟體都是如此, 還是這就是標準`專家系統架構`???
* printLog + writeLog 這兩個動作結合的命名叫做啥(write IO???)

# 孵化器（Incubator）/加速器（Accelerator）
* 商業加速器
* 專案孵化器

# 最大型開源[(沙箱Sandbox > 孵化Incubating > 畢業Graduated > Acquisition被收購???)](https://www.oschina.net/news/99567/cncf-graduation-criteria-v1-1)
* Apache 頂級開源項目
* Linux 社區
* OpenStack
* CNCF

![](https://github.com/zero85258/MyNOTE/blob/master/img/company-life-cycle.png)

* ICO(首次代幣發行，早期透過網站登入註冊) vs IEO(首次交易所發行，意即透過交易所代為發售) vs STO(證券型代幣發行，可視為受政府監管)

# 套件風格 MONOREPO VS MULTIREPO
* multirepo 我的理解是 `一包一包Component`(小東西適合)
* monorepo 我的理解是 `就是集中管理`(大東西適合)

# CE（Community Edition）社區版 和 EE（Enterprise Edition）企業版
* 通常`前者免費`,`後者付費`

# fork(衍生、分支)
* 發生在當開發人員從一個軟體包拷貝了一份原始碼然後在其上進行獨立的開發，建立不同的軟體。
這個術語不只意味著版本控制上的分支

# headless software
* 是能夠在沒有圖形用戶界面的設備上工作的軟件

# jobQueue 的 channel(胡思亂想)
* `使用上`可以想像成 異步編程的`變數`
* 一但`變數channel`改變, 就做對應的事情(本質就是pub/sub)

# 模組化(胡思亂想)
* Framework == mesh型 + wheel型
* plugin, lib, module

# 執行檔(胡思亂想)
* 其實就是 `程式邏輯` + `程式資料` 每一時間點的`0跟1`的疊加態

# rsync , scp(胡思亂想)
* rsync 其實就是 scp的疊加態

# 函數遞迴 與 電路回授(胡思亂想)
* 感覺都是需要收斂

# 基底 + 權重 == 就可以描述這世界 (胡思亂想)

# 監聽
* 所謂的`監聽`是某個service程式會一直常駐在記憶體當中
```sh
# nc傳檔,串流,聊天,遠端執行 通通可實現
nc -l 5000 > my.jpg # 監聽接收
nc hostB.com 5000 < my.jpg # 發送
```

# 序列化serialization
* 就是把某個存在於`記憶體中的資料`(`對象`)狀態保存下來(`可傳輸的字節序列`)的動作
* 是指將資料結構或物件狀態轉換成可取用格式（例如存成檔案，存於緩衝，或經由網路中傳送

# 掛起 
* 是指在OS行程管理將`前台的process暫停`並`轉入後台`的動作

# L10n：Localization && I18n：Internationalization 
* 文件/軟體翻譯
* 專案本身的語言拓展到各國語言就稱為 I18n，對於貢獻者將專案翻譯成本土語言就稱為 L10n。
* [Crowdin](https://crowdin.com/)

# upstream(上游)
###### 在軟體開發中，upstream通常是指擁有軟體原始碼的`原作者`或是`維護者`，他們通常也較容易發現程式錯誤及使用Patch程式來修復。
###### 舉例來說，一個修補程式被送到上游即為提供給軟體的原作者或是維護者。
```
if 被接受了
	作者或維護者就會包含該部份的修補程式到他們軟體中，可能是立即釋出或包含在未來的版本中。
else 被拒絕了
	提交修補程式的人就不得不繼續維護自他們自己的版本。
	
upstream 開發將會使其他fork版本在未來的釋出中受益
```
這個詞也涉及到程式錯誤
最終所有程式錯誤仍需由`上游修復`而不是由其他衍生版本進行移植及整合。(應該先修掉地基)

# 串流stream && 管道pipe
* stream 對所有類文件系統操作的相關的功能進行抽象
* stdin/out/err，文件fopen等等...的操作，網絡上的數據流，字符串流，對象流，zip文件流等...都是io操作
* 流的作用是在出發地和目的地之間傳輸數據。
```php
$出發地and目的地可以 = [
	'文件',
	'命令行process',
	'網絡連接',
	'ZIP壓縮文件',
	'TAR壓縮文件',
	'臨時內存',
	'stdin/out',
	'通過PHP流封裝協議實現的任何其他資源'
]   
```
我們可以把流比作`管道pipe`，把水（資源數據）從一個地方引到另一個地方。  
在水從出發地到目的地的過程中，我們可以過濾水，可以改變水質，可以添加水，也可以排出水。  
個人理解是 php,node,等....在此概念上是差不多的

```
如果你讀寫過文件，就用過流; (stdin/out/err本身就屬於stream)
如果你從php://stdin讀取過數據，或者把輸入寫入php://stdout，也用過流。
流為PHP的很多IO函數提供了 底層實現，
如file_get_contents，fopn，fread和fwrite等.PHP的流函數提供了不同資源的統一接口。
```

# [I/O model](https://medium.com/@clu1022/%E6%B7%BA%E8%AB%87i-o-model-32da09c619e6)
### 基本I/O事件包含2階段 
* 等待data
* data從`KernelSpace` copyTo `UserSpace`(通常說的process/thread都在這側). 
### model種類
* `Blocking I/O`: App從發出systemCall 一路等到 data從KernelSpace copyTo UserSpace. 
* `Non-Blocking I/O`:App在等待資料時，App不斷地`poll輪詢`kernal，if資料還沒好就先走人，直到資料可讀後，data從KernelSpace copyTo UserSpace  
* `Asynchronize I/O`:App發出systemCall後就閃人，等到 kernel複製data到user space 後 系統將data直接送回request程序中 . 

所以Non-blocking和Asynchronize是不一樣的I/O Model!

`Synchronous I/O`: 包含了`blocking I/O`, `nonblocking I/O`, `I/O multiplexing(selector)`, `signal-driven I/O`
`Asynchronous I/O`: 就是`asynchronous I/O`, 但它跟nonblocking還是差很多的
### 場景
* Java BIO ： 同步並阻塞，服務器實現模式為一個連接一個線程，即客戶端有連接請求時服務器端就需要啟動一個線程進行處理，如果這個連接不做任何事情會造成不必要的線程開銷，當然可以通過線程池機制改善。
* Java NIO ： 同步非阻塞，服務器實現模式為一個請求一個線程，即客戶端發送的連接請求都會註冊到多路復用器上，多路復用器輪詢到連接有I/O請求時才啟動一個線程進行處理。
* Java AIO(NIO.2) ： 異步非阻塞，服務器實現模式為一個有效請求一個線程，客戶端的I/O請求都是由OS先完成了再通知服務器應用去啟動線程進行處理。

# I/O
* [i/o概念](https://www.jianshu.com/p/b74a83e0f9fc)

```sh
輸入輸出是相對的，要考慮具體的對像是什麼。
一般，當我們寫的程序需要讀取磁盤文件時，相當於把磁盤的數據輸入到程序中，
對於程序來說，讀取的數據就屬於Input，
但是對於磁盤來說，相當於把數據輸出給程序，輸出的數據屬於Output。

程序完成IO操作會有Input和Output兩個數據流。
當然也有隻用一個的情況，
比如，從磁盤讀取文件到內存，就只有Input操作，
反過來，把數據寫到磁盤文件裡，就只是一個Output操作。

# py
StringIO就是在內存中讀寫str
BytesIO實現了在內存中讀寫bytes(就是操作二進制數據)
```

# [Context Manager上下文管理器 With (感覺跟io編程有關)](https://blog.gtwang.org/programming/python-with-context-manager-tutorial/)

# `sync同步`,`async非同步`,`blocking阻塞`,`non-blocking非阻塞`,`Concurrent併發`,`Parallelis並行`
[link](https://tw.saowen.com/a/ee53cd13f1a8fac04b5ae00cf31eaa2c1789748f5e9e3d2c95b49e4406552f64)

* sync同步: 一件事情解決,有結果,才能做下一件
* async非同步: 先讓事情進行,不等結果,就可以做下一件 (Goroutine就是這樣先做,再去chan收割結果)
* blocking阻塞: 呼叫結果返回之前，當前thread會被掛起。呼叫執行緒只有在得到結果之後才會返回
* non-blocking非阻塞: 指在不能立刻得到結果之前，該呼叫不會阻塞當前執行緒。
* Concurrent併發: cpu*1 只是來回切換很快
* Parallelism並行: cpu*N 名副其實的同時進行
###### 也就是說，
* `同步/非同步`則是在wait“事情完成訊息”通知過程中的狀態（能不能幹其他任務），
* `阻塞/非阻塞`是“事情完成訊息”通知的方式（機制），
* 在不同的場景下，同步/非同步、阻塞/非阻塞的四種組合都有應用。

# `異步IO`,`同步IO`
是計算機OS對輸入輸出的處理方式：
* `異步IO` : 發起IO請求的 `process/thread` 不等IO操作完成，就繼續執行隨後的代碼，IO結果用其他方式通知發起IO請求的程序。
* `同步IO` : 發起IO請求的 `process/thread` 不從 `正在調用的IO操作函數`返回（即被阻塞），直至IO操作完成。
```sh
由於CPU和Ram的速度遠遠高於外設的速度，所以，在IO編程中，就存在速度嚴重不匹配的問題。
舉個例子來說，比如要把100M的數據寫入disk，
CPU輸出100M的數據只需要0.01秒，
可是disk要接收這100M數據可能需要10秒，
怎麼辦呢？有兩種辦法：

第一種是CPU等著，也就是程序暫停執行後續代碼，
等100M的data在10秒後寫入disk，再接著往下執行，這種模式稱為同步IO。
另一種方法是CPU不等待，只是告訴disk，“您老慢慢寫，不著急，我接著幹別的事去了”，於是，後續代碼可以立刻接著執行，這種模式稱為異步IO
```

# [System Call](https://ithelp.ithome.com.tw/users/20103524/ironman/1086)
* 指運行在`使用者空間user space`的`程式`向OS `核心空間kernal space`請求需要更高權限運行的服務(感覺就是api)
* (有點像app process對kernal call request)
* [list](http://man7.org/linux/man-pages/man2/syscalls.2.html)

# [Kernal Space](https://ithelp.ithome.com.tw/users/20001007/ironman/958?page=1)

# [select，poll，epoll (SystemCall, IO多路復用的機制)](https://www.cnblogs.com/anker/p/3265058.html)
* 這得益於Nginx使用了最新的epoll（Linux 2.6內核）和kqueue（freebsd,Mac）網絡I/O模型，單次請求得到響應更快，高峰情況下，比其他web服務器如Apache更快響應請求。
* 而Apache則使用的是傳統的select模型。而在高並發服務器中，輪詢I/O是非常耗時間的操作。
* Linux下的epoll和Mac里的kqueue

# parallelism平行化
```sh
# data parallelism 
就是把迴圈平行化、分成好幾個 thread（執行序）來同時進行計算；
每個 thread 的所做的事情其實都是相同的，只有計算的資料不同而已

# task parallelism
可能會是想要讓幾個很複雜、而且`不相同`的計算同時進行
```

# 併發差異
* Erlang和Scale 他的並發模型是`Actor模型`， 
* Golang是`CSP模型(communicating sequential process)`，他倆都是差不多的數學模型
* NodeJS 處理並發是`Reactor模式`，是一種事件驅動型非阻塞IO框架，
* Ruby的Goliath框架也是使用這種Reactor模式，也能處理高並發，具體可以可以研究下eventmachine。

# Future Pattern (多thread pattern)
* 先給你這張`取貨單`
![](https://github.com/zero85258/MyNOTE/blob/master/img/future1.png)
![](https://github.com/zero85258/MyNOTE/blob/master/img/future2.png)

# [Actor Pattern](https://blog.techbridge.cc/2019/06/21/actor-model-in-web/)
* 當對 `低一致性需求` && `高性能需求`時
* stateful service的良好實作
* 有點reducer的感覺(只允許內部改變狀態)
* Self-healing自我修復系統
* ActorRef && Future

```c
// 對參考的任何存取，都是對物件的操作
int n = 10;      // 定義變數
int *p = &n;     // 定義指標，儲存 n 的位址
int &r = n;      // 定義參考，是 n 的別名
```

![](https://github.com/zero85258/MyNOTE/blob/master/img/actor-model.png)
![](https://github.com/zero85258/MyNOTE/blob/master/img/actor-model-counter.png)
![](https://github.com/zero85258/MyNOTE/blob/master/img/actor.png)

* 證交系統常用
* 客戶的出價是否在成交價區間 && 客戶保證金足夠 (RuleBase)

# Akka 的 [Actor](https://blog.techbridge.cc/2019/06/21/actor-model-in-web/)的訊息傳遞
* fire-and-forget：也可視為tell，其操作子（operator）為”!”；將訊息以非同步的方式送給Actor後即刻返回。
* send-and-receive-future：也可視為ask，其操作子為”?”；將訊息以非同步的方式送給Actor後，回傳一個代表可能的回覆的Future物件。

```
而在操作上，每個 Actor 只被允許做下面3種 operation：

創建另一個 Actor
傳送 Message
指示該如何處理下一個 Message
```

# Hosting 代管
* 服務,內容 啥都可代管

# Repo(Hosting)
* [Nexus Repository](https://note.qidong.name/2017/08/nexus-repository-oss/)感覺好像是 repo 代管 全家桶 oss 殺必死
* 圖床
* 程式碼
* 映像檔

# CDN (Content Hosting)
* 可以將網站上的`靜態內容`（例如.html文件、.jpg圖片）和`動態內容`（例如DB查詢）緩存到CDN提供商位於全球各地的多個伺服器上, 加快Client讀取速度
* 其實導覽器感覺可視為就是`K/V`, K是URL, V是內容
* 多個edge

# 內嵌函式inline function
```
內嵌函式inline function{	//論原理比較像是巨集
	來建議編譯器將 呼叫的地方 置換成 函式主體 
}

看起來跟巨集有點類似，最主要的差異在於
巨集	 是	前置處理器(preprocessor)在處理的
內嵌函式 是 	編譯器(compiler)在處理的
```

# `巨集macro` 與 `函式function` 差異


* `函式`是拿時間換取空間的，
透過執行時期在函式堆疊的切換，相同邏輯區塊只要抽出成為函式，則大家共用同一份程式即可。
函式實務上還有另一個好處是可以取得函式位址，也就是說可以把函式當參數。

* `巨集`則是拿空間換取時間，
在編譯之前，前置處理器就將該程式替換至各個呼叫區塊，所以相同的邏輯在會重複出現在各個地方，
但是由於執行時間不需要在函式堆疊切換，節省了點切換時間。

不過據說在現今強大的編譯器優化能力之下，巨集與函式在執行時期的時間差，已經可以忽略了。
由於巨集是文字替換的本質，所以使用上也有上述的細節需要注意，

所以還是提倡多多使用函式實作的函式庫吧。

* [bash的黑魔法方案](https://stackoverflow.com/questions/10186359/define-a-function-like-macro-in-bash)
* laravel也可以用define呢!XD

# 抽象化 <---> 具體化 

	抽象化(隱藏個體過多細節) <---> 具體化
	
	主要是為了只保存和一特定目的有關的資訊
	降低複雜度
	抽象化主要是為了使複雜度降低，以得到論域中，較簡單的概念，
	好讓人們能夠控制其過程或以綜觀的角度來了解許多特定的事態。
	
	高階模組為抽象，abstract class 為抽象，interface 為抽象。
	低階模組為細節，class 為細節。
	
# abstract抽象化,interface介面
```	
若你真的需要繼承某class，但又希望別人無法new它，就將它宣告成abstract；
若你沒有需要繼承某class，只希望N個class都要求有某些功能,就先宣告一個interface，讓各class去實作它！
interface可解決部分語言 無法多重繼承
```

# 遞迴 
```
使大型程式碼變簡潔(樹狀走訪方便)
會要用到大量的 呼叫函式(堆疊) 
浪費太多記憶體(內存,CPU的RAM)
```

* [Recursive遞迴專家](https://medium.com/learn-or-die/recursion-%E9%81%9E%E8%BF%B4-%E4%B8%8D%E5%90%8C%E9%A1%9E%E5%9E%8B%E7%9A%84%E9%81%9E%E8%BF%B4-659ab2f53466)

# 預處理概念 
```
把部分的程式碼先經過編譯
提升執行效率
```

# 永遠搞混的SRAM,DRAM

	SRAM 就是 CPU的內存
	DRAM 就是 一條一條的金士頓等...

	伴隨中央處理器的快取記憶體(cache memory) SRAM
	主記憶體(main  memory)的容量 	DRAM
	NAND-Flash所製成的固態硬碟SSD

# 物件導向.性狀trait

	trait就是class的部分實體化
	解決{
		兩個類之間沒有共同父類
	}

# [Iterator迭代器(跟yield有關) && generator生成器](http://ithelp.ithome.com.tw/articles/10133614)
* yield 就像函式的中斷點，每次執行到這就會進行`回傳`，並中斷函式的執行

```
generator的所有功能都可以使用傳統函式搭配Iterator interfae達成，
但generator更簡單、更快速、且更節省記憶體，但也只提供forward-only功能

可以把許多複雜的循序操作，包裝成可以透過foreach來迭代的物件

可在容器物件（container，例如鏈表或陣列）上遍訪的介面，
設計人員無需關心容器物件的內存分配的實現細節
生成器 是一個返回 迭代器 的函數

PHP的generator就是簡單板的Iterator
資料量大時,可節省大量內存
功能性多樣 跟 簡潔性 之間的 折衷方案
```

* Iterator的next() 某種程度可視為`pub/sub`的


# js Generator
* 跟PHP的一樣
* js使用場景:使`非同部`代碼看起來跟`同步`一樣

# [閉包closure(特性) ](https://eyesofkids.gitbooks.io/javascript-start-from-es6/content/part4/closure.html)
* 一種變數會從函數外層跑到內層的`特性`
	
# 匿名函數 
* 沒有名稱的函數
* 適合作函數或方法的Callback
```js
function($name){
	return sprintf('Hello %s',$name);
};
```

# dll動態庫 vs 靜態庫(`體積`跟`單一進入點`的取捨)
```
*.DLL動態連結(Dynamic Linking)	 
目的{
	節約應用程式所需的磁碟和記憶體空間
	可不公開code的情況分享給別人使用
	更新程式庫 無需重新編譯 其他程式
}
特色{
	優:執行檔的體積小(跟執行檔不是同一包)
	缺:有相依性
}
DLL的函式會在程式執行時才被載入，
而不是直接編譯在執行檔中，這種作法讓系統更彈性的應用硬體資源，
由OS根據App的請求，動態到指定目錄下尋找並裝載入記憶體中，
同時需要進行地址重定向
```

```
*.Lib靜態連結(Static Linking)	
目的{
	不需要外部的函數庫支援
}
特色{
	缺:執行檔的體積大(跟執行檔包成一包)
	優:內容簡單 不需要外部的函數庫支援
}
會在開發階段將程式所需要的函數、
資源等全部加入程式的執行檔，執行檔的體積因此變大，
所以靜態連結的執行檔往往需要較大的記憶體空間，當所用的函式庫越多時，執行檔也就越龐大。
在編譯期間由編譯器與鏈結器將它整合至應用程式內，並製作成目的檔以及可以獨立運作的執行檔
```

# 動態語言 靜態語言
![](https://github.com/zero85258/MyNOTE/blob/master/img/%E8%AA%9E%E8%A8%80type.jpg)
* `靜/動`態類型決定compile-time類型安全, `強/弱`類型的run-time時類型安全
```
靜態方法 高效率, 但會常駐內存，占用內存空間,
動態方法 低效率, 調用完後會自動釋放，節省內存空間。

什麽情況下使用動態方法，什麽情況下使用靜態方法：
1:使用靜態方法是有好處的，因為靜態方法只維護一份拷貝，所以無論你有多少個實例，內存中都只會有一份拷貝。(util適合, 有點單例的感覺)
2:商務邏輯動態佳
```

* 靜態語言（statically typed languages
```
若一個程式語言的型別檢查（Type Checking）工作是發生在編譯時期（Compile Time），則稱之為靜態語言。
程式撰寫時必須使用明確的型別宣告，
編譯的當下，編譯器就會進行型別檢查，且變數或物件的型別一旦宣告後，
在Runtime執行時就無法任意更換型別，否則會發生Exception錯誤。
```
* 動態語言（dynamically typed languages）
```
若一個程式語言的型別檢查（Type Checking）工作發生在執行時期（Runtime），則稱之為動態語言。
編譯器不會事先進行型別檢查，而是在執行時才會進行，
且在執行時，變數還能不斷任意更換型別，JavaScript就是一例。
```


# 登錄檔(就是log檔)
```
什麼是登錄檔？
簡單的說，就是記錄系統活動資訊的幾個檔案，例如：何時、何地 (來源 IP)、何人 (什麼服務名稱)、做了什麼動作 (訊息登錄囉)。
換句話說就是：記錄系統在什麼時候由哪個程序做了什麼樣的行為時，發生了何種的事件等等。
```

# php 的 Static 類屬性,類方法
聲明類屬性或方法為靜態，就可以不實例化類而直接訪問。
靜態屬性 不能通過一個類已實例化的對象來訪問(要靠::)。
靜態方法

# 亂七八糟Driven
* troubleshooting Driven
* [規範 Driven](https://github.com/zero85258/MyNOTE/blob/master/%E6%AD%B8%E7%B4%8D&%E7%B5%B1%E8%A8%88%20-%20%E7%A8%8B%E5%BC%8F%E6%A6%82%E5%BF%B5.md#%E8%A6%8F%E7%AF%84%E5%85%B1%E8%AD%98)
* tradeOff Driven 取捨驅動

# 商業問題驅動開發BQD 
* Business-Question-Driven 
* 把`需求`變成`任務`的transform (取代pm的方式)
* 這幾乎就是找到`正確需求`的途徑了

![](https://github.com/zero85258/MyNOTE/blob/master/img/BQD.png)

# 測試驅動開發TDD
* 撇除unitTest, intergrationTest , 先找troubleshooting也是一種TDD

# [行為驅動開發BDD](https://tw.alphacamp.co/blog/bdd-tdd-cucumber-behaviour-driven-development)
* Cucumber
* BDD 比 TDD 更進一步，在寫測試前先寫測試規格書。這份測試規格會用更接近人類語意的自然語言來描述軟體功能和測試案例
* 而且這份規格不是單純的敘述文件，而是一份「`可執行的規格`」，也就是可以被轉成自動化測試
* WBS 直接轉 TEST

# [領域驅動開發DDD](https://www.slideshare.net/ssusercab70d/ddd-66897552)
* [link](https://medium.com/%E7%A7%91%E6%8A%80%E6%96%B0%E6%83%B3/domain-driven-design-%E7%AC%AC%E4%B8%80%E6%AD%A5-%E4%BA%86%E8%A7%A3%E5%83%B9%E5%80%BC%E9%8F%88%E8%88%87%E5%AE%9A%E7%BE%A9%E9%A0%98%E5%9F%9F%E6%A8%A1%E5%9E%8B-b60bb817f43d)

```sh
# 第一 擬定Domain Model, Domain Terms, ubiquitous language && 
與各你公司各個領域的專家（Domain Experts）合作定義
領域模型（Domain Model）和各個領域的領域詞彙 （Domain Terms）。
你如果有涉略DDD的話，你應該會有聽過 ubiquitous language 這個詞，
DDD 的目的就是與領域專家合作，為每一個Domain 定義出通用語言（ubiquitous language）。
通用語言和領域模型會是本篇文章的重點。
# 第二 依照domain terms實作
利用 Domain Model 和 ubiquitous language 來實作你的系統，
不論 class name, method name, event name, variable name，都應該去利用 domain terms 去定義，
如此一來，你的產品和工程團隊，和你的商業團隊可以用同樣的詞彙來溝通和討論。
# 第三
定義系統的範圍，除非你是從頭開始為一個複雜的商業流程設計一個系統，
妳一定需要接觸的舊有的系統，這些舊系統顯然的不會去遵循你所定義的新詞彙，
這是你必須要清楚的劃清系統的 界線Boundaries，
並在新舊系統間，定義一個 Translator(轉換層) / Anti-Corruption(防毀層) Layer，
你不需要去對就有的系統，做全盤的更新，
而是利用 Anti-Corruption Layer 去定義系統的範圍和清楚的指出新舊系統之間的對應關係
```

# [純商務邏輯的程式開發方向](https://ithelp.ithome.com.tw/users/20010292/ironman/62)
* [MDA + UML == DSL + 軟體工廠（Software Factories）](https://www.huanlintalk.com/2008/05/domain-specific-languages.html)
* [jetbrains mps]() 感覺是開發dsl 相關的東西

```
模式驅動結構(Model-Driven Architecture, MDA)已是一種廣被接受的軟體開發架構，
包括
平台獨立模式(Platform Independent Model, PIM)、
特定平台模式(Platform Specific Model, PSM)與
程式模式，
以及
PIM轉PSM，
PSM轉程式模式等，以改善系統開發之生產率、高階系統模式可攜性（或重用性）與維護性等問題。

本書再版除明白揭示結合MDA與UML(Unified Modeling Language)的物件導向分析與設計外，
還融入強韌分析與物件正規化以強化分析與設計之正確性與彈性，
並整合OCL(Object Constraint Language)與CASE工具以強化系統開發之自動化。
將強韌分析、類別正規化、UML、MDA、OCL與CASE工具等完美的整合於物件導向系統分 析與設計中，以大幅提升軟體開發效率與維護性的綜效

課程配合本書內容, 首先介紹系統開發模式、強韌分析、UML及其塑模方法論，
再介紹結合MDA、 UML、物件正規化、OCL的物件導向分析與設計之概念、程序步驟與方法，
並以一個案例與CASE工具，依MDA架構進行物件導向分析與設計及系統開發； 
循序漸進地一一說明，使讀者能清楚瞭解結合強韌分析、MDA、UML、類別正規化、OCL等進行物件導向系統分析與設計，
所可獲取之完整且連貫的塑模概念、活動與模式產出等。

對像管理組織（英文Object Management Group
```

# 模型驅動架構MDA(CIM,PIM,PSM)
* `CIM(Computation Independent Model)` Focus在`系統環境`及`需求`，但不涉及系統內部的結構與運作細節
* `PIM(Platform Independent Model)` Focus於`系統內部細節`，但不涉及實作系統的實體平台(Platform)
* `PSM(Platform Specific Model)` Focus在系統落實於`特定實體平台的細節`，例如，Spring、EJB2、.NET…等實體平台

---

* CIM以`使用者`的角度描述`業務需求`；
* PIM則專注在`各領域應用系統的模型化`，但仍不考慮使用的技術；
* PIM可對應到各種`技術平臺的PSM模型`，進而`自動產生程式碼`。
* 修改PIM對應到PSM即可自動產出不同的`程式碼`或`資料庫Schema`，系統維護工作也就變得容易。

---

* [enterprise architect 實踐](https://www.jb51.net/softjc/692394.html) [一頁式簡介](https://sparxsystems.com/products/ea/index.html)

# 事件驅動架構EDA
* Event 代表已經發生過的事(可以把`事情發生`跟`實際處理`2件事分開進行)
* Event Notification 提供的依赖反转，我们的系统将具有更好的扩展性, 
* Event Carried State Transfer模式, 


```sh
不可避免地，下游系統在處理這個event時，
往往還需要查詢上游系統來獲取這些額外信息。
簡單來說，就是讓event的消費方（上文中的保險報價系統）自己保留一份要用到的上游系統的數據。

現在各個event消費方系統都複製了一份各自業務所關心的上游系統數據，由此也產生了備份數據之間的一致性問題。
考慮到解決數據一致性的成本和這個模式所帶來好處，
在實際工程中的應用會更少一些。
```

* Event-Sourcing, (akka有點相關)
* [Event Store 殺必死](https://yami.io/golang-event-store/)
* Command Query Responsibility Segregation (CQRS)

```sh
# Event
紀錄狀態/資料"如何"改變，而非改變後的狀態結果 例如對資料庫/table的更動， Event會是不可變的(真實的歷史紀錄)

# Event sourcing
將Event依序記錄下來，而不直接紀錄變動後狀態，
靠著執行所有的Events可以取到最新或特定的狀態，或者由於有所有的Event(整個改變的歷程)，
可以從最新的狀態透過反序執行相反的Event或是針對Event補償的動作，rollback/rollundo到特定的狀態
```
* [dapr](https://github.com/dapr/dapr) 感覺像是事件驅動得infra, (Dapr不知道是不是幫我們做掉微服務裡面worker的sdk問題

# 繼承相關(this,self,parent)
* $this 代表 物件本身(使用時後面變數不用$ ex:$this->apple)
* self 代表 類本身
* parent 代表 父類本身
* final 不能被繼承(絕子絕孫)

# SQL 的 LIKE(模糊比對)
```sql
-- 有點像正則表達式
SELECT Name FROM city WHERE Name LIKE '%app__%'
```

# TCP/IP SOCKET HTTP 的區別
```
IP協議對應於網絡層
TCP/IP協議對應於傳輸層	(SOCKET是此層的API接口) PHP 使用Berkley的socket庫
而HTTP協議對應於應用層
```

# Program Process Thread
```
Program == 只是一堆程式碼
Process == OS分配 系統資源() 給 Program 並 執行上面的指令 
Process = Thread[0] + Thread[1] + Thread[2] + .....

作業系統 會配置給每個Thread一部分 CPU暫存器空間 (register)  以及存放執行指令過程中，暫存相關資料 的 記憶體空間
```

# Context switching內文切換(process之間的,作業系統範疇內的,thread沒有)
```bash
# 當CPU從一個process切到另一個process執行之前，(就是切換task)
Context switching(){	
	PSP行程堆疊.push(執行狀態) 	//OS必須保存原有process的執行狀態(eg. pc, CPU register store in PCB)，
	PSP.pop()			//同時載入 New Process的執行狀態(eg. Load PC, CPU register值from its PCB)
}
而 Context switching是一系統負擔，其時間長短，幾乎完全取決於Hardware因素
```

# Swap & ContextSwitch
* swap 是process在記憶體搬上搬下的，
* context switch是兩個process在轉換資訊的過程

# Compiler知識 
```
一個code 經過 "特定Compiler" 只能放在 "特定平台運行"
code.Compiler(PC)	//是不行被放到其他平台的 只能放PC
code.Compiler(ARM)	//是不行被放到其他平台的 只能放ARM
```
# 分時系統 
只有一個CPU,但是同時處裡`多個Process`


# 多型polymorphism , 多載overload , 重載(覆寫)override (一直搞錯)
```
用 參數 控制函式行為的，就叫 "多載overload"。{
	bool Add( int a, int b );
	bool Add( float a, float b );
}


用 類別 控制函式行為的，就叫 "多型polymorphism"。{	//通常會使用interface
	相同的訊息可能會送給多個不同的類別之物件，而系統可依據物件所屬類別，引發對應類別的方法，而有不同的行為
	喇叭.PLAY()
	吉他.PLAY()
	//PLAY()出來的聲音不一樣
	
	一些 功能||範疇 相近的類別，它們有類似的行為與功能，但卻不適合塞近同一個類別中。
	為了 規範開發原則，常會利用一個 interface 或 基礎類別 來延伸這些 子類別，
	以強制這些 子類別 有完全一樣的 屬性() 與 方法()，達到 "規格最佳化"
}

覆寫,重載override {
	寫一個父類相同名稱的函數
	可覆蓋繼承過來的函數用法
}
```

# 委派delegate (一種型別)
* Delegate(委派)是將 function 當成參數傳遞的`型別`

```cs
//委派 就是拜託他去幫你執行某個 "方法"，
//你所拜託的委派，要能做到你所要的方法(也就是傳回的型別，跟傳入的參數要一致)	
Main(){
	MyDelegate d;

	//依照傳入的動作，選擇要傳入委派的方法,(這邊有用到 匿名函式)
	if(case=="+")		d = new MyDelegate(加法);
	else if(case=="-")	d = new MyDelegate(減法);
	else if(case=="*")	d = new MyDelegate(乘法);
	else if(case=="/")	d = new MyDelegate(除法);
		
	//使用該委派(這邊有用到 匿名函式)
	int Answer = d(5, 2);
	Console.WriteLine(Answer);
}
	
public static int 加法(int x, int y){return (x + y);}
public static int 減法(int x, int y){return (x - y);}
public static int 乘法(int x, int y){return (x * y);}
public static int 除法(int x, int y){return (x / y);}
public delegate int MyDelegate(int x, int y);
    	
```

# Lambda表示式(是一種匿名函式)
```cs
//Lambda表示式 概念圖	
//(input parameters)  =>  { expression }
	
if(case=="+")
	//加法是用delegate，然後傳入參數並在中括號中 return結果
	d = delegate(int x, int y){ return x + y;};
else if(case=="-")	
	//減法省略delegate關鍵字，改用Lambda運算式的寫法
	d = (int x, int y) => { return x - y;};
else if(case=="*")
	//乘法連 中括號 和 rtn 都省了，直接寫要傳回的結果
	d = (int x, int y) => x * y;	
else if(case=="/")	
	//除法連傳入的型別都可省略，因Lambda會自動推斷
	d = (x, y) => y != 0 ? x / y : 0;	//正確的型別
		
```
	
# Dictionary字典,Hashtable雜湊陣列 
```sh
//使用上來說都是 a[KEY] = VALUE
//但是在排序,Thread方面,等...上來說不一樣
//Dictionary
//Hashtable 
//題外話:GET,POST,Cookie,Session這些東西使用上通通都是 a[KEY] = VALUE
```

# Websocket、Ajax輪詢、長連接(long pull)、Server-Sent-Events(SSE)比較 
```sh
# Websocket
# 優點就是，只要建立一次連接，就可以連續不斷的得到伺服器推送的消息，節省帶寬和伺服器端的壓力。
客戶端：我要建立websocket連接
伺服器端：好的，已經切換到websocket協議，websocket連接已經建立
客戶端：有什麼消息要及時告訴（推送）我
伺服器端：好的
伺服器端：xxxxxx
伺服器端：yyyyyyy

# Ajax輪詢
# 缺點顯而易見，每次都要建立HTTP連接，即使需要傳輸的數據非常少，所以這樣很浪費帶寬；同時，這個過程是被動性的，即不是伺服器主動推送的。
ajax輪詢模擬長連接就是每個一段時間（0.5s）就向伺服器發起ajax請求，查詢伺服器端是否有數據更新
客戶端：有沒有新消息
伺服器端：沒有。。（第一次http結束）
客戶端：有沒有新消息
伺服器端：沒有。。（第三次http結束）
客戶端：有沒有新消息
伺服器端：沒有。。（第四次http結束）
	
# 長連接（long pull）
# 缺點也是顯而易見的，同ajax輪詢一樣，也是每次都要建立HTTP連接，也都是被動的。而且這種方法對伺服器的並行要求比較大
客戶端：有沒有新信息（Request）--第一次http請求開始
伺服器端：沒有信息，不作回應（時間一直的流逝。。。一直保持http連接，當等到有消息的時候）
伺服器端：給你xxxx（Response）--這時，第一次的http請求獲得想要的結果，然後還要發起第二、三。。次http請求
客戶端：有沒有新消息（Request）--第二次http請求開始

# Server-Sent-Events(SSE)
# websocket比較全面性,假如只是client要收資料好像比較簡單
var source = new EventSource('stream.php');
source.addEventListener('message', function(e) {
  console.log(e.data);
}, false);
```

# 作業系統.同步異步機制 
mutex、semaphore、monitor 等《同步機制》，那些就是作業系統課程裡的重點問題了。  

* mutex	用於`多thread`編程中，防止兩條thread同時對同一公共資源（比如全局變數）進行讀寫的機制  
* semaphore 提供平行運算環境中，控制`多process` (程序)或`多thread`(執行緒)存取共享資源的能力  
* monitor  
* 幾乎是用在 `判斷某個東西,然後賦值` 的場景

# Mutex互斥鎖
```
using System.Threading;
	
private static void MyThreadProc()
{
	//進入互斥區，搶得工作權，其他人只得等待
	mut.WaitOne();

	//做些工作
	    
	//離開互斥區，歸還工作權，換下一個
	mut.ReleaseMutex();
}
```
	
# thread Synchronization 執行緒同步化(排隊) 
```
迫使多條thread從 非同步 暫時切換成 同步執行 
使用lock關鍵字
迫使各thread在進入特定程式碼區塊時乖乖`列隊`，以達到同步化的效果。
```

# [Synchronization/Synchronized 執行緒同步化(排隊) ](https://www.jackforfun.com/java-synchronized)
* 用來控制線程同步(排隊)的
* 在執行了thread之後，下個要問的議題就是要怎麼在thread之間去做synchronization(同步)。我們分以下幾個[議題](https://popcornylu.gitbooks.io/java_multithread/content/sync/sync.html)來討論:
* `Resource Sharing`: 如果多個threads同時存取變數該如何解決? 是否可以同時只有我這個thread允許修改某一個resource?
* `Flow Control`: 一個thread可否等到另外一個thread完成或是執行到某個狀況的時候才繼續往下做?
* `Message Passing`: 我可否把我一個thread的output當作另外一個thread的input?

# Starvation 執行緒飢餓
* 意思是如果一個Thread優先權太低, 那麼有可能發生沒有足夠時間執行完任務

# muti-thread join
[muti-thread join](https://my.oschina.net/u/2529036/blog/618014)
`多thread`併發比較常見，但很多時候一個thread的`input`可能非常依賴於另外一個thread的`output`，  
此時這個`thread`就需要`wait()`依賴thread執行完畢再執行。通俗的說，就是合併多個路徑為單一路徑，變`多thread`並發為`單thread`順序執行  
join——英文含義為加入，通俗的說就是將一個線程合併到另一個線程。但是還有以下幾個問題：  
* 哪個線程加入？
* 加入到哪個線程?
* 加入後的效果是啥?
* thread之間的溝通是靠類似MessageQueue的方式

# IPC(process的溝通方式)
* 提供了4種機制: `匿名管道(Anonymous pipes) |`,`命名管道(Named pipes) mkfifo`,`套接字(Sockets) *.sock`,`訊號量(Signals) kill`。
* `共享內存` 好像也是常用的方式
* 殺只是其中一個功能, kill 其實是送 signal

# [Unix Domain Socket](https://blog.gtwang.org/programming/bash-tutorial-open-tcp-udp-socket/)(一種IPC)
* `unix:///var/run/td-agent/td-agent.sock`
* 好像可以 Nginx 可以 proxy_pass 給 sock, 再由 nodeJs listen 收 request
* unix socket分2種 = [STREAM類型(類似TCP),DGRAM類型(類似UDP)]
* `php-fpm.sock`,`mysql.sock`,`docker.sock`,等... 很多東西的連線都是用這個方式

```sh
# nc 方案
nc -lU /var/tmp/dsocket
```

```bash
# 開啟連線至 Google 網頁的 socket
exec 3<>/dev/tcp/www.google.com.tw/80

# 送出 HTTP 請求
echo -e "GET / HTTP/1.1\n\n" >&3

# 接收網頁內容，1 秒後自動停止接收資料
timeout 1 cat <&3

# 關閉輸入與輸出 socket
exec 3<&-
exec 3>&-
```

# process掛起(SIGHUP)

# 分段Segmentation && 分頁Paging (記憶體分配方式,`空間`與`性能`的取捨)
	
* `分段Segmentation`：是依照 程式所需 的記憶體實際大小來分配記憶體位址。
* `分頁Paging`：是將記憶體切割成 `固定大小chunk`，然後依程式需求量而給予足夠記憶體空間。
```sh
# 一般來說
實體記憶體{
	價格昂貴，但運作速度快，OS 均採取 分段 的配置法，如此可避免配置不完整的空間浪費
}虛擬記憶體{
	讀取速度慢，但價格便宜，因而採用 分頁 配置模式。
}
```

# (CI => hook , Laravel => middleware) (感覺都是lifeCycle裡面,某`階段phase`會觸發的腳本)
```
//目的: 不修改系統核心文件的基礎上擴展系統功能
CI 裡叫 hook (猜測是把外部的東西捕捉到函式)
Laravel 叫做 middleware (流水線一關關檢查)
	
//在事件傳送到終點前 截獲||監控 事件的傳輸，
//像個鉤子鉤上事件一樣，並且能鉤在鉤上事件時，處理一些自己特定的事件
```

# URI URL URN 差異 

	URI{	//統一資源識別項
		URL(定位符){	//統一資源定位符
			它標識一個網際網路資源，並指定對其進行操作或取得該資源的方法
			協定/域名/目錄及檔案
		}
		URN(名稱){	//統一資源名稱
			URN是基於某命名空間通過名稱指定資源的URI
		}
	}
	
# .htaccess 文件 
```
是在Apache HTTP Server這款服務器架設軟件下的
一個對於系統目錄進行  各種權限規則設置的文件
	
比較常見的是  
定義默認首頁名稱，404頁面，301轉向，等等，
還有更多的功能比如偽靜態，限製圖片外鏈，限制下載，密碼保護，去除頁面廣告等等
```

# implements實作 (配合interface)
```php
//有點監督的概念,假如沒有 實現 方法 , 編譯就不會過
// --- 會報錯 -----------------------------
interface action{
    	public function run();
}

class animal implements action {

}
	
// --- 正確 --------------------------------
interface action{
	public function run();
}

class animal implements action {
    	public function run(){}
}
```

# 軟體心法
![](https://github.com/zero85258/MyNOTE/blob/master/img/%E8%BB%9F%E9%AB%94%E5%BF%83%E6%B3%95.png)


# [正交設計(正交四原則)](https://www.jianshu.com/p/f7f5813882a1)
* 消除重複
* 分離關注點(SoC)
* 縮小依賴範圍
* 向穩定依賴

### 好的面向對象設計，自然是符合高內聚，低耦合原則的對象劃分和協作方式
### 正交原則與SOLID的關係
#### 高內聚（怎麼分）
* 單一職責:策略`消除重複`，分離`不同變化`方向(`分離關注點`)，正是讓類達到單一職責的策略與途徑。

#### 低耦合 (怎麼合)
* 開放封閉:對於修改是封閉的，對於擴展是開放的
* 里氏替換:子類不應該破壞其父類與客戶之間的契約。唯有如此，才能保證：客戶與其父類所暴露的接口（即API）所產生的依賴關係是穩定的
* 依賴倒置：為了讓`依賴關係是穩定`的，不應該由實現側根據自己的技術實現方式定義接口
* 介面隔離 `縮小依賴範圍`策略


# SOLID 
```sh
S:單一職責 (好讀)
	#策略消除重複，分離邏輯關注點
O:開放/封閉原則 (代碼的正確率會++) 
	#對於修改是封閉的，對於擴展是開放的
L:Liskov替換 (代碼的正確率會++)
	#子類可以擴展父類的功能，但不能改變父類原有的功能
	#子類拿來就可以當父類用，而且還不出錯。接口要符合，限制要比父類寬泛。
I:介面隔離 
	#縮小依賴範圍策略
D:依賴反轉 (好修改)
	#為了讓依賴關係是穩定的，不應該由實現側根據自己的技術實現方式定義接口
	#車體不該依照輪胎規格設計,應該輪子該依照車體設計(否則 輪子一改 車體得重新設計)
```

# 依賴反轉 DIP(SOLID原則的D) 	
* [車體不該依照輪胎規格設計,應該輪子該依照車體設計](https://www.zhihu.com/question/23277575)

```
依賴反轉 == 讓 待測物件 僅能相依於 由unitTest訂出interface

為了可測試性，
unitTest必須可決定 待測物件 的 相依物件，如此才可由unitTest將相依物件加以 抽換隔離。
我們不能讓 待測物件 直接相依其他 class
而實際 相依物件 可由unitTest來決定，如此我們才能對相依物件加以抽換隔離。
	
依賴反轉 只確保了待測物件的相依物件相依於 interface
```

# IoC 控制反轉Inversion of Control (一種OOP設計原則) 
```
用來減低計算機代碼之間的耦合度。
其基本思想是：藉助於「第三方」實現具有依賴關係的對象之間的解耦
```

# IoC Container 控制反轉'容器' # Inversion of Control Container 
```
---service1-----|========|      
---service2-----| Ioc容器 
---service3-----|========| 
```

# [依賴注入 DI (屬於一種IoC方法)](http://jaceju.net/2014-07-27-php-di-container/)
* 實現代碼解耦，便於單元測試
```
依賴注入 == 依賴反轉 + 注入動作
所謂 依賴注入，就是把底層類(輪胎)作為參數傳入上層類，實現上層類(車體)對下層類(輪胎)的“控制”
```

就是將實例變量傳入到一個對象中去(Dependency injection means giving an object its instance variables)。
```
所謂 依賴
如果在 Class A 中，有 Class B 的實例，則稱 Class A 對 Class B 有一個依賴。
例如下面類 Human 中用到一個 Father 對象，我們就說類 Human 對類 Father 有一個依賴。
	
Q:WHY 不new 改成 建構子(User $user) != 有依賴
A:還是有依賴,但是依賴變成可抽換

laravel 是因為service container 讓我們方便實現 DI
```

# 依賴注入 DI (屬於一種IoC方法) 
* `依賴注入DI`是為了實現`控制反轉IoC`，`控制反轉IoC`是為了實現`系統分層`，`系統分層`是為了實現`解耦`以實現`可維護可擴展`。

```
//我們的相依物件 要 相依interface, 
//我們的相依物件 = model資料 ,所以框架本身model應該是有相依某interface~
//不然就是我們的 待側物件 根本沒有 相依物件
DIP 只確保 待測物件 的 相依物件 相依於 interface
	
高階模組 不要 依賴細節，細節要依賴 interface。
	
既然 相依物件 相依於 interface，		//interface 指的就是controller抽出的service???
若 單元測試 可以產生該 interface 的物件，	//new XXXXService()???;
並加以注入，就可以將相依物件加以抽換隔離，這就是依賴注入。	//publice function xxxxx(User $user)
```

# 循環注入
* 包之間的依賴結構必須是一個直接的無環圖形（DAG）。也就是說，在依賴結構中不允許出現環（循環依賴
* DI是解法???

# 單元測試 

```sh
為了可測試性，unitTest必須可決定 待測物件 的 相依物件，如此才可由單元測試將相依物件加以抽換隔離
想 單元測試 得達成{	//需要 由unitTest 將 相依物件 加以抽換隔離
	必須可決定 待測物件 的 相依物件，如此才可由unitTest。	//白話的說 必須可以mock相依物件,以之前來說可能就是資料上的相依 
}


有了IoC != 達成可測試性，IoC只確保了待測物件的相依物件相依於 interface。

//疑點{
	既然 待測物件 的 相依物件 相依於 interface，
	若單元測試可以產生該 interface 的物件 , 並加以注入，
	就可以將 相依物件 加以抽換隔離，這就是依賴注入。
}不知是不是答案{
	//不知是不是指mock這件事
}
	
而應該由單元測試訂出 interface，讓待測物件僅能相依於 interface，
```

# 純函數測試
```
純函數之所以易於測試，從某種角度上說是因為它的所有依賴就是它的參數，
所以我們可以很容易地在測試的時候模擬其所有需要的依賴的變化進行測試。
依賴注入通過給所有我們需要用到的函數、量統一包裝，也能實現類似的效果。
```

# gc (資源釋放)

# 語法糖 
* JSX, TypeScript, CoffeeScript 都算是語法糖

# 事務 vs 鎖
* 事務(原子性) vs 鎖(隔離性==多個原子性 共存)

# 事務併發(隔離性)
* 樂觀鎖,悲觀鎖
* MVCC

# (SQL) ON DUPLICATE KEY用法 (`悲觀鎖`,且資料不存在) 
```sql	
# 需求是「新增一筆資料，如果資料已經存在改成更新」(否則insert之前還要select)	
INSERT INTO Player(sn, playerName, height, weight)
VALUES('12', 'Kevin', 177, 72)
ON DUPLICATE KEY UPDATE playerName = 'Kevin', height = 177, weight = 72
```

# SELECT ... FOR UPDATE (正確度優化,`顯式鎖定`,`悲觀鎖`,`排它鎖`) 
* [避免 Race condition](http://blog.xuite.net/vexed/tech/22289223-%E7%94%A8+SELECT+...+FOR+UPDATE+%E9%81%BF%E5%85%8D+Race+condition)
* 隱式鎖定 和 顯式鎖定

# SELECT ... LOCK IN SHARE MODE(`共享鎖`)

# MVCC(隔離性)
```
MVCC是通過保存數據的多個版本來實現並發控制，
當需要更新某條數據時，
實現了MVCC的存儲系統不會立即用新數據覆蓋原始數據，
而是創建該條記錄的一個新的版本。
對於多數數據庫系統，存儲會分為Data Part和Undo Log，

Data Part用來存儲事務已提交的數據，(寫是這個嗎???
Undo Log用來存儲舊版本的數據。(讀

多版本的存在允許了讀和寫的分離，
讀操作是需要讀取某個版本之前的數據即可，
和寫操作不衝突，
大大提高了性能。
```

* PGSQL == vacuum

# 共享式鎖定 Shared Lock(S)
```
共享鎖定，
共同分享讀取資料表內的資訊，
此鎖定僅會在對資料進行讀取時產生。
這種模式的鎖定是不會影響到其他人讀取相同資料，
例如，
當您透過select 指令查詢資料時，
就會有共享鎖定的產生。
那為何要有這樣的鎖定機置呢? 共享鎖定，
其實是一種非常悲觀的模式設計，
主要用途是當資料進行查詢的同時，
防止其它交易對同份資料進行更新，
當讀取的動作結束後，
除非有額外設定「Lock Hints」或是「Isolation Level」否則系統會迅速得將資料解鎖，
並且釋放。
「Lock Hints」及「Isolation Level」我們往後會談到。
一個交易的Shared Lock 可與 其他交易的Shared Lock 或是 Update Lock相容。
```


# 獨佔式鎖定 Exclusive Lock(X)
```
獨佔鎖定，
當下達insert、update以及delete這類DML指令時，
系統其實會內含兩個操作，
首先會
產生Shared Lock讀取資料，
接著產生Exclusive Lock 進行資料的實際更新，
而當Exclusive Lock產生後，
其他的交易是無法針對相同資料進行封鎖。
一個交易的Exclusive Lock無法與其他交易的任何種類的Lock相容
```

# Lock Hints


# 外鍵
* 用來保證資料的`完整性`和`一致性`
* 會使速度和性能`下降`

	
# 服務容器 (Laravel核心的概念)
```
Laravel的核心 就是一個 IoC容器，
稱其為“服務容器”，顧名思義，該容器提供了整個框架中需要的一系列服務(Router,Migrate,Blade等等等...)
```

# Laravel ServiceProvide服務提供者 
```
假設模塊一多，那麼容器不是越來越大？每次加載，豈不是加載好久？
能像管子一樣，連接著模塊，插在容器上，
"需要時"再通過管道獲取呢？這樣子，容器只是裝著管頭而已，就不怕被撐大了！
這條管子就是服務提供者。

---service1-----|========|      
---service2-----| Ioc容器 
---service3-----|========| 
```
	
# 麵包屑路徑 Breadcrumbs 
```sh	
# 像是這種 就叫做 麵包屑路徑(網頁上的pwd)
Home > 產品分析 > 廣告主 > 亞太電信股份有限公司 > 產品列表
```

# callback 
* 把一個函數傳入另一個函數,然後`執行`傳入的函數
	
# 匿名函式 

# fetch API
* 為了取代XHR
	
# Promise ( `異步執行` 的 `流程控制架構`)
* js一行行乖乖寫是`同步`,要`異步`執行就需要setTimeout
* Promise結構是一種 異步執行 的 `控制流程架構` (否則以前要`異步`同時要`控制流程`就要靠callbackHell)
* resolve,reject `感覺`可以當成linux stdout stderr的感覺來看

```
可以 異步執行的callback函式，
可以把 多個 異步執行的函式(callback hell)，
執行流程轉變為序列執行 一個接一個( .then().then().then() )，
or 並行執行(全部都要處理完再說)，
更好的錯誤處理方式。

reject
```

# mysql viewTable (速度優化) 
* 可把常用的查詢存起來
* laravel 底下可用 ->toSql() 打印出sql 再存入view;


# Procedural Language(速度優化)
* 有點像把 多個常用的sql 串成 腳本
* sqlJob1()->sqlJob2()->sqlJob3()->sqlJob4()
* Oracle派:PL/SQL
* PostgreSQL派:PL/pgSQL
* 微軟派:TSQL
* MySQL:Stored Procedures
* Greenplum PL == PL/Container - Greenplum PL Analysis Suit Backend


# 資料庫 正規化(拆表,正確度up) 反正規化(合表,效能性up) 
* 降低 `重複性` 與 `相依性`
* 透過刪除重複性和不一致的相依性，保護資料並讓資料庫更有彈性
	//正規化()		只是建立資料表的原則，而非鐵的定律。
	目的:降低資料的重覆性、避免資料更新異常，使資料庫運作起來更有效率，維護上也更容易
		
	if(過度正規化){
		查詢來自於多個 表 的大量資料時，會造成效能下降(join太多)。
	}	
	
	//反正規化()
	目的:提升效能，以查詢(select)效能為考量
	亦即將原來的第三正規化降成第二正規化，或是將第二正規化降成第一正規化。

# [正規化1~3](https://support.microsoft.com/zh-tw/help/283878/description-of-the-database-normalization-basics)
* 透過刪除重複性和不一致的相依性，保護資料並讓資料庫更有彈性

	
# [存儲引擎 MyISAM InnoDB ](https://www.jianshu.com/p/a957b18ba40d)
```
if(R/W > 100:1 且update相對較少 || 並發不高 || table數據量小 || 硬件資源有限){
	採用MyISAM引擎
}

if(R/W比較小，頻繁更新大字段 || 並發高 || table數據量超過1000萬 || 安全性和可用性要求高){
	採用InnoDB引擎
}

MyISAM{	//性能,性能,性能(讀)
	1.每個MyISAM在磁盤上存儲成三個文件{ 
		.frm文件存儲表定義。
		數據文件的擴展名為.MYD (MYData)。
		索引文件的擴展名是.MYI (MYIndex)。
	}
	2.data是以文件的形式存儲，所以在跨平台的數據轉移中會很方便。在backup和恢復時可單獨針對某個table進行操作
	3.強調的是性能，每次查詢具有原子性,其執行數度比InnoDB類型更快，但是不支持 事務。
	4.可以和其他字段一起建立聯合索引。引擎的AI列必須是索引，如果是組合索引，自動增長可以不是第一列，他可以根據前面幾列進行排序後遞增
	5.只支持table lock,操作myisam表時 curd語句都會給表自動加鎖
	6.允許沒有任何index和pk的表存在，index都是保存行的地址
	7.不支持fk
}

InnoDB{	//安全,安全,安全(寫)
	1.所有的table都保存在同一個數據文件中
	2.需要更多的ram和存儲，它會在ram中建立其專用的緩衝池用於高速緩衝數據和index
	3.免費的方案可以是拷貝數據文件、備份 binlog，或者用 mysqldump，在數據量達到幾十G的時候就相對痛苦了。
	4.提供支持 事務，fk等高級數據庫功能
	5.InnoDB中必須包含只有該字段的index。引擎的AI列必須是index，如果是組合索引也必須是組合索引的第一列
	6.支持事務和row lock，是innodb的最大特色。row鎖大幅度提高了多用戶 並發操作的新能
	7.如果沒有設定pk || not null唯一索引，就會自動生成一個6字節的主鍵(用戶不可見)，數據是主索引的一部分，附加索引保存的是主索引的值
	8.如果你的數據執行大量的INSERT或UPDATE，出於性能方面的考慮，應該使用InnoDB表。 
	  DELETE 從性能上InnoDB更優，但DELETE FROM table時，InnoDB不會重新建立表，而是一行一行的刪除，。
}
```


# (SQL) 資料庫分區化(Partition)(速度優化) 
```
當資料表的資料越來越多，檔案越來越大，存取速度越來越慢。
使用分區(partition)是將同一個資料表的資料，分成不同小檔案儲存，
甚至可以指定每個小檔案儲存的位置，例如放在不同磁碟，增加存取的速度。

#if($data < 20)
	$分區1->save($data) 
#elseif($data < 40)
	$分區2->save($data) 
	
"ALTER TABLE {$表名} ADD PARTITION (
	PARTITION {$分區1} VALUES LESS THAN (
		20
	)
	PARTITION {$分區2} VALUES LESS THAN (
		40
	)
)"
```

# truncate table 
* 在innodb上如果要清空保存有大量數據的表，最好使用truncate table這個命令

# Temporary Table 臨時表 (常用於大量寫入)
```
如果有一個300萬筆的資料表，而你只需要用到其中的一千筆，
而且還需要重覆的篩選、比對(Join)這一千筆資料的話，
那麼Temporary Table(臨時表)能夠減少重複查詢大資料表的次數，
也能讓資料的篩選和比對變得更容易
	
下面簡單跟大家說明TEMPORARY TABLE的幾個特性
```
* 功能與實體表相同，可以儲存資料、建立、刪除、增加INDEX、PRIMARY KEY...等功能
* 不可以被reopen(在同一個查詢指令內，查詢TEMPORARY TABLE兩次，但實體表可以)
* 在同一個連線下會持續存在，當連線關閉時，TEMPORARY TABLE會自動被刪除
* 表的大小取決於 tmp_table_size 的設定值，當表的大小超過這個設定值資料表會將表存入磁盤，則造成效能大減
```
Schema::create('temp', function (Blueprint $table) {
       	$table->increments('id');
        $table->string('session_id');
});
```


# 池Pool 
```
如果有某個物體需要經常 實例化() 並進行 銷毀()
這會導致實例化的成本過高
這時候就可以透過物件池來對物體進行管理
要用時取出,沒用時放回去
//同理 連線池,線程池,事件池,人力池........
```
* stream pool, connection pool, thread pool

# MYSQL 連線機制
```
if($mysql < 5.6) 
  一個連線一個thread(不斷銷毀建立)
else
  thread pool 
```

# mysql mysqld 
* mysql是shell
* mysqld是實際運行的 後台程序
	
# Linux Swap 

* Swap 空間可是個 swap`partition`（建議使用）或 swap`檔案`，或 swap `partition`與 swap `檔案`的`結合`
* `虛擬內存`是運行process可以使用的`RAM`和`磁盤空間`的組合。
* `swap`是`硬盤`上`虛擬內存`的一部分，在RAM已滿時使用。

```sh
swapon -s			#查看目前使用的虛擬記憶體 資料
fallocate -l 4G /swapfile	#在根目錄底下建4G 大小的swap檔案
	
swapoff /swapfile		#關閉off
chmod 600 /swapfile
mkswap /swapfile		#格式化
swapon /swapfile		#打開on
```

# 代理 反向代理 
* `Proxy Server 代理伺服器` 的工作是去各個 Web Server 抓取資料回來放在伺服器上來供用戶讀取、下載，
	
* `Reverse Proxy Server 反向代理伺服器` 做的事則是和 Proxy Server 剛好相反，
負責將用戶端的資料傳送給藏在 Reverse Proxy Server 後面	的 Web Server， 
這些躲在後面的 Web Server 不會、也不能直接被用戶直接連結，只能經由 Reverse Proxy Server 代理傳送和接收資料。 


# 水平和垂直擴充 (Scaling) 
* 垂直擴充（vertical scaling）
就是把硬體升級到更快的CPU或更多RAM  
傳統DB架構的設計是為了能在單一主機上運作順暢，應付大量營運的最簡單方式


* 水平擴充（horiontal scaling）
例如：Hadoop 和 Cassandra，則是被設計在相對較低階伺服器的叢集上執行，  
所以要應付更多資料，最簡單地就是在叢集中增加更多主機，當營運量越高、資料量越大，這種方式就越便宜，

那些巨量資料處理流程也都被建置在水平擴充模型中。但是這種方式有一項特殊成本 -- 
處理分散式資料的程式碼開發工作是有相當難度的，同時也需要考慮速度、擴充性、容錯性、傳統資料庫的單元性（或稱不可分割性）和一致性，在這些要求之間取捨。


# systemd systemctl service
* systemctl ==控制=> systemd
* systemd 啟動服務的機制
* systemctl == service(腳本命令) + chkconfig

# L5 Repository (分離關注點)
* [github](https://github.com/andersao/l5-repository)
* [教學](https://www.jianshu.com/p/f8027eab186c)
* 可在Repository把一些重複的程式碼消掉
* 例如fetch,fetchAll之類幫你包好,在service段呼叫就可以更一致化

# L5 Repository Transformer (分離關注點)
* `composer require league/fractal`
* for API 好用

# DAO ~= Repository Implementation + Repository Interface (分離關注點)

# DTO == MVC Entity (分離關注點)

# laravel vs spring
* 設想一下如果是前端做好頁面, 拿到後端套範本,那Thymeleaf 完爆Blade, 因為Thymeleaf 可以保留預覽數據, 渲染實際數據,Blade 做不到這一點.
* Laravel 框架的 ORM 構建需要經歷兩個步驟,migration 和 model , 而且改動 migration 需要調整 model, 無法向JPA(JavaPersistenceAPI) 一樣Entity 即資料庫結構;
* 拿MVC類比，在Java Web里面，JSP是用于View层面的，Servlet扮演Controller + router的角色。

# [連線池 DB Connection thread Pool](http://peggg327.blogspot.com/2014/11/connection-pool.html)
* DB Connection 的建立成本是昂貴的，故當有許多Thread都需要建立connection時，其資源的耗費是龐大的。
##### 對於最佳 Pool 用例，需要考慮一些經驗法則：
* 變量`Threads_running ` == 當前在MySQL服務器中執行的 `並發語句數量`
```
//對於InnoDB工作負載通常超過40
if (Threads_running　始終 > 服務器無法以最佳方式運行的區域) 
  則 Pool 將是`good`的，尤其是在極端 並行 過載情況下。
}
```
* if您使用 innodb_thread_concurrency 限制 `並發執行語句`的數量，
您會發現 Pool 通過為線程組分配連接，然後根據`Transaction事務`內容，用戶定義的名稱等排隊執行，只能更好地解決相同的問題。
* 最後，如果您的工作負載主要包含短查詢，則 Pool 將是有益的。


# [Isolation Levels(transaction的隔離機制種類)](https://medium.com/getamis/database-transaction-isolation-a1e448a7736e)
* (決定多個transaction共存的演算法)
* 事務隔離級別越高,安全性越good,but是並發就越bad
* 用這個指令`SET SESSION transaction_isolation='SERIALIZABLE';`
* [Weak Isolation](https://zhuanlan.zhihu.com/p/64576887)

|隔離級別\副作用 | Dirty Write髒寫 | Dirty Read髒讀 | Non-Repeatable Read | Phantom Read幻影讀 |適用場景|
|---|---|---|---|---|---|
|None|O|O|O|O||
|RU(Read Uncommited)|X|O|O|O||
|RC(Read Commited(Non-repeatable read))|X|X|O|O|OLTP|
|RR(Repeatable Read)|X|X|X|O|不太適合一般的OLTP,而更適合統計查詢報表類需求|
|Serializable|X|X|X|X||

* 以下這些糟糕的情況都是`儘管有用transaction`還是會發生(適用場景待思考)
* `Non-Repeatable Read`:在一次transaction中，當一行數據獲取2遍得到不同的結果
* `Dirty Read`:如果一個 transaction 還沒 commit，但是你卻讀得到已經更新的結果
* `Phantom Reads`:當在同一個 transaction 連續2次讀取時，讀取出來的筆數跟上次不同

# Serializable (一種Isolation Levels,最安全的)
* 資料庫引擎必須要能在2個以上的交易同時進行時，自動決定能將兩個交易都順利完成的排程順序，
這個排程演算法 (scheduling algorithm) 是交易隔離層次機制實作的其中一個部份，決定排程的動作
* 為了解決 Serialization failure: 1213 Deadlock found when trying to get lock; try restarting transaction in /var
/www/html/專案/vendor/doctrine/dbal/lib/Doctrine/DBAL/Driver/PDOStatement.php:141

# 關聯式DB ACID
* Atomicity（原子性）：一個`transaction`中的所有操作，或者全部完成，或者全部不完成，不會結束在中間某個環節。`transaction`在執行過程中發生錯誤，會被回滾（Rollback）到事務開始前的狀態，就像這個`transaction`從來沒有執行過一樣。即，事務不可分割、不可約簡。
* Consistency（一致性）：在`transaction`開始之前和事務結束以後，資料庫的完整性沒有被破壞。這表示寫入的資料必須完全符合所有的預設約束、觸發器、級聯回滾等。
* Isolation（隔離性）：資料庫允許多個並發`transaction`同時對其數據進行讀寫和修改的能力，隔離性可以防止多個`transaction`並發執行時由於交叉執行而導致數據的不一致。`transaction`隔離分為不同級別，包括讀未提交（Read uncommitted）、讀提交（read committed）、可重複讀（repeatable read）和串行化（Serializable）。
* Durability（持久性）：`transaction`處理結束後，對數據的修改就是永久的，即便系統故障也不會丟失。

# [分散式DB CAP定理](https://www.itread01.com/content/1544171826.html)
#### 三者不可得兼。`C3取2`。C它是NOSQL資料庫的理論基石。
#### 優先考慮C一致性，然後是A可用性，最後考慮P分割槽容忍
* 一致性（C）：在分散式系統中的所有資料備份，在同一時刻是否同樣的值。（等同於所有節點訪問同一份最新的資料副本）
* 可用性（A）：在叢集中一部分節點故障後，叢集整體是否還能響應客戶端的讀寫請求。（對資料更新具備高可用性）
* 分割槽容忍性（P）：以實際效果而言，分割槽相當於對通訊的時限要求。系統如果不能在時限內達成資料一致性，就意味著發生了分割槽的情況，必須就當前操作在C和A之間做出選擇。

# BASE
* `B`-asically `A`-vailable: 如同字面意思，服務基本上保持可用，client的請求一定會得到結果。( CAP 的A一樣的概念)
* `S`-oft State: 系統中元件儲存的資料可能會隨時間改變即使沒有client發送請求，搭配下面的原因。
* `E`-ventual consistency: 這裡抽換掉了ACID的Consistency的概念，已經開始偏向CAP的Consistency。元件可能因為斷線，使得目前資料不是最新的，* client也可能讀取到舊的資料。但是最終一段時間過後，所有元件會更新成最新的資料，client再次讀取就會取得最新的資料。這種Consistency從而交換到了一定程度的Availability。

# [NoSQL設計準則](https://blog.toright.com/posts/4483/mongodb-schema-%E8%A8%AD%E8%A8%88%E6%8C%87%E5%8D%97.html)

# [Facade Pattern (外觀模式)](http://blog.turn.tw/?page_id=875)
* 感覺重點是`單一入口`
* laravel用一個類別的靜態函式,包裝呼叫物件的函式(可讓你少打很多字)
* 用 `::method` 取代 `new $obj() + $obj->method()`

# process manager
* php-fpm 管理 php process
* pm2 管理 NodeJS process

# php-fpm , fastCGI ,php-CGI , CGI
* php-fpm: 管理`多個fastCGI`的`process管理器`(性能好)
* fastCGI: process常駐型,常駐在`RAM`所以性能比較好
* PHP-CGI :就是PHP實現的自帶的FastCGI的管理器(性能差)
* CGI: process需要開開關關的,怕大規模併發

# CGI
* (process需要開開關關的(`fork-and-execute模式`),怕大規模併發)

```
cgi就是專門用來和web服務器打交道的.
	
if(web服務器 收到 用戶request){
	cgi程序(用戶request);	//cgi程序(php的fastcgi)
}
	
根據request提交的參數應處理（解析php），
然後 輸出標準的HTML語句 返回給 web服務器，
再response給client，這就是普通的CGI的工作原理。
```

# FastCGI
* process常駐型,常駐在`RAM`所以性能比較好

# [php-cgi + cgi VS php-fpm + fastCGI](https://www.awaimai.com/371.html)
* CGI來說，每個request,PHP都必須重新解析php.ini文件，重新載入全部extension，並重新初始化全部數據結構。
* FastCGI，所有這些都只在process啟動時發生一次。一個額外的好處 是，持續DB連接（持久性數據庫連接）可以工作。
* 由於FastCGI是`多process`，所以比CGI`多thread`消耗更多的RAM，PHP-CGI解釋器每進程消耗7至25兆RAM，將這個數字乘以50或100就是很大的RAM數。

# node.js
* 是`單thread`。好處就是
1. 簡單
2. 高性能，避免了頻繁的thread切換(contextSwitch)開銷
3. 占用資源小，因為是單thread，在大負荷情況下，對ram占用仍然很低
4. 單thread安全，沒有加鎖、解鎖、死鎖這些問題

* 壞處就是

```
如何解決高並發？
node使用`async IO(異步IO)`和`事件驅動`（callback函數）來解決這個問題。

一般來說，高並發解決方案會提供`多thread`模型，為每個業務邏輯提供一個thread，通過contextSwitch來來彌補同步I/O調用的時間開銷。  
像apache，是一個request一個thread。

而node.js使用的是`單thread`模型，對所有I/O都採用`async異步`的請求方式，避免頻繁的contextSwitch，  
在node.js執行的時候維護著一個`事件queue`；程序在執行時進入事件循環等待下一個事件到來，每個異步I/O請求完成後都會被推送到`事件queue中的等待執行。
```

# [php-pm(ppm)](https://github.com/php-pm/php-pm) 
* 感覺比php-fpm + nginx 厲害的東西
* 好像是基於socket IPC的

# php ob函式

# php gc

# php opcache
* [link1](https://blog.51cto.com/liuqunying/1950277)
* [link2](https://xueyuanjun.com/post/7326)
* [link3](https://learnku.com/articles/19088)

# PHP flush
* ob_flush是把在PHP緩衝區(output_buffer)(假設有打開)的東西輸出，但並不是立刻輸出到螢幕上
* flush則是把非PHP緩衝區，伺服器上準備輸出的資料輸出到瀏覽器上"顯示出來"

# serverless
* AWS Lambda就是
  * 早期的網頁程式是整個包成一包，而將我們寫好的這一包程式，放在網頁上後去執行；  
  * 但Serverless的情況是，，最小的單位稱為Function，每一個Function，負責一段商業邏輯。
```
ex:
假設我們的網站有100個功能，早期會將這100個功能包成一包，放到一台server上，
但Serverless的情況變成，我們要分別將100個功能，分成100包檔案，佈署到100個Lambda Server上
```

# 二元樹的遍歷Binary Tree Traversal
![](https://github.com/zero85258/MyNOTE/blob/master/img/BFS-and-DFS.png)

* DFS  (深度優先)
  * Preorder Traversal 前序遍歷(Root排在前面)  
理論上的遍歷順序是Root、L子樹、R子樹。  
即是Depth-first Search。  

  * Inorder Traversal 中序遍歷(Root排在中間)  
理論上的遍歷順序是：L子樹、Root、R子樹。  
實際上是採用Depth-first Search，只不過更動了節點的輸出順序。  

  * Postorder Traversal 後序遍歷(Root排在後面)  
理論上的遍歷順序是：L子樹、R子樹、Root。  
實際上是採用Depth-first Search，只不過更動了節點的輸出順序。  

* BFS  (廣度優先)
  * Level-order Traversal 層序遍歷
即是Breath-first Search。
遍歷順序，理論上總共四種 ── 但是事實上還是只有  

# JWT
* 是一種認證協議 (安全標準)
JWT提供了一種用於發佈接入令牌（Access Token),並對發佈的簽名接入令牌進行驗證的方法。  
令牌（Token）本身包含了一系列聲明，應用進程可以根據這些聲明限制用户對資源的訪問。

```
//基本思路就是
client提供username和password給`認證server`，
server驗證用户提交信息信息的合法性；

if(驗證成功){
	會產生並返回一個`Token令牌`
	client可以使用這個`Token令牌`訪問服務器上受保護的資源。
}

* JWT token(string) == Header(令牌類型,簽名算法) + ayload(基本信息) + signature(為了保證JWT沒被修改過)

```
* `服務`本身會存有jwt_secret(非storage layer),所以不會翻資料庫,從而造成loading


# OAuth2
* 是一種授權框架，提供了一套詳細的授權機制（指導）。
* `用户`OR`應用`可以通過公開的或私有的設置，`授權`第三方應用訪問特定資源。

```sh
它詳細描述了系統中不同角色、用户、服務前端應用（比如API），以及客户端（比如網站或移動App）之間怎麼實現相互認證。
```


# Linux程序呼叫(fork-and-exec流程)  
程序都會藉由 `父process` 以複製 (fork) 的方式產生一個一模一樣的`子process`，  
then 被複製出來的`子process`再以 exec 的方式來執行實際要進行的程式，  
最終就成為一個`子process`的存在。


# OKR(Google服務)
除了KPI以外另外的績效相關制度


# AWS RI(`Reserved Instances預留執行個體`)
* 預定機器會使用一年,有點像綁約,比較便宜

# CPU 時間片
* 時間片`timeslice`  == 處理器片`processor slice`
* 從process開始執行 ~ 被搶占的時間

# 監督式 非監督式(機器學習)

# [目錄結構 /var/run](https://www.jb51.net/article/137999.htm)

# `敏捷式` & `瀑布式` 開發
* 心法是以流程為主軸，正式名稱`瀑布式開發（Waterfall）`，最具代表的武功就是CMMI，
* 心法是以人為主軸，正式名稱為`敏捷式開發（Agile）`，最知名的武功是Scrum。
* Lean UX

# LLVM && CLang && GCC (編譯器框架)
* LLVM == low level virtual machine的簡稱，其實是一個編譯器框架

# CMAKE
```
CMake是一種跨平台編譯工具，比make更為高級，使用起來要方便得多。 
CMake主要是編寫CMakeLists.txt文件，
然後用cmake命令將CMakeLists.txt文件轉化為make所需要的makefile文件，
最後用make命令編譯源碼生成可執行程序或共享庫
```

# Conan, VcPkg Build2? （c++ packageManager
* cmake關係?

# C++ 2020
![](https://github.com/zero85258/MyNOTE/blob/master/img/c%2B%2B2020.png)

# 語言虛擬機
* [為什麼需要 JVM](https://openhome.cc/Gossip/JavaEssence/WhyJVM.html)
* [HHVM](http://wuduoyi.com/note/hhvm/)

# SSR(Server Side Rendering。)
```
小明的想法是這樣的，既然問題出在「第一次渲染」，那我們只要在第一次渲染的時候把該輸出的資料都輸出就好啦，對使用者來說還是一個SPA，差別在於使用者接收到HTML的時候，就已經有完整的資料了。
舉例來說，假設使用者拜訪顯示所有留言的頁面，我在Server Side先把所有留言都準備好然後render出來，這樣使用者一收到Response的時候就能夠看到所有留言，搜尋引擎也能順利地爬到。
而後續的操作還是由JavaScript來處理，依舊能保持SPA的優點。或者我們能用一句話來總結：
第一個頁面由Server side render，之後的操作還是由Client side render
```
* 可以查Nuxt.js dashborad直接把玩

# Scala(語言)
* spark生態圈
* java強化版？？
* 語法簡潔,代碼量少

# 虛擬記憶體
* 通常會被分成
* User space，使用者空間 (又譯為用戶空間)
* Kernel space 核心空間

# Hive,HBase (可用來取代傳統ETL)
### Hive(有點像是hdfs的Mysql???)
* `操作上來說`就是對HDFS底下的檔案進行sql操作
* `底層上來說`hive可以認為是map-reduce的一個包裝。hive的意義就是把好寫的hive的sql轉換為複雜難寫的map-reduce程式。 
* 那麼,hive是什麼?  Hive 中包含以下数据模型：表(Table)，外部表(External Table)，分区(Partition)，桶(Bucket)
* 可用來取代傳統ETL
### HBase(有點像是hdfs的Mongo???)
* [常用指令](https://tsai-cookie.blogspot.com/2015/09/learning-hbase-shell.html?fbclid=IwAR2y_VIcmRPNCf-Kg1v-aSjFJ2g-mtWad4vV03Gs74x7O7LF5SBGFV0BQY8)
* Realtime!!!
* 適用 億row * 百萬column 
* 同樣白話一點加不嚴格一點,hbase可以認為是hdfs的一個包裝。他的本質是資料儲存,是個NoSql資料庫;hbase部署於hdfs之上,並且克服了hdfs在隨機讀寫方面的缺點。 

# MapReduce(一種軟體架構)
* 用於大規模資料集（大於1TB）的並列運算。概念「Map（對映）」和「Reduce（歸納）
* 主要思想，都是從`函數語言程式設計語言`借來的，還有從`向量程式語言`借來的特性
* [實作上分很細很美的架構](https://blog.alantsai.net/posts/2017/12/data-science-series-09-hadoop-map-reduce-java-wordcount-example)
* INPUT | split(分給多個cluster) | map | combine | shuffle & sort | reduce | OUTPUT

# HDFS(一種文件系統)
* HDFS是一個主/從（Master/Slave）體系架構，
* 由於分布式存儲的性質，集群擁有兩類節點NameNode和DataNode
* NameNode（名字節點）：系統中通常只有一個，中心伺服器的角色，管理存儲和檢索多個DataNode的實際數據所需的所有元數據。
* DataNode（數據節點）：系統中通常有多個，是文件系統中真正存儲數據的地方，在NameNode統一調度下進行數據塊的創建、刪除和複製。

* HDFS文件系統可存儲超大文件G、T、P級別
* 一次寫入，多次讀取(一個文件經過創建、寫入和關閉之後就不需要改變，這個假設簡化了數據一致性的問題，同時提高數據訪問的吞吐量。)
* 運行在普通廉價的機器上

# 元數據(就是是用來描述數據的數據)
```
年齡（三十歲上下），身高（個子高挑），相貌（身材勻稱，黑黑的眉毛，紅紅的臉蛋）
“年齡”，“身高”，“相貌”，就是元數據
```

# 資料分析技術演進
* SMACK架構
[資料分析技術演進](https://www.ithome.com.tw/news/103278)

# RDD
* RDD是一種可跨群集（cluster）被使用、可儲存於主記憶體中的immutable的物件集合。
* 這裡所謂的immutable物件，乃是指在被產生之後，其狀態便無法被修改的物件。
* 在Spark當中有點像是對 RDD集合 進行各種 map,filter,reduce的函數式編成運算
### RDD可施加2類型的操作
* `轉換Transformation`，其操作結果為新的RDD，意即其作用在於將RDD再轉換生成另一個RDD。
* `動作Action`，則是在RDD之上進行計算之後，將其結果返回 Spark 的驅動程序，或寫至檔案系統。


# LINQ查詢表達式(有點像對陣列下SQL)
```c#
int[] numbers = { 7, 3, 2, 1, 9, 8, 41, 3, 2, 1 };

//LINQ查詢表達式
var result = from num in numbers
		where num < 7
		orderby num ascending
		select num;
			
//顯示查詢結果
foreach (var e in result) {
	Console.WriteLine(e.ToString());
}
```

# 導覽器繪圖
* canvas(基於像素,本身就是個`畫布`)
* svg(基於物件模型,多個圖形元素)

# Volume
* Volume 是具有單個`fs文件系統`的單個可訪問存儲區域

# Mirror鏡像 (鏡像下載, 鏡像站
* 一種含義是指 增強`資料整合度`、`容錯`、`吞吐量`等作用（如RAID）, 複製到相同功能的儲存裝置中以起到
* 一種含義是指 `資料備份`, 複製到不同的device或資料格式，主要用於資料備份。

# 虛擬檔案系統 (Virtual File System, VFS)
* 就是多種FileSystem的Adapter

# IPFS
* 是一個分佈式文件系統
* 挖礦常用

# `btrfs`可snapshot <===> `xfs`速度快  (`安全`跟`快`的取捨)

# LVM (Logical Volume Manager)
![](https://github.com/zero85258/MyNOTE/blob/master/img/lvm.jpg)

是一種可以動態變更 捲volume (由 LVM 所切割出來的空間被稱為 volume)大小的`方式`,  
可以讓你能更容易利用管理你的硬碟.  

如果磁區空間不夠了,你可以隨意將空間放大 or 磁區的使用率太低也可以將空間縮小.  
when我們在放大縮小時這都不影響原先在硬碟上的資料.  
輸入輸出流，這裡包括網絡請求、文件處理、db操作等；  

傳統的硬碟空間在切割完時就決定了大小,如果要重新規劃必須將資料先備份下來,硬碟磁區重新切割才可能有改變原來的硬碟磁區環境.  
不過 LVM(Logical Volume Manager) 就不同了,

```sh
# 不知VG可否看成PV跟LV之間 邏輯上的解藕
LVM == []VG
PE物理區域 --[]同樣大小組成--> PV物理卷 --[]組成--> VG卷組 --分配成--> LV邏輯卷 --分配成--> LE邏輯區域

PV == []PE
VG == []PV

LV == []LE
```

* PV物理卷(physical volume)：this在LVM最底層，可為整個`物理硬盤Disk`或`硬盤分區Partition`。
* VG卷組(volume group)：this建立在物理卷上，一卷組中至少要包括一物理卷，this建立後可動態的添加捲到this中，一個LVM工程中可有多個this。
* LV邏輯卷(logical volume)：this建立在卷組基礎上，卷組中未分配空間可用於建立新的this，this建立後可以動態擴展和縮小空間(這層比較像是`fs`)。
* PE物理區域(physical extent)：this是物理卷中可用於分配的最小存儲單元，this大小在建立卷組時指定，一旦確定不能更改，同一卷組所有物理卷的物理區域大小需一致，新的pv加入到vg後，pe的大小自動更改為vg中定義的pe大小。
* LE邏輯區域(logical extent)：this是邏輯卷中可用於分配的最小存儲單元，this的大小取決於邏輯卷所在卷組中的物理區域的大小。
卷組描述區域：卷組描述區域存在於每個物理卷中，用於描述物理卷本身、物理卷所屬卷組、卷組中邏輯卷、邏輯卷中物理區域的分配等所有信息，它是在使用pvcreate建立物理卷時建立的。

```sh
pvcreate /dev/vdb2
pvmove /dev/vdb2
vgdisplay vgGroupName
vgextend vgGroupName /dev/vdb2
vgreduce 

# lv ~= fs
lvextend -l +128M

# fsextend
xfs_growfs /mnt/hercules
```

# 軟體定義儲存
### Ceph核心元件
* `Monitor`:一個Ceph叢集需要[]Monitor組成的小叢集，它們通過Paxos同步資料，用來儲存OSD的元資料。
* `OSD`:OSD全稱Object Storage Device，也就是負責reponse客戶端request返回具體資料的程序。一個Ceph叢集一般都有[]OSD。
* `MDS`:MDS全稱Ceph Metadata Server，是CephFS服務依賴的元資料服務。
* `Object`:Ceph最底層的儲存單元是Object物件，每個Object包含元資料和原始資料。
* `PG`:PG全稱Placement Grouops，是一個邏輯的概念，一個PG包含[]OSD。引入PG這一層其實是為了更好的分配資料和定位資料。
* `RADOS`:RADOS全稱Reliable Autonomic Distributed Object Store，是Ceph叢集的精華，使用者實現資料分配、Failover等叢集操作。
* `Libradio`:Librados是Rados提供庫，因為RADOS是協議很難直接訪問，因此上層的RBD、RGW和CephFS都是通過librados訪問的，目前提供PHP、Ruby、Java、Python、C和C++支援。
* `CRUSH`:CRUSH是Ceph使用的資料分佈演算法，類似一致性雜湊，讓資料分配到預期的地方。
* `RBD`:RBD全稱RADOS block device，是Ceph對外提供的塊裝置服務。
* `RGW`:RGW全稱RADOS gateway，是Ceph對外提供的物件儲存服務，介面與S3和Swift相容。
* `CephFS`:CephFS全稱Ceph File System，是Ceph對外提供的檔案系統服務。

# RAID
* 0快1安全
* 特別是企業最常用的1+0或0+1
* 5安全跟快中間

# NFS(是`協定`,不是`fs`)
```sh
mount -t nfs -o sync serverX:/share /mountPoint
autofs # 自動掛載fs的服務
```

# CIFS(就是SMB)
* 常被使用於以 Windows PC 為主的區域網路內， 例如公司內部的檔案分享伺服器。


# [OLAP](https://www.ithome.com.tw/node/44569)
* ROLAP
* MOLAP
* Hybrid OLAP == ROLAP + MOLAP

# statless 無狀態
* 在Server端並沒有特別去紀錄Client端上一個送出的request內容(所以才需要cookie 或是 session解套)
 
```
舉例來說，
我在Yahoo首頁點下新聞，進入Yahoo新聞的頁面，
跟我直接在url列中打上http://tw.news.yahoo.com/取得的結果是一樣的，

我想要看Yahoo新聞不見得要經過進入Yahoo首頁(http://tw.yahoo.com/)的動作，
也就是說我可不可以看Yahoo新聞只跟我有沒有連到http://tw.news.yahoo.com/這個網址有關，
而與我前面的步驟無關，這種情況，我們稱之為Stateless。 
```

* 有狀態就是有資料儲存功能。有狀態物件(Stateful Bean)，就是有例項變數的物件 ，可以儲存資料，是非執行緒安全的。在不同方法呼叫間不保留任何狀態。
* 無狀態就是一次操作，不能儲存資料。無狀態物件(Stateless Bean)，就是沒有例項變數的物件 .不能儲存資料，是不變類，是執行緒安全的。


# [用戶代理(User-Agent) <-> 源伺服器Origin-Server](https://read01.com/G0z5.html)
* 表明瀏覽用戶的身份
![](https://github.com/zero85258/MyNOTE/blob/master/img/user-agent%26origin-server.png)

```sh
是用來表明瀏覽用戶的身份，讓網頁開發者可以得知訪問終端的信息。
根據不同的終端發送不同的顯示內容，例如桌面版和移動版發送不同的網頁內容以適應螢幕和OS的差別（即響應式網頁的理解）,
或者是因為不同的瀏覽器支持的標準不一樣,這樣做的目的當然是為了避免瀏覽器不支持的功能以及獲得更好的用戶體驗。

# 這就是User-Agent(常在http header裡看到的)
User-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36
```

# 加鹽
```
的指是在要加密的字串中加特定的字符，
打亂原始的字符串，使其生成的散列結果產生變化，
其參數越高加鹽次數多越安全相對的加密時間就越長。
```


# [負載平衡LB](https://blog.toright.com/posts/3967/%E5%AF%8C%E4%BA%BA%E7%94%A8-l4-switch%EF%BC%8C%E7%AA%AE%E4%BA%BA%E7%94%A8-linux-haproxy%EF%BC%81.html)
* 負載平衡:分配請求
* [各種比較方案](https://kknews.cc/zh-tw/tech/r5lemr.html)
```
雲端方案 ELB
實體硬體方案 L4/L7 Switch 差不多要準備個 100W，設定也相當複雜。
窮人方案 HAProxy/Nginx
```
* 有`輪詢WRR`,`權重`,`hash`等等分配

# binary-Tree 與 B-Tree 與 B+Tree 的 diff

# 序列化 與 RPC  
[ProtoBuf(IDL)與gRPC](https://yeasy.gitbooks.io/blockchain_guide/content/appendix/grpc.html)

# Protobuf格式(like json格式,xml格式)
```proto
message Person
{
    required string name = 1;
    required int32 id = 2;
    optional string email = 3;

    enum PhoneType
    {
        MOBILE = 0;
        HOME = 1;
        WORK = 2;
    }

    message PhoneNumber
    {
        required string number = 1;
        optional PhoneType type = 2 [default = HOME];
    }

    repeated PhoneNumber phone = 4;
}
```

# telnet(是種協議)
* 好像已經被ssh取代了

# 生產者/消費者 Producer-Consumer problem
* 解決 `生產者`不會在緩衝區滿時加入數據，`消費者`也不會在緩衝區中空時消耗數據  (前後2者皆會引發程式錯誤,過度耦合,所以要`解耦`)
* `易擴充`
* PUB/SUB(發佈/訂閱) == 觀察者模式

# AMQP(一種協議)
* [RabbitMQ](https://www.imooc.com/video/17844)就要用`AMQP協議`來溝通,所以laravel要裝amqp的driver
* [methods](https://www.rabbitmq.com/amqp-0-9-1-quickref.html)
* 在異步通訊中，`消息`不會立刻到達接收方，而是被存放到一個`消息隊列`中，
* 當滿足一定的條件之後，`消息`會被`消息隊列`發送給接收方
* 而完成這個功能需要雙方和`消息隊列`以及其中的各個組件遵守統一的約定和規則

# 消息佇列
* `AMQP`一種協議
* `RabbitMQ` 是messQueue
* `Beantalk`,`SQS` 是taskQueue
* 解決 多system、異構系統間的 `數據交換`,`消息通知`,`通訊`

```sh
1共10則消息,有A,B 兩人

# Queue(隊列消息) 
2人共收到10則

# Topic(主題消息) 
* 2人都收到10則 (廣播)
```

### 架構
![rabbitMQ](https://github.com/zero85258/MyNOTE/blob/master/img/rabbitMQ.png)

```
broker == []vhost
Connection == []Channel
```

* Broker:它提供一種傳輸服務,它的角色就是維護`一條`從`生產者`到`消費者`的路線，保證數據能按照指定的方式進行傳輸, 
* vhost:虛擬主機,，用作不同用户的權限分離。 
---
* Exchange：消息交換機,它指定消息按什麼規則,路由到哪個隊列。 
* Binding:綁定，它的作用就是把exchange和queue按照路由規則綁定起來. 
* Routing Key:路由關鍵字,exchange根據這個關鍵字進行消息投遞。
* Queue:消息的載體,每個消息都會被投到`1個`or`n個`隊列。  
---
* Producer:消息生產者,就是投遞消息的process. 
* Consumer:消息消費者,就是接受消息的process. 
---
* Connection:客户端連接,底下有多個Channel
* Channel:消息信道,Consumer是從this取Message


# TaskQueue Vs MessageQueue (異步`任務`載體 Vs 異步`通訊`載體)
* 兩者都有`延遲defer處理`的目的
* 兩者的`Queue資訊`都可用 beanstalk,redis,mysql,file之類的`載體+機制`儲存,
* 冪等性 靠`Qos`
* 一致性 靠`Acknowledge request`

```sh
Subscriber 在處理完 message 後，
會依照 messageId發送 acknowledge request 給 Pub/Sub，
以確定訊息已經處理完成。
當 Pub/Sub 收到某一 message id 的 acknowledge request 後，會將此 message 從 Pub/Sub 中刪除。
```

# TaskQueue
* 感覺`TaskQueue`是`指派清單`的隊列,調度工作來給`單/多`個`worker`處理,感覺是處理`併發process`
* task優先級
* laravel的jobQueue算是 `工作清單queue` + `載體讀寫機制` 的組合 ,搭配`supervisord`(processManager)達成 `process併發方案`

# MessageQueue
* 感覺`MessageQueue`可以`變相取代`系統`內部API溝通`的方式,`溝通資訊`上的排隊,
* 大型分散式系統 為了 `分散式事務` 需要用MQ維持一致性

```sh
為什麼要用
切合前一部分猜測的MQ產生背景，其主要解決兩個問題：

系統解耦：專案開始時，無法確定最終需求，不同程序間，新增一層，實現解耦，方便今後的擴充套件。
訊息快取：系統中，不同程序處理訊息速度不同，MQ，可以實現不同Process之間的緩衝，即，寫入MQ的速度可以儘可能地快，而處理訊息的速度可以適當調整（或快、或慢）。


# 下面針對系統解耦、訊息快取兩點，來分析實際應用訊息佇列過程中，可能遇到的問題。
# 虛擬場景：Process_A通過訊息佇列MQ_1向Process_B傳遞訊息，幾個問題：

針對MQ_1中一條訊息message_1，如何確保Process_B從MQ_1中只取一次message_1，不會重複多次取出message_1？
如果MQ_1中message_1已經被Process_B取出，正在處理的關鍵時刻，Process_B崩潰了，哭啊，我的問題是，如果重啟Process_B，是否會丟失message_1？
不要著急，閱讀了下面的簡要介紹後，水到渠成，上面幾個問題就可以解決了。 MQ有如下幾個好處，這大都是由其系統解耦和訊息快取兩點擴充套件而來的：

提升系統可靠性：
冗餘：Process_B崩潰之後，資料並不會丟失，因為MQ多采用put-get-delete模式，即，僅當確認message被完成處理之後，才從MQ中移除message；
可恢復：MQ實現解耦，部分程序崩潰，不會拖累整個系統癱瘓，例，Process_B崩潰之後，Process_A仍可向MQ中新增message，並等待Process_B恢復；
可伸縮：有較強的峰值處理能力，通常應用會有突發的訪問流量上升情況，使用足夠的硬體資源時刻待命，空閒時刻較長，資源浪費，而訊息佇列卻能夠平滑峰值流量，緩解系統元件的峰值壓力；
提升系統可擴充套件性：
調整模組：由於實現解耦，可以很容易調整，訊息入隊速率、訊息處理速率、增加新的Process；
```

```
其他：
單次送達：保證MQ中一個message被處理一次，並且只被處理一次。本質：get獲取一個message後，這一message即被預定，同一程序不會再次獲取這一message；當且僅當程序處理完這一message後，MQ中會delete這個message。否則，過一段時間後，這一message自動解除被預訂狀態，程序能夠重新預定這個message；
排序保證：即，滿足佇列的FIFO，先入先出策略；
非同步通訊：很多場景下，不會立即處理訊息，這是，可以在MQ中儲存message，並在某一時刻再進行處理；
資料流的階段效能定位：獲取使用者某一操作的各個階段（通過message來標識），捕獲不同階段的耗時，可用於定位系統瓶頸。
```

# [發佈者/訂閱者模式 Pub/Sub](https://blog.csdn.net/u010687392/article/details/50593815)
```
關於這個模式，其實是生產者/消費者模式的變體，
這種模式並不需要存儲中介，而是通過一個DataSource空殼來包裝數據，對於發布者提交了一個Task後，
將立即返回一個DataSource ，對於任務執行完後的結果，
如果你想獲取則必須通過datasource.subscribe(new XxxSubscriber(…))來訂閱獲取執行後的結果，
而如果不通過數據源訂閱的方式來獲取而直接通過datasource. getData()獲取則返回null，
因為DataSource只是一個獲取數據的空殼。這種模式在Fresco源碼中有很好的體現，用了大量的這種模式。
```

# 背壓現象 back-pressure
* 響應式RX場景，上游Pub速度大於下游Sub速度，導致下游的 Buffer 溢位

# stomp 協定
* 除了java其他語言要跟ActiveMQ(J派)溝通就得靠這個協定

# CEF(chrome embedded framework)
```
CEF(嵌入式Chromium框架)是C/C++開發的庫
目前 Google Chrome（Google瀏覽器），
Chromium瀏覽器，Opera等都是基於CEF為核心，Webkit引擎的瀏覽器。
```

# CPU指令流水線
* [CPU指令流水線](https://blog.csdn.net/maimang1001/article/details/7566763) 再多行指令的時候才有加速的效果

# 單核,多核
```
指令是在 CPU 的流水線上執行的，而流水線有多級，各級同時執行不同的指令，也就是說我們的代碼在單核 CPU 上也是在並行執行，只不過這是指令級並行。

CPU 廠商，為了減少等待從緩存讀取數據的時間，也是不遺餘力，做了很多優化，比如說：分支預測,亂序執行。
前段時間刷屏的 Spectre 和 Meltdown 漏洞，同樣與 分支預測() and 亂序執行() 有著直接的因果關係。

當然，前面提到的這些，在單核 (single-processor) 運行的時候，都不會造成一致性問題，廠商已經在 CPU 層面替我們處理好了這些。

多核
單核的一致性問題，CPU 幫我們解決了，那多核 (multiple-processor) 呢？

這裡我們需要了解，CPU 的每個核心都有獨立的 L1、L2 緩存（cache），為了提高性能，多數情況下 CPU 讀數據是讀的緩存，而不是 主存 (RAM)。 
Intel 為了解決這些緩存間的同步問題，在 cache 上實現了 MESIF 協議，來保證緩存的同步，即：在一處修改緩存後，其它緩存的狀態會跟著改變。

但 MESIF 只解決了緩存的空間一致性問題，並沒有解決時間一致性問題。之前提到的分支預測和亂序執行在多核的情況下，會導致代碼出錯
```

# 反應器模式 Reactor pattern
* NodeJS eventDrive 就算是 extend 這個模式

# Reactive Programming 響應式編程
* [常用函數的命名概念](https://blog.miniasp.com/post/2018/09/06/Clarify-some-confused-RxJS-operators)
* 當變數或資源發生變動時，由變數或資源自動告訴我發生變動了
* RX想做的事情就是將 `異步調用()` 與 `事件調用()` 抽象出來。
```
通過一系列的接口讓這些調用變的更加的易於編寫與使用。
因此一些專家找到了一組合理的抽象API與模式，將他們制定成RX規範供我們使用。
從而降低我們的異步與事件編程的重複勞動，
```
* `RxJS` ,`RxPY` 就有點算是`Functional Programming` 及 `Reactive Programming`混合 

```js
rxjs.fromEvent(document, 'click')
  .pipe(rxjs.operators.scan(count => count + 1, 0))
  .subscribe(count => console.log(`Clicked ${count} times`));
```

# 響應式Rest API
```
異步無阻塞。響應式編程極大的為寫異步和無阻塞應用程序提升了靈活性。
事件、消息驅動。系統可以對應活動產生相呼應的事件或者消息。打個比方，來自數據庫的就會被看作事件流。
支持背壓。通過背壓，我們可以避免拒絕服務的出現，因為它可以很方便的處理掉一個系統到另一個系統的壓力。
應用響應的時間可以預測。由於線程屬於異步非阻塞，所以對於負載下應用的響應時間可以做到比較詳細的預測。
系統資源利用率高。它可以支持更多的用戶請求，因為其線路異步且非阻塞，因此各種線程不會被I/O所佔用，其係統資源利用率就更高。
基於負載的擴容方式。
脫離基於請求的線程。借助於異步線程，基於請求的線程模型限制就可以得到脫離，因為模型會和服務器同時創建事件，並通過請求線程，處理其他請求。
```

# 編程種類
* `命令式編程Imperative`：詳細的命令機器`怎麼How`去處理一件事情以達到你想要的`結果What`；(DAG+pipeline)
```
最一般寫的php,js,java......
```
* `聲明式編程Declarative`：只告訴你想要的`結果What`，機器自己摸索過程`怎麼How`(直接描述東西長相)
```
SQL,dsl,regex,html,verilog
```

# [Observable](https://ithelp.ithome.com.tw/articles/10186832) Pattern
* Observable ==  Observer Pattern(Producer/Pub Event) + Iterator Pattern(Consumer/Sub Event)
* pipe 算是組成的一部分
* Rx系列的pkg都算是這個的實作

# [分散式系統必知](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/73502/)
* `一致性`:分散式環境中的一致性是指資料在多個`副本`之間是否能夠保持一致的特性。
* `可用性`:是指系統必須一致處於可用的狀態，對用使用者的請求能夠在有限時間內返回結果。其中，“有限時間”是相對的，是使用者可接受的合理響應時間；“返回結果”是期望的結果，可以是成功或失敗，不能是使用者不能接受的結果。

# [鎖](http://hyuga.top/2018/08/27/lock-about/)
* 併發編程 鎖 是指鎖什麼?process?變數?檔案?
### 公平鎖、非公平鎖(Fairness公平性)
* 公平鎖(Fair)：加鎖前檢查is有排隊等待的thread，優先排隊等待的thread，先來先得。
* 非公平鎖(Nonfair)：加鎖時不考慮排隊等待問題，直接嘗試讀取鎖，if讀取不到then動到隊尾等待。
* 正常模式下的互斥锁能够提供更好地性能
* (饥饿模式 搶不到的排隊 避免 Goroutine 由于陷入等待无法获取锁而造成的高尾延时)
### Mutex互斥鎖、Semaphore號誌、讀寫鎖
* `Mutex互斥鎖`：是一件`可容納1人的房間`,一個人拿了就可進入一個房間，出來的時候把鑰匙交給隊列的第一個。一般的用法是用於串行化對critical section代碼的訪問，保證這段代碼不會被並行的運行。指的是一次最多只能有`1個線程持有`的鎖
* `Semaphore號誌`：是一件`可容納N人的房間`，如果人不滿就可以進去，如果人滿了，就要等待有人出來。對於N=1的情況，稱為binary semaphore。一般的用法是，用於限制對於某一資源的同時訪問。
* 讀寫鎖：ReadWriteLock接口及其實現類ReentrantReadWriteLock，默認情況下也是非公平鎖。分了2種情況，`一種是讀時的鎖，一種是寫時的鎖`
```go
# go
# 允許多個隻讀操作併行執行，但寫操作會完全互斥
sync.RWMutex
```
### 悲觀鎖PessimisticLock、樂觀鎖OptimisticLock(加鎖機制)
* `悲觀鎖PessimisticLock`，顧名思義，就是很悲觀，每次去拿數據的時候都認為別人會修改，所以`每次在拿數據的時候都會上鎖`，這樣別人想拿這個數據就會block直到它拿到鎖。(ex:Java synchronized)
* `樂觀鎖OptimisticLock`，顧名思義，就是很樂觀，每次去拿數據的時候都認為別人不會修改，所以不會上鎖，但是`在提交更新的時候會判斷一下在此期間別人有沒有去更新這個數據`。樂觀鎖適用於讀多寫少的應用場景，這樣可以提高吞吐量。
### MySQL中的行級鎖、表級鎖、頁級鎖(鎖粒度)

### 共享鎖、排它鎖(兼容性)
* 共享鎖 允許`不同事務`之前共享加鎖讀取，但`不允許其它事務修改`或者`加入排他鎖` 如果有修改必須等待一個事務提交完成，才可以執行，容易出現死鎖

### 自旋鎖
```
自旋鎖是指當一個thread在獲取鎖的時候，如果鎖已經被其他thread獲取，那麼該thread將poll等待，
然後不斷地判斷是否能夠被成功獲取，知直到獲取到鎖才會退出循環。
```
![](https://github.com/zero85258/MyNOTE/blob/master/img/lock.jpg)

# Heap 堆積(一種tree,child都比parent大)
* 常用於 找出一群資料的最大或是最小元素 

# JVM 記憶體管理
* JVM 記憶體的 Stack 和 Heap 絕對不要和其他同名的東西搞混，在這裡是做為 JVM `儲存資料`或`儲存指令`的區域，和其他同名的東西無關，請把它當作平行宇宙看待。

# Cassandra
* NoSQL
* 易於水平擴充

# DB Cursor 游標

```
資料指標(Data Cursor) 或稱游標，是在資料庫引擎 (Database Engine)中，
讓開發人員或資料庫管理員可以遍歷、瀏覽檢索結果的資料列(稱為資料查詢結果集, Result set)，
是主要用於在結果集中移動到某一資料列(row)的控制結構。
游標可以被看作是指向一組列中，代表某一列的指針。
游標一次只能參照一列，但可以根據需要移動到結果集的其他列。

游標有助於隨檢索之後的資料處理與遍歷相結合，如添加和刪除記錄。
它能遍歷資料查詢結果集的特性，類似於程式語言的疊代器概念。
開發程式人員通常依需求而使用游標，來處理由資料庫系統查詢返回的整個結果集。
```

# 一等公民(函數式編程,最大的權力)
```js
程序世界裡，有這麼幾種權力 = ["創建"，"賦值"，"傳遞"]
```

```
介紹函數式編程語言的書籍裡常常提到，函數是一等公民（first-class citizens）。
那麼什麼是一等公民呢？什麼又不是一等公民？

其實很多時候名字已經透露了太多的信息。有一等公民，就有二等公民，三等公民。
層級越高，權力越大。很多時候高層的人有權利做的事，下面的人就不能做。

程序世界裡，有且不僅有這麼幾種權力。創建，賦值，傳遞。

這些權力，object 都具備，function 都不具備。
對象可以通過參數傳遞到另一個對象裡，從而兩個對象可以互相通信。
函數卻不行，兩個函數想要通信，必須以對象為介質。

以 Java 舉個例子：函數a，想要調用函數b。雖然a並不關心函數b是從哪兒來的，只要函數b可以完成這個特定的功能即可。
但是在 Java 的世界裡函數必須要依附在對像上，所以函數a必須依附在對象A上，函數b必須依附在對象B上，函數a必須通過一個對象才能找到函數b(必須new之類的)
```

# [HOC(Higher-Order-Component)](https://medium.com/@max80713/react-developer-%E4%B8%8D%E5%8F%AF%E4%B8%8D%E7%9F%A5%E7%9A%84-higher-order-component-fb5028167fad)
* 是一種 function，它接收某個 Component 作為他的參數，並且回傳另外一個新的 Component。

# [協程Coroutines](http://meloguo.com/2018/11/15/%E5%8D%8F%E7%A8%8Bco%E5%92%8Casync/)
* 協程可以看做是能在 [`中途中斷`、`中途返回值給其他協程`、`中途恢復`、`中途傳入參數的函數`]
* 和一般的函數只能在起始傳入參數，不能中斷，而且最後返回值給父函數之後就結束的概念不一樣。

# [内存泄漏 & 内存溢出]()
* 內存洩漏Memory Leak：是指程序在申請內存後，`無法釋放`已申請的內存空間，`造成可用内存越来越少`，一次內存洩漏似乎不會有大的影響，但內存洩漏堆積後的後果就是內存溢出。
* 內存溢出Memory Overflow(Out Of Memory == `OOM`)：指程序申請內存時，沒有足夠的內存供申請者使用，或者說，給了你一塊存儲int類型數據的存儲空間，但是你卻存儲long類型的數據，那麼結果就是內存不夠用，此時就會報錯OOM,即所謂的內存溢出。
* exhausted 枯竭

# BI Visualization 商業智慧視覺化工具, Data Visualization 資料視覺化工具
* [python](https://www.sicara.ai/blog/2018-01-30-bokeh-dash-best-dashboard-framework-python)

# BI Report
* [ReportServer](https://hub.docker.com/r/bitnami/reportserver/)

# completion 自動完成
* git completion
* docker completion

# [tty終端設備的統稱、pty虛擬終端、pts](https://iximiuz.com/en/posts/linux-pty-what-powers-docker-attach-functionality/)

* pty == ssh到別的host介面

# daemon
在背景執行的process, 會提供某種服務, 不需要standard in/out

# [ODBC](https://ithelp.ithome.com.tw/articles/10209968)
資料庫連線的`適配器`????

# 決策支援系統（DSS）
DSS的架構以Sprague與Carlson所提出的對話-資料-模式（Dialog-Data-Modeling，DDM）架構最為學術界所接受，認為DSS有三大組件：

* 資料庫管理系統（Database Management System，DBMS）
* 模式庫管理系統（Model-base Management System，MBMS）造模語言
* 對話產生與管理系統（Dialog Generation and Management System，DGMS）# 對話系統的兩個關鍵部分，分別是自然語言理解（NLU）和對話管理（DM）
* OSS:OpenRules,[Drools](https://www.drools.org/)(有docker\m/)
* 感覺celebrus的 Semantics就有點像是DSS的[DMN](https://www.drools.org/learn/dmn.html)(從event判斷條件,做對應的curd)
* [DMN(決策模型),BPMN(業務流程模型),CMMN(案例管理模型)](https://bpmn.io/)
* [Flowable](https://medium.com/@herbertchang/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E5%BC%80%E6%BA%90%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E-flowable-f1f371e7069d) 是一個使用 Java 編寫的輕量級業務流程引擎
* [activiti](https://www.activiti.org/) 是一個使用 Java 編寫的重量級業務流程引擎

# BPM/BPMS/BPR 系統
* Object Management Group這家公司跟BPMN,CMMN,DMN,PIM這些東西好像都有關連
* 專家系統最後好像就演變成這個東西了

# 決策engine(DAG) && 規則engine(Table) 
```
實際業務流程中，有時需要由多個 決策 來決定流程走向，
而每個 決策 都要根據自身的 規則 來決定，每個決策之間也可能存在關聯。
此時就需要規則engine來提供決策支撐。在規則引擎開源產品中，Drools 是最知名的一款

CMMN 引擎適用於如下幾種場景：重複與並行的工作分發。處理帶有生命週期特徵的場景，如客戶、產品、項目、僱員。以項目為例，項目的立項、中止、收尾、交付等階段（phases），可以在 CMMN 中通過階段（Stages）概念在更高層次進行描述。
BPMN 引擎在處理順序執行、職責分工明確的工作流程時有優勢，但面對動態、自由、並行的情況時，BPMN 顯得靈活性不足，此時CMMN 則更適合應對
```

# [bpmn](https://ithelp.ithome.com.tw/articles/10211026?sc=rss.qu)
* general, gateway, event (參考draw.io)
* scenario == 感覺就是一堆event的組合
* Semantics
* Event Hub, Sensor Hub感覺也都只是bpmn概念的實踐

# WorkFlow
* [Airflow(py)](https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html#%E6%89%80%E4%BB%A5%E7%82%BA%E4%BD%95%E8%A6%81%E9%80%99-App-%EF%BC%9F)
* gui的job管理
* Azkaban(java)
* n8n(js)
* oozie(hadoop)

# Rx Epics
* 有點像是 `Observable` + `state Management`的整合物
它是函數的形式，其函數簽名如下：

```js
// 主要作用就是，
// 接收Redux中的action，
// 利用RxJS強大靈活的操作符，將action進行一些變換(如：網絡請求)，
// 最後再返回actions，注意這裡是actions，
// 也就是可能會發出多個action。
// 發出的action，將會自動調用store.dispatch()進行分發。

function (action$: Observable<Action>, store: Store): Observable<Action>;
```

# 面向切面编程AOP(編程範式) ,decorator ,wrapper ,annotation
* 就是知道一个方法被调用 。然后在被调用之前，执行自己想要的方法，在被调用之后，执行自己想要的方法。
* 面向對象側重靜態，名詞，狀態，組織，數據，載體是空間；
* 面向過程側重動態，動詞，行為，調用，算法，載體是時間；
* 常用於 登入驗證、日誌 logging(因為不會破壞原有的程式邏輯)
* Spring annotation @component,@service,@repository,@controller,@autowired`根據型別依賴注入物件`,@primary,@qualifier`根據名字依賴注入物件`,@configuration
* [Spring annotation常用](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/488347/)

# 自然語言處理NLP 架構
![](https://github.com/zero85258/MyNOTE/blob/master/img/nlp-pipe.png)
![](https://github.com/zero85258/MyNOTE/blob/master/img/nlp-dl.png)


* 自然語言處理的具體表現形式包括[機器翻譯、文本摘要、文本分類、文本校對、信息抽取、語音合成、語音識別...](https://ithelp.ithome.com.tw/articles/10193224)等。
* 可以說，自然語言處理就是要計算機理解自然語言，
* 自然語言處理機制涉及2個流程，包括`自然語言理解`和`自然語言生成`。
* nltk 聽說是必玩的套件
* bert 新潮
* [字向量,拼音向量,詞向量,詞性向量,依存關係向量](https://www.itread01.com/content/1543401246.html)

# [DOT,Graphviz](http://llever.com/exercism-rust-zh/dot-dsl/README.zh.html),[mermaid](https://mermaid-js.github.io/mermaid/#/) (DSL)
* 繪圖可以使用,語法他媽的超簡單
* [範本](https://github.com/zero85258/MyNOTE/blob/master/%E7%B6%B2%E8%B7%AF%E6%B4%A8%E9%AB%98%E6%89%8B/Misc%E5%A4%A7%E9%9B%9C%E7%87%B4%20-%20%E7%B9%AA%E5%9C%96%E5%A4%A7%E5%B8%AB.md)

# 短路求值(三元ternary operator的化簡)
```js
// js
e = a || b || c
```
```py
# py
b = "" or "" or ggg
```

# Orchestration編排(聲明式) <==> Automation自動(命令式)
* Kubernetes,Docker Swarm,Apache Mesos, Marathon,OpenStack這些都叫做`Orchestration編排工具`
* Ansible 這些都叫做`Automation自動工具`
* vRA(vmware現代化的基礎架構自動化

# DevOps-IaC
* Chef, Ansible 他們最主要的功能是「配置管理」，亦即是決定要安裝什麼套件、設定什麼環境變數…等之類的，
* [Ansible(自動化部署工具)](https://medium.com/@chihsuan/ansible-%E8%87%AA%E5%8B%95%E5%8C%96%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7-b2e8b8534a8d)
* Terraform 則是決定要什麼樣的機器。
![](https://github.com/zero85258/MyNOTE/blob/master/img/devOpsChain.png)


# Terraform
* 雲端架構程式自動化
```sh
terraform init		# 初始化
terraform apply		# 執行
terraform destroy	# 清除
terraform graph | dot -Tsvg > graph.svg
```

# FaaS(Framework as a service, ServerLess) PaaS(Platform as a service, 容器調度)
* [OpenFaaS](https://www.openfaas.com/) (使用上覺得有點像把dockerImg當作執行檔,或是可以直接取其他當語言, 而不是像service常駐
* [java玩OpenFaaS](https://blog.alexellis.io/java-comes-to-openfaas/)

# [ServerLess framework](https://serverless.com/framework/docs/getting-started/)

# ACL(Access Control List)
* laravel permission就屬於一種 (登入機制面的)

# Webhook(訂閱網站)
* [bash webhook listener](https://gist.github.com/orangeblock/15ee8e3cb304a4046082b422adaaf5fb)
* 訂閱網站或是`端點entrypoint`的方法。
* 平台上會有觸發event, 會主動知會訂閱者
* jira, gitlab, slack, line

# hook
* windows hook(鍵盤側錄也是基於這個做出的)
* apple event manager

# binery hook

# [React Hook](https://www.ruanyifeng.com/blog/2019/09/react-hooks.html)
* 感覺是在`函數內部`把`外部`的東西抓來用(`組件`訂閱`狀態`)

# RSS Feed && JSON Feed

# ChatOps
* [StackStorm st2](https://github.com/StackStorm/st2)

# wrapper(stream)
```
http協議傳來的資料是流的方式，但只有http包裝器才理解http協議傳來的資料的意思，
可以這麼理解，流就是一根流水的管子，只不過它流出的是資料，
包裝器就是套在流這根管子外層的一個解釋者，它理解流出的資料的意思，並能操作它
```

# Suspend/Resume 掛起/喚醒

# 過濾器模式（Filter Pattern）或標準模式（Criteria Pattern）是一種設計模式，
```
這種模式允許開發人員使用不同的標準來過濾一組對象，
通過邏輯運算以解耦的方式把它們連接起來。
這種類型的設計模式屬於結構型模式，它結合多個標準來獲得單一標準。
```

# linux 常看到的 -- (double-dash)
* 表示命令選項的結尾，此後僅接受位置參數。
* 用法示例：假設您要為該字符串grep文件`-v` 通常-v會被認為是反轉匹配含義的選項（僅顯示不匹配的行），但是--您可以使用grep這樣的字符串-v：
* grep -- -v file

# source 跟 export 的區別

# AI近況
* [各式各樣的神經網路](https://ek21.com/news/1/20703/)
```
樓上的文章我的看法也是差不多，不過感覺他應該是寫一段時間了，不然就美國生態現在有變。
現在的狀況做DL的，除非是高端的DL，其他的也是普通的monkey。
做CV的就u-net、voxelnet、yolo v3這幾個，
做nlp的 芝麻街BERT 系列都有現成的、
然後台灣的情況為了騙客戶弄一堆rulebase很常見。
至於其他的金融分析的還是一堆用傳統ml加一點dl堆起來。
總結來說，目前整個生態就是朝兩極化發展。
高端的話，台灣別想，國外真的去找一所好的大學唸phd，或是擠進最頂的國際企業的實驗室，
不然就務實一點把soft的基本功練滿，往架構師加應用到DL或資深韌體晶片加DL前進
```

# [Neural Network Architectures](https://www.youtube.com/watch?v=oJNHXPs0XDk) 神經網路
* ![](https://github.com/zero85258/MyNOTE/blob/master/img/Neural%20Network%20Architectures.png)
* ![](https://github.com/zero85258/MyNOTE/blob/master/img/neural-networks.jpeg)
* hidden layer 其實就是在做資料的`特徵擷取`，可以`降維`或`增維`，而這個過程不是經驗法則去設計，而是由資料去學習得來
* kernal cell 卷積核:感覺有點像是mask
* 卷積:加權疊加
* 池化:過濾聚合

# 兩階段終止(Two-phase Termination兩相終止)
* 所謂的兩階段終止，即中止「運作階段」，並完成「善後階段」
* 事情要突然中斷,需要先做個段落,在中斷
* SIGTERM感覺就是有善後, SIGKILL感覺就是硬砍
* Terminator，终止者，负责接收终止请求，执行终止处理，处理完成后再终止自己。
* TerminationRequester：终止请求发出者，用来向Terminator发出终止请求。

# 空運行(dry run)
* 也稱為試運行（practice run

# `exec`,`eval`,`${}`,\`\`的差異

# [SDN 程式定義網路](https://ithelp.ithome.com.tw/users/20107467/ironman/1370?page=3)
```
SDN是將傳統網路中，
管理網路的
控制面（Control Layer）與資料層（Data Layer，或又稱Forwarding Layer，意思為傳送封包的轉送面）分離開來，
將網路的管理權限，
交由控制層的控制器(Controller)軟體負責，
控制器軟體就像人類的大腦，
能靈活統一的下達指令給眾多網路設備，
如此一來，
網路設備則只需專注於封包的傳遞，
這種透過集中管理網路的方式，
將能大幅提升網路資源控管與使用效率。
```

# OpenFlow(SDN用的 通訊協定)
* Openvswitch :一種虛擬交換器，可用來作為L2switch(OSI Lv2)，切割網域，QoS或是流量監控，同時支持`openFlow協定`。

# p4語言
* 好像跟SDN有關係

# 網路功能虛擬化 NFV
```
將實體設備的網路功能，
以軟體的型態呈現，
例如路由器（Router）、防火牆（Firewall）、負載平衡器（LoadBalancer）與用戶終端設備（CPE）等；
這種將網路功能虛擬化（意即軟體化）的概念，
顛覆過去網路功能必須存在特定硬體設備中的傳統架構。因網路功能被虛擬化後，
有著極佳的彈性配置特性，
能加速網路服務的部署效率，
亦能降低購置專用硬體的開銷。
```

# [OPNFV](https://kknews.cc/zh-tw/tech/3qyr9o.html)
* SDN軟體定義網路 相關,感覺比較像是大架構,想要把現有的東西組裝起來
* OpenContrail == SDN軟體定義網路 平台开源

# firewall
* `ip` + `port` 的組合
* 來源(設置`outbound`放行`外出`) ===> 目的(設置`inbound`放行`進入`)
* Netfilter 用來封包過濾
* 可用ClearOS (OSS),iptables玩

# 防火牆擋了什麼(不能連線時)
* 封包還有啥?

# VPC/VPN/IDC
![](https://github.com/zero85258/MyNOTE/blob/master/img/vpn2.png)

# [VPN](https://www.asus.com/hk/support/FAQ/1033906/)
* `PPTP點對點隧道協議`:使用TCP協定，適合没有防火牆限制的網路
* `L2TP第2層隧道協議`:使用UDP協定，一般可以穿透防火牆，適合有防火牆限制環境，如公司、網咖、學校等。

```
PPTP的運作需要使用 TCP Port 1723 及 IP Protocol GRE(47)
L2TP的運作需要使用 UDP Port 500、UDP Port 4500及IP Protocol ESP(50)
```

# VPC(AWS服務)
Amazon VPC 讓您能夠在 Amazon Web Services (AWS) 雲端佈建一個在邏輯上隔離的部分，
以在自己定義的虛擬網路中啟動 AWS 資源。  
您可以完全掌控虛擬聯網環境，包括選擇自己的 `IP地址範圍`、建立`子網路`，以及設定`路由表`和`網路閘道`。  
您也可以在公司IDC和VPC之間建立硬體虛擬私人網路 (VPN) 連接，將 AWS 雲端當成公司IDC的延伸。  

# VPS
* 主機商會將一台`主機host`分成多個`虛擬機guest`

# [土製IDC](https://ithelp.ithome.com.tw/users/20094403/ironman/2170)

# Gateway閘道器(也有人稱為`通訊閘`,`網關`,就是大門)
* 其功能主要是讓`兩種不同性質的網域相互連接`，幫助使用者免除連上不同網域而使用不同軟體或學習的步驟。
* 通常就是`ifconfig`底下的`預設閘道`

# 網域 == []子網路(子網段)
* 網域 ==`子網路遮罩`切 => 網段
* 引入劃分子網路這個概念的目的是為了允許一個單一的站點能擁有多個 LAN區域網路

# 網域(Domin的那個)
```
網址: www.pkthink.com 或 pkthink.com 就是所謂的主網域，
而 gallery.pkthink.com 就是子網域( 次網域 )
```

# FQDN
* ![](https://github.com/zero85258/MyNOTE/blob/master/img/fqdn.jpeg)

# 外網/DMZ/內網
* 通常連上hub設定
* 虛擬交換器 [OpenvSwitch](https://www.netadmin.com.tw/netadmin/zh-tw/technology/A54919443A1C442389BD38E531D5B4FB)
* 虛擬路由器 [Vyatta](https://www.lijyyh.com/2015/05/software-based-router-practice.html)

![](https://github.com/zero85258/MyNOTE/blob/master/img/external-dmz-internal.jpg)

# netstat 
* ESTABLISHED(通常是request發起端,port都很大) <---> LISTENING(通常是response回應端,80,443,3306....)

# interface metric(網路介面優先級)
* 有時一台主機有多張網卡(可能有內有外),沒設定可能導致無法連線
* 還有route metric

# DNS 代管 & 自管(自架)

```sh
# 自管 53 port
/etc/named.conf
/etc/init.d/named start
```

```
其實對域名的解析來說，沒有什麼自管或是代管，
就只看 NS 紀錄指到那一個機器，查詢就會自動轉到那邊去，
代管就是這台機器放在你指定的廠商，
自管就是你自己有對外網路，自己架設了 DNS 伺服器。

如果是代管，就需要知道廠商的 NS 名稱與 IP 位址，
然後把他填入域名的名稱伺服位址欄位，就變成代管，
自管 == 填入自己架設的電腦位址，只能填入名稱伺服器的位址，
千萬不要在名稱伺服器填入 168.95.1.1 或是 8.8.8.8 ，
那是快取伺服器，並不是域名管理主機(又稱權威伺服器)。
```

# NAT
```
NAT 類型通常分為
Open（Type 1）、
Moderate（Type 2）
Strict（Type 3）。

本遊戲使用的多人連線網路架構設計需要您的 
NAT 類型 >= Moderate 
盡可能是 Open 的 NAT 連線類型，以獲得最佳的多人遊戲配對體驗。
```

# [NAT穿透(內網穿透)](https://github.com/fatedier/frp)
* 可幫助您將NAT或防火牆後面的本地服務器公開到Internet
* p2p打洞
* 平偉拆你家

# DNS
* 外網DNS,內網DNS,自己主機DNS
* host檔 (host檔的功能 == DNS的功能, 有點像是DNS的本地暫存的概念)
* googleDNS(cloudflare) == 1.1.1.1
```php
// 網址與IP 可以是 一對多關係(LB) 多對一關係(DNS)
// 使用者上網時原理 user --> DNS($網址) --> 網站IP
$IP = hosts檔($網址) ? hosts檔($網址) : DNS($網址);
```

* [可用dnsmasq 取代 /etc/hosts]()
```sh
/etc/hosts 	#這個是最早的 hostname 對應 IP 的檔案；
/etc/resolv.conf  #這個重要！就是 ISP 的 DNS 伺服器 IP 記錄處；
/etc/nsswitch.conf #這個檔案則是在『決定』先要使用 /etc/hosts 還是 /etc/resolv.conf 的設定！
```

# DNS託管服務

# [C10k問題](https://blog.niclin.tw/2018/08/19/%E5%B7%A5%E7%A8%8B%E5%B8%AB%E6%87%89%E8%A9%B2%E7%9F%A5%E9%81%93%E7%9A%84-c10k-%E5%95%8F%E9%A1%8C/)
* 簡單來說，C10K下跑Zrange會讓Redis變超慢，如果你不會BigO那根本不用談了
* 多看看Triton Ho的東西,ex:[Redis相關](https://github.com/jimliu7434/Diary/issues/15)
* [c100k連kernel都要動](https://www.bytelego.com/2013/11/22/c100k-4-kernel-tuning/)

# Netty(異步框架)
* 如果你想知道Nginx是怎么写出来的，如果你想知道Tomcat和Jetty是如何实现的，
* 如果你也想实现一个简单的Redis服务器，那都应该好好理解一下Netty，它们高性能的原理都是类似的。
* 可實現自己的特定協議的服務器

# MQTT
* MQTT 的設計初衷是為了在不可靠的網絡中運作良好，(感覺多用於嵌入式場景)
```sh
# apt install -y mosquitto
mosquitto_sub -h 10.211.55.9 -t Sensor/Temperature/Room1
mosquitto_pub -h 172.20.10.4 -t Sensor/Temperature/Room1 -m "hello world"
```

# [服務質量QoS](https://swf.com.tw/?p=1015)(交付保證次數)
```sh
失敗必有重試,所以 保證只有1次是最高品質

QoS Level 0：至多一次
這是最簡單的級別，無需客戶端確認，其可靠性與基礎網絡層 TCP/IP 一致。

# 感覺UDP的模式就有點像這個
QoS Level 1：至少一次，有可能重複
確保至少向客戶端發送一次信息，不過也可發送多次；
在接收數據包時，需要客戶端返回確認消息（ACK 包）。
這種方式常用於傳遞確保交付的信息，但開發人員必須確保其系統可以處理重複的數據包。

# 感覺TCP的模式就有點像這個
QoS Level 2：只有一次，確保消息只到達一次
這是最不常見的服務質量級別，確保消息發送且僅發送一次。
這種方法需要交換4個數據包，同時也會降低消息代理的性能。
由於相對比較複雜，在 MQTT 實現中通常會忽略這個級別，請確保在選擇資料庫或消息代理前檢查這個問題。
```

# EventSourcing
* 感覺最後就是連`資料`都可做到版控(雖然儲存成本還是嚇死人),所有程式裡面的操作記錄都會被以event的方式記錄,控管,處理

```
不保存對象的最新狀態，而是保存對象產生的所有事件。

通過事件回溯(Event Sourcing, ES)得到對象最新的狀態

以前我們是在每次對象參與完一個業務動作後把對象的最新狀態持久化保存到數據庫中，也就是說我們的數據庫中的數據是反映了對象的當前最新的狀態。
而事件溯源則相反，不是保存對象的最新狀態，而是保存這個對象所經歷的每個事件，所有的由對象產生的事件會按照時間先後順序有序的存放在數據庫中。
當我們需要這個對象的最新狀態時，只要先創建一個空的對象，然後把和改對象相關的所有事件按照發生的先後順序從先到後全部應用一遍即可。
這個過程就是事件回溯。


因為一個事件就是表示一個事實，事實是不能被磨滅或修改的，所以ES中的事件本身是不可修改的(Immutable)，不會有DELETE或UPDATE操作。

ES很明顯先天就會有個問題——由於不停的記錄Event，回溯獲得對象最新狀態所需花的時間會與事件的數量成正比，
當數據量大了以後，獲取最新狀態的時間也相對的比較長。

而在很多的邏輯操作中，進行“寫”前一般會需要“讀”來做校驗，
所以ES架構的系統中一般會在內存中維護一份對象的最新狀態，在啟動時進行”預熱”，讀取所有持久化的事件進行回溯。
這樣在讀對象——也就是Aggregate的最新狀態時，就不會因為慢影響性能。

同時，也可以根據一些策略，把一部分的Event合集所產生的狀態作為一個snapshot，下次直接從該snapshot開始回溯。

既然需要讀，就不可避免的遇到並發問題。

EventSourcing要求對回溯的操作必須是原子性的，具體實現可參照Actor模型。
```

# [CQRS](http://edisonxu.com/2017/03/23/hello-cqrs.html)
* 把`命令`與`查詢`這兩種責任給明確區分開來。
* 常與EventSourcing一起被提及
* [Gravity](https://medium.com/brobridge/%E6%87%89%E7%94%A8%E5%B1%A4-cqrs-%E7%9A%84%E5%AF%A6%E7%8F%BE%E8%88%87%E5%9B%B0%E9%9B%A3-378f97e86639) outOfBoxSolution

![](https://github.com/zero85258/MyNOTE/blob/master/img/CQRS.jpg)


# immutable(不可變更的)

# 多路複用（Multiplexing，又稱「多工」）
* 是一個通訊和計算機網路領域的專業術語，在沒有歧義的情況下，「多路複用」也可被稱為「複用」。
* 多路複用通常表示在一個通道上傳輸多路訊號或數據流的過程和技術。
* 因為多路複用能夠將多個低速通道整合到一個高速通道進行傳輸，從而有效地利用了高速通道。

# 萬用字元： (Wildcard)

# [CentOS 7好站](https://www.server-world.info/)

# [Beanstalkd]()
![](https://github.com/zero85258/MyNOTE/blob/master/img/beanstalkd-life-cycle.png)
* tube 感覺就是 Queue
### state
* `READY` - 需要立即處理的任務。
* 當producer直接put一個任務時，任務就處於READY狀態，以等待consumer來處理。當延時 (DELAYED) 任務到期後會自動成為當前READY狀態的任務
* `DELAYED` - 延遲執行的任務。當任務被延時put時，任務就處於DELAYED狀態。
* 等待時間過後，任務會被遷移到READY狀態。當消費者處理任務後，可以用將消息再次放回DELAYED隊列延遲執行
* `RESERVED` - 已經被消費者獲取，正在執行的任務。
* 當consumer獲取了當前READY的任務後，該任務的狀態就會遷移到RESERVED狀態，這時`其它的consumer就不能再操作該任務`。 Beanstalkd會檢查任務是否在TTR(time-to-run)內完成
* `BURIED` - 保留的任務，這時任務不會被執行，也不會消失。
* 當consumer完成該任務後，可以選擇delete、release或者bury操作。delete後，任務會被刪除，生命週期結束；

### 操作
* release操作可以重新把任務狀態遷移回READY狀態或DELAYED狀態，使其他consumer可以繼續獲取和執行該任務
* bury會拔任務休眠，等需要該任務時，再將休眠的任務kick回READY；也可能過delete刪除BURIED狀態的任務

# Data pipeline
* streaming pipeline：`listen事件流`，即通常通過AMQP，Kafka，Kinesis等實現，並處理每個事件。每當管道遇到UserVisitedWebsite事件時，將計數增加一。(storm好像就是這個)
* batch pipeline：通過`cron`運行批處理代碼來使用存儲在數據湖中的數據。通常每晚。在匯總表中更新記錄。
* 準確性：有重複事件的可能性。請記住，沒有重試就無法保證交貨，因此會造成重複。如果事件重複，則計數將出錯。
* 冪等性：哪裡有代碼，哪裡就有bug。數據管道也是如此。修復錯誤後，在同一日期重新運行管道代碼並不少見。不難發現，由於實時更新代碼不是冪等的，因此無法重用

# [冪等性Idempotence(感覺好處是可帶來某種程度的容錯)](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/614601/)
* 理解：冪等性是系統的介面對外一種承諾(而不是實現)，承諾只要呼叫介面成功，外部`多次呼叫`對系統的影響是一致的。
* 宣告為冪等的介面會認為外部呼叫失敗是常態，並且失敗之後必然會有重試。
* 介面冪等性，只要保證介面內的邏輯不涉及介面外的物件狀態累積或變遷即可。

# [分散式系統等級](https://itw01.com/88PETBB.html)

# 分佈式協議
* 使用分佈式協議來解決數據一致性問題已經成為了主流的方向
* paxos raft

# Paxos
```
首先粗略展示 Paxos 的大致流程：

一個（或多個結點） 決定要成為 Leader
想要成為 Leader 的結點， 首先提出一個候選值（Proposed Value）, 以期待大家對這個候選值可以達成共識
Leader 聯繫所有的參與結點， 嘗試收集到半數以上結點的同意回复
參與結點的含義：
可以是一個預先配置好的結點集
也可以是前一個視圖中的所有結點
如果半數以上的人回復了同意， 成功的達成了共識 ！

在一個存在多副本狀態機的系統中，即使有少數結點失效，系統也能繼續運行
在每一次發生結點失效以後， 執行視圖變化算法 Paxos
這樣可以使得系統中的多數狀態機達成新的共識狀態
這樣， 系統中的每個結點都能有共同認可的主結點
```

# 對話用戶介面（CUI - Conversational User Interface）
* siri就是 (本質好像也是FSM)


# RabbitMQ 持久化Persistent 保證
* 使用 `MirroredQueue鏡像隊列`
```bash
# msg -> RabbitMQBuffer(可能暫丟記憶體?) -> 物理disk
首先可以引入RabbitMQ的mirrored-queue即鏡像隊列，這個相當於配置了副本，
當master在此特殊時間內crash掉，可以自動切換到slave，這樣有效的保障了HA, 
除非整個集群都掛掉，這樣也不能完全的100%保障RabbitMQ不丟消息，
但比沒有mirrored-queue的要好很多，很多現實生產環境下都是配置了mirrored-queue的。
```

# id設計,與取捨 
* [分布式唯一ID生成服务](https://juejin.im/post/5b3a23746fb9a024e15cad79)


# BBCODE

# Parquet
* Parquet 節省了大量的存儲空間，同時節省了大量的`表掃描`和`反序列化`的時間。
* 如果說 HDFS 是大數據時代文件系統的事實標準的話，
* Parquet 就是大數據時代存儲格式的事實標準

# 長時間運行事務(long-running business process)
* 分佈式場景
* 把單一的transaction按照步驟分成一組若干子transaction，通過`補償機制`實現最終一致性。

# http2
```
伺服器推送
HTTP/2 的一項新特色是加上了伺服器推送功能，伺服器可以主動推送內容到瀏覽器上。這增加了許多特別的新應用，例如可以在瀏覽器尚未發出請求前，預先推送 CSS 或頁面 Layout 到瀏覽器上，增加之後的頁面載入速度。

標頭壓縮與編碼
HEAD 在傳輸的時候，有蠻多重複或冗餘的資訊，這些資訊可藉由 Haffman 演算法壓縮 HEAD 來增加傳輸速度。

流程下載控制與優先級
藉由控制下載流程的優先級，可以讓 HTTP/2 的傳輸過程中，將最重要的內容優先下載，避免大量資訊堵在一起。

不強制採用加密傳輸
相較於 SPDY 強制要採用 https 協議，HTTP/2 並未強制傳輸要加密，不過在 HTTP/2 協議下，將更容易實現 TLS 傳輸加密。

如何使用 HTTP/2
```

# 命名風格 Naming style
```php
$className = studly_case('foo_bar');    // FooBar
$converted = camel_case('foo_bar');     // fooBar
$converted = snake_case('fooBar');      // foo_bar
$converted = kebab_case('fooBar');      // foo-bar
$s = Str::plural($no_s = $model);  // 英文字複數型 轉換
$no_s = Str::singular($s = $model);  // 英文字單數型 轉換
studly_case("FooBar");    // FooBar
camel_case("FooBar");     // fooBar
snake_case("FooBar");     // foo_bar
studly_case("FooBar");    // foo-bar
str_plural("FooBar");     // FooBars
str_singular("FooBar");   // FooBar
```

* [真的他媽找不到bash方案了,是否該自己刻個cli](https://github.com/illuminate/support/blob/master/Str.php)

# LRU cache 快取置換機制
* 由於電腦記憶體空間（memory）的限制，無法容納所有資料和文件，所以當有新的文件要被置換進入快取（cache）時，必須根據一定的規則來取代掉適合的文件，這就是所謂的快取文件置換機制。

# Memory Management 相關
* stack page, data page, code page

# DS_Store (英文全稱Desktop Services Store) 
是一種由蘋果公司的Mac OS X作業系統所創造的隱藏文件，目的在於存貯目錄的自定義屬性


# Mysql Identifying Relationships && Non-Identifying Relationships
* Identifying Relationships是指childTable的每一列資料必須依賴於parentTable的資料而存在。母表的primaryKey欄位必須為子表的主鍵的一部分
* Non-Identifying Relationships是指子表的資料必須不依賴於母表的資料而存在。母表的primary key欄位不為子表primary key的一部分。

# MySQL FK(資料連動機制)
```
CASCADE
在父表上update/delete記錄時，同步update/delete掉子表的匹配記錄

SET NULL
在父表上update/delete記錄時，將子表上匹配記錄的列設為null (要注意子表的外鍵列不能為not null)

NO ACTION
如果子表中有匹配的記錄,則不允許對父表對應候選鍵進行update/delete操作

RESTRICT
同no action, 都是立即檢查外鍵約束

SET NULL
父表有變更時,子表將外鍵列設置成一個默認的值 但Innodb不能識別
```

# 柯里化
Curry 的概念很簡單， Function參數足夠就執行，不夠就會回傳Function

# 資料格式
* parquet
* BSON
* avro

# Bean(物件) <==> XML(序列化產物) (JAVA)
* 可以將多個物件封裝到一個物件（bean）中。特點是`可序列化`成xml
* Bean可以接收來自其他Object的Event，也可以產生Event給其他Object。
* 
```java
# Java語言欠缺屬性、事件、多重繼承功能。
# 所以，如果要在Java程序中實現一些面向對象編程的常見需求，只能手寫大量膠水代碼。 
# Java Bean正是編寫這套膠水代碼的慣用模式或約定

反序列化物件.getX()
```

# Web容器
* Tomcat就是

# H5
* 就是在微信裡，透過公眾號或是朋友圈發文的一個連結，點開後會在微信`內部瀏覽器`開啟一個類似移動端的活動網頁

# Native Messaging
* chrome跟本地的程式溝通

# 秒殺(限量搶購)
* 感覺分成 `搶購(Redis + Lua原子操作)`,`生成訂單(MQ慢慢消化)`,`付款(第三方金流)`,`出貨`
* [秒殺系](https://segmentfault.com/a/1190000022566350)
![](https://github.com/zero85258/MyNOTE/blob/master/img/%E7%A7%92%E6%AE%BA.png)

# 短網址
* [自架yourls](https://www.vedfolnir.com/shrink-shorten-urls-by-yourls-13260.html)
* [lihi好像幹掉了goo.gl](https://lihi.io/)
* tracking data

# 第三方追蹤
* AppsFlyer 好像是很大的SaaS

# finger print

# 流量分析服務
matomo/piwik

# p2p下載
* torrent種子 (透過Tracker找其他人)
* magnet磁力鏈接(比種子好)

# HLS協議
* m3u8 串流影音
* `.ts` == chunk
* `.M3U8 檔` 索引檔 (index file) 記錄這些chunk的順序與位址 
* 號稱無損分割H.264 TS

```sh
# 下載
ffmpeg -i "m3u8網址" -c copy 名字.mp4
```

# DDos
* 泛洪FLOOD(理解是塞爆,來不及處理)
* 反射泛洪(理解是 用廣播的response塞爆)

# 事件傳遞機制(JS)
* 瀏覽器事件的運作原理，包含event bubbling、event capturing
* addEventListener 事件監聽
* preventDefault
* stopPropagation 取消事件傳遞

# Event Bubbling 特性 && Event Capturing 特性
```sh
# Event Bubbling(子==>父)
指的是當某個事件發生在某個DOM element上（如：點擊），
這個事件會觸發DOM elemtn的event handler，
接下來會再觸發他的parent的event handler，
以及parent的parent的event handler…直到最上層。

# Event capturing(父==>子)
和Event bubbling相反，
event發生在某個DOM element上的時候，
會從他的最上層parent開始觸發capturing handler，
再來是倒數第二上層的ancestor的capturing handler，
以此類推，
直到觸發事件的DOM element本身的capturing handler。
```

```js 
// 如果要設定capturing handler，
// 將addEventListener的第三個參數設為true（預設值為false）：
form.addEventListener('click', handler, true)
```

# Event Delegation
```js
// 常與Event Bubbling一起使用
var btn1 = document.querySelector('button#btn1');
const bubblesClick = new Event('click',{
  bubbles:true
});
btn1.dispatchEvent(bubblesClick);
```


# 待尋找 opensource方案
* 企業入口平台 Enterprise Portal (Portal, EIP) Portlet導入 `Apache Pluto`
* 企業流程管理 Business Process Management (BPM) `JBoss`
* 商業智慧 Business Intelligence (BI) Reporting導入

# [RocketMQ](http://jm.taobao.org/2017/01/12/rocketmq-quick-start-in-10-minutes/)

# [記憶體DB方案](https://juejin.im/post/5c22e049e51d45206d12568e)
* levelDB(engine)

# tls握手(https)
* `自簽`別用在production
![](https://github.com/zero85258/MyNOTE/blob/master/img/tls-handshake.png)

# kickstart 自動化安裝
* 拿vagrant練習
* `ks.cfg`

```sh
1、server掛載rhel7映象包，並配置yum源
2、安裝需要的包 yum install -y dhcp xinetd tftp-server syslinux nfs-utils httpd && system-config-kickstart
3、設定dhcp服務 `vi /etc/dhcp/dhcpd.conf`, 且確保主機所處的網路中沒有其他dhcp服務。
4、配置tftp服務, 且重啟xinetd服務
5、配置nfs服務 `vi /etc/exports`, 且`service nfs restart`
6、配置需要的kickstart檔案，並將檔案儲存為`/var/www/html/ks.cfg`, `system-config-kickstart`
7、`service httpd restart && service dhcpd start`
8、啟動client，設定啟動裝置為網絡卡。
```

# Aws
* Splunk 感覺也是 log的分析服務
* Athena 感覺是SQL查s3 (感覺就是hive
* Glue 感覺是etl服務
* Kinesis Data Streams
* Kinesis Data Analytics(Apache Flink) 感覺是用SQL分析`串流資料`or 或程式化開發
* Kinesis Data Firehose 把data stream存到aws storage
* Kinesis Video Streams
* QuickSight 感覺像是 `社群網站式`的dashborad or bi system?!

# Kafka
* Real-Time Data Streaming(感覺像是當年`ETL中心`redis的角色)

# streaming data
* raw Data好像`不儲存`
* 即時的作法 就要用`推送`
* Apache Flink計算框架, 可處理批次資料(Batch)和流式資料(Streaming)

# PDI(Pentaho Data Integration)/Kettle

```sh
Pentaho Data Integration資料整合，專案名稱為 Kettle， 
主要為以Spoon為主的資料整合開發環境，Pentaho資料整合支援部署在一個雲或是叢集架構的單一電腦上。

Pentaho Data Integration (PDI) 為一個資料整合 ETL開發環境，
以圖形化介面提供使用者定義資料整合工作(Job)與移轉(Transformation)。 
資料整合提供了大量的Plugins以開發執行Job與Transformation，
Job通常可依排程以批次模式在設定時間區間自動執行。

主要模組：
Spoon(GUI): 是PDI主要設計環境，以圖形化介面讓使用者能設計並執行Job與Transformation。
Carte(REST Worker): 一個簡單Web Server讓您遠端執行Job與Transformation。可建置Cluster以分散Job與Transformation的執行。
Pan(REPL): 命令列式的Transformation執行引擎。
Kitchen(REPL): 命令列式的Job執行引擎。
Encr(加密工具): 提供PDI可進行文字加密。

設計內容：
Transformation: 從來源到目的進行資料項的搬動、轉移，可被平行執行。
Job: 主要在於流程控制，包含執行Transformations、發送E-mail、處理ftp檔案等，依順序執行。
```


```sh
# Pentaho Repository是用於協作分析和ETL（提取，轉換和加載）開發的環境

# 執行 workflow == []ETL
sh kitchen.sh -rep=REPO名 -user=帳 -pass=密 -job=JOB名

# 執行 ETL
sh pan.sh -rep=REPO名 -user=帳 -pass=密  -trans=Transformation名

# mac執行pdi spoon
./所在地資料夾/data-integration/Data Integration.app/Contents/MacOS/JavaApplicationStub
```

# 虚拟化 (`性能`<=>`靈活`的取捨)
```sh
# 1型虚拟化
Hypervisor 直接安装在Host上，多個VM在 Hypervisor 上運作。
Hypervisor 實現方式一般是一个特殊的 Linux 系统。Xen 和 VMWare 的 ESXi 都屬於這類型。
# 2型虚拟化
Host上首先安装一般的OS，比如 Redhat、Ubuntu 和 Windows。Hypervisor 作為 OS 上的一个程式運行，對VM進行管理。
KVM、VirtualBox 和 VMWare Workstation 都屬於這類型。
```

# Simulator模擬器 vs Emulator仿真器
* Simulator純粹以`軟件`來模擬源平台的功能和運行結果；
* Emulator以`軟件`+`硬件`來模擬源平台的內部設計、行為和運行結果。

# Windows Container 
```
Windows Container 的出現，更把 stackoverflow.com 使用的這種異質性架構的門檻降到最低了。
這時平台是 windows or linux 已經不會再是左右你選擇的主要考量了，你大可挑選業界最佳的個別服務，來組裝你的 application。
包括採用的基礎建設，挑選現成的服務，以及決定自行開發的服務及平台。
這是很大的突破，轉眼間 .NET / Java / PHP 不再是派別的對立，而是可以讓團隊自由選擇採納的開發平台。
唯一的考量是: 這平台適合拿來開發這服務嗎? 還有我的團隊對這個平台是否有足夠的掌握能力?
```

# [Distroless](https://github.com/GoogleContainerTools/distroless)
* 只能有runtime跟dependencies的docker image(感覺就是要挑戰比alpine更輕)

# Busybox
* 是重要的Embedded Linux工具箱，
* 這個工具箱提供基本的UNIX指令、系統程式(daemon)與開機程序(init process)。
* 用來建造1個基本、最小化且可開機的Linux系統，由於Busybox裡的指令與工具都經過最小化處理
* 是目前主要應用在Embedded Linux實作上的開放源碼專案了

# [Wine](https://magiclen.org/wine/) 有點像是 win版支援GUI的alpine
* 可搭配Winetricks
* [教學](https://www.davidbaumgold.com/tutorials/wine-mac/)
* 感覺遊戲,工程軟件通通可以包XDDDD
* Cygwin好像就是 在win跑 linux程式XDD
* darling == 在linux 跑 macOS(mach kernel vs linux kernel

# wine
```sh
# /Users/zero85258/.wine/drive_c
winecfg
wine 程式.exe
wine msiexec 程式.msi
winetricks

wine-mono # .net在linux的實現
wineserver -k # 關閉wine service
```

# window app containerize 

```sh
# i386/alpine:3.10.2

apk update && apk add --no-cache wine freetype wget xvfb-run ncurses
wget -P /app http://dl.winehq.org/wine/wine-mono/4.9.3/wine-mono-4.9.3.msi
winecfg
wine64 msiexec /i /app/wine-mono-4.9.3.msi

xvfb-run wine64 /app.exe

# 啥 x11vnc fluxbox gnome xvfb ncurses
```

# 移動端 Simulator
* [ios simulator](https://apppeterpan.medium.com/%E6%8B%96%E6%9B%B3-app-%E5%88%B0%E6%A8%A1%E6%93%AC%E5%99%A8%E5%AE%89%E8%A3%9D%E7%9A%84-xcode-8-2-%E5%AF%86%E6%8A%80-992c0b9ab701)
* [android simulator](https://developer.android.com/studio/run/emulator?hl=zh-cn)

```sh
# Android Emulator
/Users/zero85258/Library/Android/sdk/emulator/emulator -avd Pixel_2_API_30 -netdelay none -netspeed full

# iOS Simulator
open /Volumes/My\ Passport\ for\ Mac/Xcode.app/Contents/Developer/Applications/Simulator.app
```

# Hypervisor(VM Monitor)
```sh 
裸機型 : hypervisor 直接安裝於空機或新機上，直接掌控硬體資源，硬碟無須先有OS。
託管(宿主)型 : hypervisor 則需先有 Windows 或 Linux 才能安裝。
容器型 : 好像就是RancherOS那種
```
* 選hypervisor的時候，我們會從三大選擇出發。VMWare、Hyper-V、KVM、Proxmox VE
* 大師就曾經是vsphere的使用者，但最後投靠kvm，而且還活的更好的

# Proxmox VE(Hypervisor)
* 是一個開源的伺服器虛擬化環境Linux發行版
* 窮人的(可攜式/行動) 機房
* 支援 KVM、LXC、ZFS 三大關鍵技術，以及一個佔據未來的創新分散式儲存技術 CEPH

# Rancher OS(容器專用Hypervisor?)
[各家比較](https://www.ithome.com.tw/news/95756?fbclid=IwAR35kh4qbqKuaf7OBA1yFDqMEaBC-ApVNYPwF9uwSZQlr9tMo96Q6rlp_iI)

# Qemu(Hypervisor?)

# 虛擬環境 (ESX、KVM、OpenStack) 

# OpenStack,CloudStack == []Hypervisor

# virsh (拿來管kvm)

# 半虛擬化 vs 全虛擬化
* 半虛擬化與全虛擬化指的是廠商在解決 x86 CPU 特權等級，運用不同的技術，解決敏感指令不能被虛擬化的問題
* 敏感指令虛擬化 ~= asm假指令????

# Linux Namespace
* chroot相關
* 容器化機制 感覺都是基於此

# Snapshot Dump/Restore
* 原理上感覺就是Process`序列化`/`反序列化`
* vm(ps) >Dump(serialization)> 映像檔image(stringData)
```sh
criu dump -D /映像檔 -j -t 9527 # snapshot
criu restore -D /映像檔 -j	# restore
```

# Coredump
* kill -11 pid  # SIGSEGV kill這個進程的同時產生coredump
* 有點像是對process snapshot

# 靜態分析 & 動態分析(資安)
* `靜態分析` 不知是不是 == 分析`映像檔` 
* `動態分析` 不知是不是 == 分析`進程` 沙箱測試

# .so檔
```
so其實就是shared object的意思。
牽扯到ELF格式，gcc編譯選項待補，簡單實用的說明一下，對Linux下的so檔案有個實際性的認識。 

2.怎麼生成以及使用一個so動態庫檔案? 
3.地址空間，以及執行緒安全. 
4.庫的初始化，解析： 
5.使用我們自己庫裡的函式替換系統函式： 

1.so檔案是什麼？ 
也是ELF格式檔案，共享庫（動態庫），類似於DLL。
節約資源，加快速度，程式碼升級簡化。 
知道這麼多就夠了，實用主義。等有了印象再研究原理。 
```

# Event Carried State Transfer
* 減少event消費方對生產方的依賴（獲取event處理所需數據）。
* 增加event消費方系統的響應速度，因為不再需要調用生產方系統API以獲取event處理所需數據。
*　現在各個event消費方系統都複製了一份各自業務所關心的上游系統數據，由此也產生了備份數據之間的一致性問題。

```sh
我們在使用event notification時，event裡面往往不會包含下游系統處理這個event所需要的所有信息。
比如回到上面這個保險系統的例子，當客戶地址發生變更時，客戶管理系統會生成一個"Linda的地址變更了"的event。
但當下游系統處理這個event時，往往還需要知道，Linda的舊地址是什麼、新地址是什麼等信息，才能完成後續處理。
所以不可避免地，下游系統在處理這個event時，往往還需要查詢客戶管理系統來獲取這些額外信息。

為了解決這個問題，我們引入一個種新的模式，叫做Event Carried State Transfer。
簡單來說，就是讓event的消費方（上文中的保險報價系統）自己保留一份在業務處理過程中需要用到的上游系統的數據。
比如讓保險報價系統保留一份在處理客戶地址變更event時所需要用到的客戶數據，避免回頭去查詢客戶管理系統。
```

# 各式關鍵系統(可以先找找看apache)
* [訂單類設計](https://kknews.cc/zh-tw/tech/82b3a8g.html) 委刊單,訂單生成等等都是
* []() 秒殺系統,招標決標系統
* 報表系統,ETL系統
* ERP: [apache ofbiz](https://github.com/apache/ofbiz) , [odoo](https://www.google.com/search?q=odoo&oq=odoo&aqs=chrome..69i57j0l2j69i60j69i61j69i60l3.1867j0j7&sourceid=chrome&ie=UTF-8)

# NCCP

# CAS（Compare And Swep）操作


# Deadlock
* [Mysql](https://kknews.cc/zh-tw/code/2ykq4ve.html)
* [Java]()

# QUIC(UDP Base)
* http3

# 指標相關
* 感覺賦值的動作通常都要 &

# webView(App) && webKit(Browser)

# Cordova(App)
* 移動開發框架。 它允許您使用標準的web 技術如HTML5、 CSS3 和JavaScript 進行跨平臺開發

# 前端 (CI/CD)
* grunt =被取代=> gulp 前端`資源`的pipeline處理
* webpack 把前端資源`關注點分離`, 包出`index.bundle.js`
* bable es6 轉譯成 es5 or other

# [Mirror Repository(CI/CD)]()

# zero downtime 無停機服務(CI/`CD`)
* 藍綠部署、金絲雀發布、A/B測試、灰度發布

# 熱部署(CI/`CD`)
* 避免每次修改代碼都重啟

# 藍綠部署(CI/`CD`)
* 靠附載平衡 先updateA,再updateB

# 金絲雀佈署,灰度發布(CI/`CD`)
* 先將部份用戶的流量導到新版本的Pod上，確認沒問題後再將所有用戶轉移到新的版本

# Monolithic高藕合 <--> MicroService低藕合
* `微服務`:把模塊化的思想，從進程內模塊（類），變為進程間

# 微服務組裝
![](https://github.com/zero85258/MyNOTE/blob/master/img/microService.jpg)

# k8s vs springCloud
![](https://github.com/zero85258/MyNOTE/blob/master/img/k8sAndspringCloud.png)

# SpringCloud与Docker 微服務

# [MicroService概念](https://columns.chicken-house.net/2017/04/15/microservice8-case-study/)
```
架構設計:
先構思我要改變什麼架構? 有哪些模組要被切割獨立成服務?

程式碼重構:
使用 proxy + factory 這兩個 design patterns, 盡可能的將這些模組調整成高內聚+低耦合的狀態

建構服務:
開始將服務獨立出來，增加 remote proxy, 改變 factory, 將調用這些模組的 code 無痛的轉移到外部服務

驗證轉移的結果:
運用單元測試，以及雙重驗證技巧，確保移轉過程順利進行。

而在不同的環境下，使用不同的通訊方式都各有好處，
使用TCP/IP的話，不管你的節點在同一台機器或是遠端，都可以連線，缺點是在同一台機器會有一定的效能耗損，而且遇到廣播的訊息，同樣的訊息被傳送N次，就沒有UDP廣播來得划算，

如果節點是在同一台機器上溝通，使用IPC的方式效率好，
如果是在同一個thread裡，那麼分享記憶體的方式最快，IPC反而會拖慢速度，

正因為有各種不同的考量，使得想要達成高效率的分散式系統是一件困難的事情
```

# 可用性Availability && 可靠性Reliability
* 兩者都用百分數的形式來表示。
* `可用性Availability`(HA): 是 系統`可供使用時間`的描述，以`丟失時間`為驅動（Be DrivenBy Lost Time）。
* `可靠性Reliability`(SRE): 是 系統`無失效時間間隔`的描述，以`失效個數`為驅動（Be Driven By Number of Failure）。


# API Gateway網關(微服務)
* [tyk](https://github.com/TykTechnologies/tyk) 好像星星比較多
* [Zuul]() spring桶
* [Kong]() & [算是一眼就懂的教學](https://blog.csdn.net/jiangyu1013/article/details/80293341)

```
API Gateway負責請求轉發、合成和協議轉換。
所有來自客戶端的請求都要先經過API Gateway，然後路由這些請求到對應的微服務。
API Gateway將經常通過呼叫n個微服務來處理一個request以及聚合多個服務的結果。
它可以在web協議與內部使用的非Web友好型協議間進行轉換，如HTTP協議、WebSocket協議。

API Gateway可以提供給客戶端一個定製化的API。它暴露一個粗粒度API給移動客戶端。
以產品最終頁這個使用場景為例。
API Gateway提供一個服務提供點（/productdetails?productid=xxx）使得移動客戶端可以在一個request中檢索到產品最終頁的全部資料。
API Gateway通過呼叫n個服務來處理這一個request並返回結果，涉及產品資訊、推薦、評論等。

總結：API Gateway負責請求轉發、請求合成、協議轉換。它提供給應用客戶端一個自定義的API。
API Gateway可以通過返回Cache或者預設值的方式來掩蓋後端服務的錯誤。
```

# Ingress Controller && Api Gateway (service mesh,api gateway等等...議題)
```
Ingress controller允許單個ip端口通過入口規則訪問在k8s中運行的所有服務。服務設置為負載均衡器，因此可以從公共Internet訪問。
Api gateway用於應用程序路由，速率限制，安全性，請求和響應處理以及其他與應用程序相關的任務。
```
* Ingress == 虛擬入口
* 比較kong traefik ingress istio consul

# Service Discovery 服務註冊表(微服務)
* 集成的`運行狀況檢查`以及`DNS`和`HTTP接口`使任何服務都可以發現並被其他服務發現
* [Consul](https://www.consul.io/discovery.html) 包含 `運行狀況檢查` `DNS`和`HTTP接口` + Key/Value Storage + ACL + Intentions

# Service Mesh 服務網格(微服務)
* [Istio](https://istio.io/) [教學](https://medium.com/getamis/istio-%E5%9F%BA%E7%A4%8E-grpc-%E8%B2%A0%E8%BC%89%E5%9D%87%E8%A1%A1-d4be0d49ee07)
* 可控制 服務之間 是否隔离(可以靠GUI 無腦連連看)
* 流量控制,分流(可以靠GUI 無腦連連看)
* 讓服務彼此符合 `開放封閉原則`(Sidecar) 無須進服務破壞設定
### Service Mesh的重點主要在兩部份：
* Control Plane
* Sidecar

```sh
Service Mesh 這個服務網絡專注於處理服務和服務間的通訊。
其主要負責構造一個穩定可靠的服務通訊的基礎設施，
並讓整個架構更為先進和 Cloud Native。
在實踐中，Service Mesh 基本來說是一組輕量級的服務代理和應用邏輯的服務在一起，並且對於應用服務是透明的。

Service Mesh 作為獨立層的概念與雲原生應用的興起有關。
在雲原生模式，單個應用可能有數百個服務組成，每個服務又可能有上千個實例，
而每個實例都有可能被像 Kubernetes 這樣的服務調度器不斷調度從而不斷變化狀態。
而這些複雜的通信又普遍是服務運行時行為的一部分，這時確保端到端的通信的性能和可靠性就變的至關重要。

# Service Mesh 就是一個網絡模型嗎？
Service Mesh 是一個位於 TCP/IP 上的抽象層的網絡模型。
它假定底層 L3/L4 網絡存在並且能夠從一點向另一點傳輸數據。
（它還假定這個網絡和環境的其他方面一樣不可靠，所以 Service Mesh 也必須能夠處理網絡故障。）

在某些方面，Service Mesh 就像是網絡七層模型中的第四層 TCP 協議。
其把底層的那些非常難控制的網絡通訊方面的控制面的東西都管了（比如：丟包重傳、擁塞控制、流量控制），
而更為上面的應用層的協議，只需要關心自己業務應用層上的事了。

與 TCP 不同的是， Service Mesh 想要達成的目的不僅僅是正常的網絡通訊。
它為應用提供了統一的，可視化的以及可控制的控制平面。
Service Mesh 是要將服務間的通信從無法發現和控制的基礎設施中分離出來，並對其進行監控、管理和控制。
```

# SideCar Pattern
* [Service Mesh](https://zhuanlan.zhihu.com/p/61901608)

# Traffic Control(微服務)
* user端口Rate Limiting`頻次`

# 斷路器(微服務)
* Hystrix

# 配置管理（Configuration Management）,配置共享(微服務)
* consul,zookeeper,etcd都有這些功能

# 微服務 狀態機
```
任意的服務器結點本質上都是一個狀態機。
分散式架構可簡化問題為多份狀態機

磁盤， 內存, CPU 緩存中的數據都屬於state
通過指令，狀態機的狀態發生變化
用戶可以通過請求觸發狀態機執行特定的指令，從而進一步觸發狀態轉化
通過複製產生了多個位於不同結點的狀態機

每一個狀態機副本必須接受到順序相同的指令集
如果每一個指令所導致的狀態是確定的（非隨機）， 副本狀態機在執行了相同的指令以後， 最終會達到相同的狀態。
```

# [Stateful Functions(框架)](https://statefun.io/)
* 可降低大規模構建和協調分佈式有狀態應用程序的複雜性
* actor???

# 軟體引擎,描述語言
* code =businessLess=> softwareEngine
* data =businessFul=> DSL

# 軟體引擎(這是某種partten嗎?)
* 數據查詢引擎
* 搜尋引擎
* 渲染引擎 = [聲音引擎,繪圖引擎,遊戲引擎]

```
以某種通用的方式告訴它“執行此操作”，並且它處理細節

泛指軟件模塊普通更複雜的程序（如庫，軟件開發工具包或物體上面提到的）。
軟件模塊保持靜態，直到被另一個模塊調用為止。
響應該調用，計算機的指令指針開始通過被調用模塊中的代碼跟踪其方式。
圖靈機是一個軟件模塊，它根據所包含的算法來更改其狀態。

相反，軟件引擎的思維模型是一台機械引擎，它可以啟動和停止，並且可以閒置一段時間。
軟件引擎的示例包括[關係數據庫引擎,工作流引擎,推理引擎,搜索引擎]。
軟件引擎的一個共同特徵是元數據，它提供了引擎處理的真實數據的模型。
軟件模塊將數據傳遞給引擎，引擎使用其元數據模型將數據轉換為不同的狀態。
與他們的思維模型相一致的軟件引擎的另一個特點是能夠調整軟件引擎以實現最佳性能。
相反，只能通過重寫軟件模塊來“調整”軟件模塊。
在數據科學中，您可以使用數據服務引擎（例如流引擎或數據轉換引擎）來轉換數據，這是重型應用程序的要求。
引擎的其他示例包括需要大量視覺優化的好萊塢電影中的音頻，視頻，圖像處理引擎以及專用的渲染引擎。
NMap有一個腳本引擎，許多Nnet也將決策引擎用於其DM模型。
```

# [iot hub]()
* [PTC ThingWorx](http://support.ptc.com/help/thingworx_hc/thingworx_8_hc/zh_TW/index.html#page/ThingWorx%2FHelp%2FInstallation%2FThingWorxDockerGuide%2Fthingworx_docker_getting_started.html%23) 用docker開始
* [thingsBoard](https://thingsboard.io/) (OSS)

# IRCd
* 很多`聊天工具`只是這個東西的加一層皮

# 寫死 Hard Code
* 參數或資料 直接寫死在程式

# [Data Collection x Streaming Data](https://medium.com/asiayo-engineering/%E5%A6%82%E4%BD%95%E7%94%A8-google-tag-manager-%E6%89%93%E9%80%A0%E5%85%8D%E8%B2%BB%E7%9A%84-data-collection-x-streaming-data-%E6%9E%B6%E6%A7%8B-d4593b88ffea)
* [常見名詞](https://shian.tw/article/238)
* [跨網域追蹤](https://medium.com/asiayo-engineering/%E8%B7%A8%E7%B6%B2%E5%9F%9F%E8%BF%BD%E8%B9%A4-%E5%AF%A6%E4%BD%9C%E8%A1%80%E6%B7%9A%E5%8F%B2-%E5%9C%B0%E9%9B%B7-%E6%9E%B6%E6%A7%8B%E9%81%B8%E6%93%87-%E8%A8%AD%E5%AE%9A%E6%95%99%E5%AD%B8-c373622226ef)
* 數位軌跡搜集
* [piwik](https://www.minwt.com/website/server/20343.html)

# Cluster的主從 職權分配
||master/server|slave/client/agent/worker/segment|
|---|---|---|
|nginx|接收外界訊號/向worker傳送信號|單一thread|
|k8s|||
|mpp|||

# Lvs(Linux Virtual Server)
```
設立Lvs的基本目的，就是要建立一套可擴充性與HA的叢集系統，
在Lvs裡，首先要有一部「Linux指引主機」(Linux Director)或稱「負載平衡器」或稱「虛擬主機」(Virtual Server)，
擔任伺服服務流量負載平衡的調節者，Linux Director本身不提供伺服服務，祇做伺服服務的配發而已
```

# Commission Host 交辦主機
* 叢集環境中添加伺服器的操作叫作“(Commission Host

# [Kubernetes(簡稱K8S)](https://godleon.github.io/blog/Kubernetes/k8s-Pod-Overview/)
```
K8S cluster == Master + []Node
Node == []Pod
Pod(部署App最小單位) == []Volume + []ContainerizedApp
(一個Pod 似乎就等於一個 Docker-Compose)
```
* Master
* Nodes
* GKE == google k8s engine == 課金懶鬼方案
* [vagrant up 就可以三節點](https://gist.github.com/danielepolencic/ef4ddb763fd9a18bf2f1eaaa2e337544)

# 網站外皮
* 掏寶感覺可買到?!

# [d4t4 celebrus](https://www.d4t4solutions.com/data-capture/)
* 

# [OWL/RDF](https://sls.weco.net/node/9195)
* 用類似xml標籤產生 關聯圖

# tagging, Tag Manager
* Tag Manager管理tag, 有tag傳送門

# 暖開機和冷開機
```
直接按POWER開啟電腦是「冷開機」。

那什麼又是暖開機呢？什麼情況下需用到「暖開機」的二種方式。

電腦當機時需用到暖開機，方法有二種：
方法一：直接按下主機上的「reset」鍵。
方法二：同時按著鍵盤上的「Ctrl」及「Alt」不動
再按下「Delete」鍵2~3下即可重新開機。

電腦當機的時候，先試試看能不能使用「暖開機」重新開機，
「暖開機」比較不會對電腦系統造成損壞，而且重新開機的速度比較快。
```

# ab Test
* 一個是`壓力測試的軟體名稱` ab
* 另一個是`測試的兩種版本的測試方法` a版本b版本


# 閾值threshold
* 通常是一個trigger event的門檻

# DAG
* 所有複雜的異步處理,其實就是個DAG圖

# Bulk Loading(DW)
感覺有點像是一包包寫入DB

# HouseKeeping(DW)
* houesKeeping 6個月就好了(MySQL), DW話應該就無上限(容量夠)
```sh
意指規律性的清理舊的記錄，刪除舊的資料、收集統計資訊和調效查詢和索引等相關事項
使得我們能夠保持資料庫執行最佳狀態，有效利用資源快速取得所需資料。
```

# [Dev(商務邏輯) Ops(工程問題) (感覺就是專門做各種領域的CI/CD)](https://rickhw.github.io/2018/06/14/DevOps/Recap-What-is-Ops/)
* DataOps
* MLOps
* DLOps
* SRE
* NoOps 無人化維運

```sh
# 其實任何領域的`雜事`能做到很輕鬆感覺精神上都是devOps,
# 聰明人做好dev, 務實人做好ops
音色,樂理,編排 ~= Dev
錄音,混音,母帶 ~= Ops
```

# Reduce規約 (有點`transform轉換` + `把stream摺併起來`的感覺)
* `前端`:在這裏意思應該是根據舊的state和Action的傳入參數，“規約"出新的state。
* `演算法`:意味著對問題進行轉換,例如將一個未知的問題轉換成我們能夠解決的問題(NP相關)
* `函數式運算`:把元素`加起來`,`整併`的感覺

# deeplink(app)
* 打開app的連結 `app:\\line\XXXXXXX`

# 前端RX
* 畫筆,拖拉...等複雜功能,很多都是mousedown,mouseup實踐
* 訂閱event > transform > 變成你想要的答案(render,再去改變action

# [NativeJS Component](https://developers.google.com/web/fundamentals/web-components/customelements?hl=zh-tw)
```js
window.customElements.define('app-drawer', class extends HTMLElement {
	// class member
});
```

```html
<app-drawer></app-drawer>
```

# [BufferOverFlow](https://books.google.com.tw/books?id=NYyKhOqOCF8C&pg=PA78&lpg=PA78&dq=bash+s-proc&source=bl&ots=zbFY-tqeuB&sig=ACfU3U17KnxyxVupRmnaQvQajChBsrDvNQ&hl=zh-TW&sa=X&ved=2ahUKEwicvYvTh9HpAhVdyYsBHeVFB6gQ6AEwAnoECAgQAQ)
* 組合語言攻擊方式

# [headless Chrome](https://developers.google.com/web/updates/2017/04/headless-chrome)
* Chrome 自 59 版起內建了 Headless 模式，允許透過命令列啟動 Chrome 以無 GUI 方式執行

# [CSP(可以理解成 網頁資源加載白名單)](http://www.ruanyifeng.com/blog/2016/09/csp.html)
* 可防XSS

# DRM
可保護影片觀看用

# 跨來源資源共用 CORS(跨域請求)
* 所以後端 要記錄 `發出request的Client的domainName`(感覺用`*`就形同虛設)

# 第一方cookie, 第三方cookie 
* 以`域`區分, `本域`==第一方, `非本域`==第三方

# 線上(行為紀錄)/現下(valueable)
* 線上資料:行為紀錄(感覺就是OLAP的那些
* 現下資料:重點資料(個資,款項,感覺就是OLTP的那些

# [第一方資料, 第三方資料](http://fredbigdata.blogspot.com/2016/03/1st-party-2nd-party-3rd-party.html)


# 聯邦學習(Federated Learning)
* 感覺有點像分散式

# Mysql Explain Visualizer
* [反正一片綠油油就棒棒](https://dev.mysql.com/doc/workbench/en/wb-performance-explain.html)

# volatile揮發性(關鍵字,`正確性`跟`速度`取捨

|語言|C|Java|
|---|---|---|
|有volatile會讀|該`變數實體位址`|主記憶體(main memory)|
|無volatile會讀|CPU暫存器|各執行緒有各自的記憶體空間(working memory)|

* 有點感覺像是 讀不讀cache的感覺(看有沒有被更新
* 有`正確性高`,沒有`效率高`
* 應用:io編程,多執行緒

# ffi 可寫其他語言的接口
Python: CFFI调用C的功能接口

# 服務之間通訊方式，
* 從最無腦的共用資料庫: share database / stroage, 
* 到非同步通訊: event driven (publish / subscribtion), event sourcing (stream data + cqrs), 
* 到同步通訊: HTTP RESTFul / gRPC 

# Apache Thrift(就是RPC,打破語言屏障
* 可讓不同語言得以溝通
* 讓php也可以做大數據(php操作hive, hbase)
* 感覺讓相異語言`不直接耦合`,可做到`解藕`(做到`函式級別`的跨語言

# Dubbo()
* A high performance Java RPC framework

# Linux RPC方案(這樣就可以僅靠alpine就搞 分散式)
* 靠NFS共享目錄 
* mkfifo 發布/訂閱
* 用watch + nohup + screen 監聽訂閱 

# RMI 遠程調用 (可看做Java RPC)
* 能夠讓在某個 JVM 上的對象調用另一個 JVM 中的對像上的方法
* 感覺是process級別的 同步溝通

```java 
// 被叫端
// 把遠程對象註冊到RMI註冊服務器上，並命名為hello
Naming.bind(
  "rmi://localhost:8888/hello", 
  hello = new HelloImplement()
);

// 呼叫端
IHello rhello = (IHello) Naming.lookup("rmi://localhost:8888/hello");
System.out.println(rhello.helloWorld());
```

# 編碼
有这么多编码，都是为了实现`兼容`和`效率`的平衡，兼容性越高的编码就需要牺牲越大的存储空间。
```
ASCII：最简单的编码，不能解析中文
ANSI：ASCII的扩展，可以解析中文，兼容差，效率高
Unicode：ANSI的扩展，兼容强，效率低
UTF8：Unicode的扩展，通用
```
### 常用工具打开文件的解析方式
最常用接触就是ANSI和UTF8两种编码
```
ANSI：Windows，DOS，记事本，UltraEdit，Excel，Oracle
UTF8：Linux，Hadoop，Python、记事本
其中记事本可以自动解析ANSI和UTF8。
如果我们在Windows打开文件出现乱码，一般都是因为文件是UTF8编码，用记事本打开就可以正常显示，把文件另存为ANSI编码，就可以用其他工具正常打开。

反过来，传到服务器端后台打开是乱码，一般是服务器默认解析UTF8编码，把文件转为UTF8编码就可以正常读取。
```

# dba式coding(可讀性極差,但極省時
```sql
# select then insert
INSERT INTO table_name(column_list)
SELECT 
   select_list

# select then delete
DELETE FROM posts WHERE id IN (
    SELECT * FROM (
        SELECT id FROM posts GROUP BY id HAVING ( COUNT(id) > 1 )
    ) AS p
)

# select then update
UPDATE "SKFH"."tmp_test_PAGE_CNF" pc
SET
  pc.ISSKBPROCESSED = 'Y',
  pc.ISSKLPROCESSED = 'Y'
WHERE exists (
  SELECT pc.sessionnumber,pc.SKB,pc.ISSKBPROCESSED,pc.ISSKLPROCESSED,pc.SKL
  FROM "SKFH"."tmp_test_PAGE_CNF" os
  left join "SKFH"."tmp_test_PAGE_CNF" pc on os.sessionnumber = pc.sessionnumber
);

# select then create
CREATE TABLE 表 AS
SELECT ....
```

# 強耦合 鬆耦合 的心得
* 命令式語言感覺就是鬆耦合,容易整合,但是不直接
* 宣告式語言感覺就是強耦合,不好整合,直接表示結果
* 框架,interface,等等 感覺就是想讓東西調整成鬆耦合,容易整合
* 硬體焊死,壞掉時就不能抽換,就是種`過度耦合`

# 雙向（bi-directional）& 全雙工（full-duplex）
* 雙工duplex == 雙向的資料傳輸
* 半雙工（half-duplex）的系統允許二台裝置之間的雙向資料傳輸，但不能同時進行
* 全雙工（full-duplex) 系統允許二台裝置間同時進行雙向資料傳輸

# PMML（預測模型標記語言 Predictive Model Markup Language
* AIModel是一種物件, PMML==該物件的序列化
* PMML == 特徵值DSL ?
* 機器學習佳, 深度學習就有點不推薦使用


```
我有一個決策樹模型, 使用效果也不錯, 
那麼就可以把樹的結構(節點間的父子關係, 節點內的豐富信息等)序列化為PMML文件, 
共享給其他人使用.  
這樣無論你的模型是sklearn,R還是Spark MLlib生成的，
我們都可以將其轉化為標準的XML格式來存儲。
當我們需要將這個PMML的模型用於部署的時候，
可以使用目標環境的解析PMML模型的庫來加載模型，並做預測。
```

# GPG加密
```sh
# 範例
gpg --recipient yufufu --output .\test.gpg --encrypt .\src.csv
gpg --recipient yufufu --output .\test.gpg --decrypt .\src.csv   # 需要secret-keys

# 查看
gpg --list-keys  # pub
gpg --list-secret-keys  # pri
gpg --check-sig

# 異動操作
gpg --gen-key   # 產 公鑰,私鑰
gpg --armor --output yufufu.asc --export  # export
gpg --import ./yufufu.asc   # import

```

# linklist
* node 可為陣列 => xml,html
* node 只能字串 => json

# 特徵值DSL
```
從視覺稿產出的 DSL 中提取預定義的特徵值，用傳統學習多分類的方法來實現模組識別。
本識別功能最終返回業務模組的類別、視覺稿中的位置等資訊。
```

# 違反可測試性 就會去破壞production


# 跨境電商門檻
* 跨境支付
* 跨境物流

# 測試
* UAT (User Acceptance Testing)使用者驗收測試
* SIT (System Integration Testing) 系統整合測試，也叫做整合測試

# register
* 註冊
* 暫存器

# Procedural Programming (一種範式
* 其實就是逐航執行的髒扣

# Structured Programming (一種範式
* 在這以前就是goto幹天下

# UnStructured Programming (一種範式
* `靈活`可以實現`協同程序`

```sh
非結構化程序設計引入了基本控制流的概念，比如循環、分支和跳轉。
儘管在非結構化模式中不存在過程，不過子程序還是可以使用的。
和過程不同，子程序可能有多個入口和出口。子程序中是允許直接跳轉入或跳轉出的。
這種靈活性可以實現協同程序，而這在過程化程序設計中是相當困難以至於不可能的。

非結構化程序設計中是沒有本地變量的概念的，不過標籤和變量可以在有限的區域中起作用，
比如，線組。這意味著在調用子程序時不需要上下文刷新，而所有的變量保持它們之前被調用後的值。
這樣，實現遞歸就很困難了。而嵌套的深度被限制在1或2級。
```

# 限制越弱的東西，功能就越強(小範圍用起來越方便，但也越容易破壞工程約束和實踐
* goto
* eval

# KEEP (DENSE_RANK FIRST/LAST)

# set operation & record operation 

# [Fintech DSL](http://www.dslfin.org/resources.html)

# dApp 太慢解決方案3(幾乎都是折衷方案
* 代議 EOS (人民代表
* 某些 交易 鍊下執行(分層
* 並行化方案 POS(分片

# Backend aaS 後端即服務
* 處理掉很多 後端應用上常用的共通邏輯
* client有個agent,sdk之類的
* [FireBase](https://litotom.com/2017/07/18/why-firebase-2/)(Google)
* [parse](https://docs.parseplatform.org/) OSS
* [Kuzzle](https://kuzzle.io/) OSS
* noSQL支援良好??

# AdHoc Query臨時查詢
```js
// 即席查詢是在發出查詢之前無法確定的查詢。創建它是為了在需要時獲取信息，
// 它由動態構造的SQL組成，該SQL通常由桌面駐留的查詢工具構造。
var newSqlQuery = "SELECT * FROM table WHERE id = " + myId;
```

# AdHoc Network

# Reactive MicroService

# Networking virtualization
* linux bridge
* iptable


# [sql Analytic Functions](https://docs.oracle.com/cd/E11882_01/server.112/e41084/functions004.htm#SQLRF06174) 

用來計算 aggregate
```
sql => over(某些場景可取代self join)
sql => an window function
 
sibling
windowing
```
* [窗口函數](https://www.jianshu.com/p/6f0f26a168ef)

# 編程範式的infra
* ex:事件驅動的 event scheduler, event connector(event hook)訂閱事件且並也invokeFunctionOrEndpoint

# 眾包crowdsourcing
* 指的是一個公司或機構把過去由員工執行的task，以自由自願的形式外包給非特定的（而且通常是大型的）大眾網絡的做法
* `區塊鏈礦工`感覺就有點像是`眾包`

# on premise(就地部署,地端) <--> XaaS(X即服務,雲端)
![](https://github.com/zero85258/MyNOTE/blob/master/img/XaaS.png)

# 看門狗Watchdog(硬體)
```
功能是定期的查看芯片內部的情況，一旦沒有持續`餵狗`就向芯片發出reset信號。
從本質上來說就是一個定時器電路，一般是連接到單片機，
一般有一個input(餵狗)和一個output(一般連接到另外一個部分的重置端)。
```

# Function Watchdog(serverless)

# AfterBurn(取捨 平衡機制？)
* cpu風扇轉速就能輕易在`性能表現`與`溫度`中 取捨 最佳平衡
* `高並發性`和`吞吐量` 取捨 最佳平衡

# Apache Tika
* 萬用型的檔案內文抽取工具，我們可以用指令列來操作Tika，就能從PDF、Microsoft Office、Open Document、純文字檔案等文件抽取內文。非常好用！
```sh
# 就是這傢伙
tika-app-1.14.jar
java -jar ~/Desktop/tika-app-1.14.jar XXXX.pdf  > XXXX.txt
```

# Predict 預測
* 其實就是 `公式`
* 程式上`predict(model, data)`通常是return`數值`(預測結果)

# 數據充實data enrichment 
* 被定義為將來自外部權威來源的`第三方數據`與現有的`第一方客戶數據`數據庫`合併`

# 傳統install
* 其實就是extract compress

# Unikernel Systems(比container還輕)
* conventional OS <==> library OS
* Runtime.js 可玩玩看 (感覺有點像vagrant的感覺)
* 搭配qemu(vm) 


# 純量語言 <---> 向量語言
* 向量語言vector ~= 函數式編程 
* R裡叫做純量, Java是混合範式但也叫做vector 
* python-pandas,R-data.frame,java-vector,laravel-collection 基本上使用都差不多

# [詞向量,詞嵌入]()
* ![](https://github.com/zero85258/MyNOTE/blob/master/img/wordEmbedding.png)
* word =encode=> vector =classification=> word class ==> word embedding


# \*.vmoptions檔(調校JVM
* 破解蠻多軟體時都會用到的技能

# CTE (Common Table Expressions) & Window Functions
```sql
# CTE 有點像是變數功能(就不用寫一堆重複的subQuery了)
WITH OrdersTable( OrderID, CustomerID, EmployeeID ) as
(
  Select OrderID, CustomerID, EmployeeID 
  from dbo.Orders
), 
OrderDetailsTable( OrderID, TotalPrice ) as 
(
  Select OrderID, SUM(Price) 
  from dbo.[Order Details]
  group by  OrderID
)
Select * 
From OrdersTable A 
inner join OrderDetailsTable B  on A.OrderID = B.OrderID 
```

# Materialized view 具體化視觀表(DW)
* 提高查詢效能和複製、同步資料

# 那些最難搞定的鳥事
* 編碼,時間,地區,語系,符點數

# Unicode, UTF-8, ASCII ,GBK(中文)
```sh
iconv -f ascii -t utf16 file2.txt > another.txt
cat unicode.txt | ascii2uni -a U -q  # unicode to utf-8
#iconv -f UTF-16 -t UTF-8 input.json > rst.json
```

# 控制字元(又叫逸出字元？
* [可視化](https://www.soscisurvey.de/tools/view-chars.php)

# UTC ISO
* mongo記得時間就是UTC
* UTC是`時間標準`; ISO-8601是表示時間的一種標準`格式`(長的像這樣2018-6-5T17:46:50ZUTC)
* UTC + 8 == ISO
```
2016-01-18T23：41：00裡面的T表示UTC，
所以這個字符串解析後就表示UTC時間的2016-01-18 23:41:00，
那麼再轉換為北京當地時間展示（
比如，在JavaScript中 裡面new Date（'2016-01-18T23：41：00'）。
toLocaleString（））時就會加上8小時的偏移，變成：2016-01-19 7:41:00。
```

# Active Directory(Win)
* 搶票用這個 時間為準time.stdtime.gov.tw
* GPO
* ntp網路時間協定

# LDAP/AD(Active Directory) 整合

# R語言 學 工程數學

# 我只會算數
* 冪 == 在代數中的意思是指乘方`運算的結果`
* 冪等:`作用1次`跟`作用n次`的結果相同
* 冪零:
* 線性:技術面來說,就是沒有分支行為的模組,函式
* 正交:指相互獨立，不可替代，並且組合起來可實現其它功能; 幾何概念中，本意是垂直。
* 奇異:是數學物件中無法處理的點
* 熵(Entropy):東西在轉換過程中耗散的、無法再利用的部分,東西的無序程度數值化
* Gini不純度(Gini Impurity)
* 凝合:感覺是`離散`變成`連續`的過程,也可以理解為`訓練過程`
* 梯度（gradient）是一種向量,梯度的方向是函数f增长最快的方向
* coefficient係數 vs factor因數
* 秩rank:

# 不同的領域 概念的映射(數學)
```sh
所有東西 == 基本原理 + 組合規則(基本就是加跟乘) # 不同的領域常常會重新定義類似乘法的概念和類似加法的概念
向量 == 基本向量 + 線性疊加
```
* 對於 `函數`，類似乘法的概念是`積分`
* 對於 `向量`，類似乘法的概念是`內積`

### 正交 Orthogonal
* 正交在線性代數中，2向量正交 指 它們2個`向量`內積為 0。
* 正交在函數中，2函數正交 指 它們2個`函數`積分為 0。

# 線性代數
* 就是用來解這些 "解空間" 相關的學習, 包括 "特徵值", "向量運算", "變換矩陣", "回歸" 等等的計算方式
```
n維的空間向量：向量的長度、內積與直線之參數等。
矩陣的代數運算。
線性聯立方程式之解：高斯消去法等。
向量空間：線性組合、獨立與相依及矩陣之秩等。
線性映射：核空間、像集、線性轉換代表矩陣及基底變換等。
內積空間：內積、正交性。
行列式。
特徵向量與特徵值。
矩陣之對角化。
歐基理德內積空間。
矩陣喬登正則形式(Jordan Canonical Forms)。
```

# 模數
```sh
# 這是除 8 / 3
# 這是模 8 % 3 (程式裡大部分好像都是)
```

# WireShark
* 指定要監聽哪個 網卡,linux bridge
* 可用termshark

# interaction ,REPL(Read-Evaluate-Print-Loop)交互式介面
* laravel tinker, 那種就是

# `主機host` && `虛擬機guest`
* host 找 guest => 內網ip
* guest 找 host => GatewayIP


# ETL
* [informatica](https://docs.informatica.com/data-integration/powercenter/h2l/how-to-install-informatica-using-a-docker-utility/how-to-install-informatica-using-a-docker-utility.html)
* `hortonworks HDP`:基於hadoop的pdi
* Talend ETL(比較for IT)
* google cloudFusion
* aws Glue 感覺是etl服務

# micro SI, 軟體經銷商(OSS Explorer)
* 景佳科技
* omniware
* inwinstack
* 弘一 informatica
* [trinity](https://tw.trinity-data.com/?FID=21&CID=63) (台灣)

# BI
* SAS viya
* SAS va

# HPE Container Platform
* 小公司做死做活 == 弄一套這個

# 超融合式基礎架構 HCI
* IDC + Infra all in  機櫃

# OOP與FP的最大區別在於數據是否是`強制不變性`

# 質化,定向 quantitative && 量化,定量 qualitative

# 正面表列 vs 負面表列 (表列==Listing)
* `可以做的` and `不行做的`
* 感覺常用在 Policy

# 顯式Implcit && 隱式Explicit
* `感覺`前者有點像`不需明文規定`,後者有點像`需明文規定`,
* [C#關鍵字](https://ronsun.github.io/content/20170924-explicit-implicit-keywords.html)

# Objective客觀 vs Subjective主觀

# 開發環境堆疊

# XSL, XSLT
* 感覺蠻常用在 Decision Tree Model
* XSLT  比較像是`程式碼`,將XML文檔轉換為其他XML文檔或其他格式的`語言`

# Niantic (AR Engine)

# entrypoint 種類
* callback URL 
* Auth URL 
* Access Token URL

# notation 標記法
* 很多DSL的解決方案

# NuGet + Chocolatey
```
NuGet的出現改變了"東市買駿馬，西市買鞍韉"的程式庫繁瑣安裝程序；
Chocolatey則透過PowerShell Script結合NuGet套件格式，
試圖提供單一指令完成Windows的程式下載安裝，營造類似apt-get的便利性
```

# 綠色軟體
```sh
# .install(舊名稱為.app，建議一律改用.install)
指透過MSI、Setup.exe安裝檔安裝，可能會更動Registry、Program Files目錄、系統檔案等，
常需升級管理者權限，移除時需透過解除安裝程序。

# .portable(舊名稱為.commandline、.tool，建議一律改用.portable)
即所謂綠色軟體，只複製檔案至單一目錄，不需更動Registry、系統檔案，
移除時刪除檔案即可，但會損失如副檔名關聯、右鍵選單等系統整合功能。
```

# VNC RDP
* RDP == win系列`連線`到其他主機的那個
* noVNC == 導覽器用的遠端桌面

# GUI container
X11視頻轉發

# OS GUI
```sh
x11vnc # 使用戶可以從用戶自己的網絡上的遠程計算機或通過Internet 來控制自己的X11桌面
fluxbox # X視窗管理員 輕量級和可客製化。所有的基本組態通過文字檔案來控制。它的使用者介面僅有一個工作列與右鍵彈出式選
gnome 
xvfb  # 可以直接處理 Window 的圖形化功能，並且不會把圖像輸出到螢幕上
ncurses # 獨立於終端的基於文字的使用者介面。它是一個虛擬終端中的「類GUI」應用軟體工具箱
```

# JTAG協議(硬體)
* JTAG協議就是用來控制CPU
* JTAG是`最底層`的協議

# 旁路（Side Channel）

# pipeline管線化

# 不務正業 OSS , Solution
* [KiCad](https://medium.com/@t104310068/kicad-%E5%AD%B8%E7%BF%92%E5%BF%83%E5%BE%97-%E4%B8%8A-b8f3ae42de7a) 電路繪製EDA oss
* GNU Octave :linux 版本的 Matlab  
* icarus verilog (oss verilog
* [SiPaaS](https://www.verisilicon.com/cn/Home) 晶片設計即服務
* [硬體棒棒網站](https://cocdig.com/)
* [chisel](https://github.com/freechipsproject/chisel3) 用很物件導向的方式設計硬體
* AOI自動光學檢測
* epaper 跟紙一樣薄的顯示器

# PPA(晶片設計原則) 3者 取捨
* `Performance性能`, `Power功耗`, `Area面積` 3者`取捨`,
* 流水線級數:`性能↑功耗↓`, 總線寬度:`性能↑面積↓`, 硬核處理單元數量:`性能↑功耗↓面積↓`

# 南僑晶片 & 北僑晶片
* 北橋晶片主要控制 `CPU` 與 `MainMemory` 以及 `PCI匯流排`之間的訊號傳輸，現今的更加有 AGP (Accelerated Graphic Port) 圖形加速匯流排的控制功能；
* 南橋晶片主要控制 `ISA匯流排`及`PCI匯流排`上速度較慢的`週邊設備`。

# 異構計算(普遍來說就是`硬體加速`)
* openCL,Cuda,openVX
* 感覺是CPU,GPU,FPGA,DSP的編程的adapter
```sh
# OpenCL 中，則大致的流程是：
把 OpenCL 裝置初始化。
在 OpenCL 裝置上配置三塊記憶體，以存放 a、b、c 三個陣列的資料。
把 a 陣列和 b 陣列的內容，複製到 OpenCL 裝置上。
編譯要執行的 OpenCL 程式（稱為 kernel）。
執行編譯好的 kernel。
把計算結果從 OpenCL 裝置上，複製到 result 陣列中。
```

# NGC Docker(NVIDIA GPU CLOUD
* 提供一系列完備的 GPU 加速深度學習、機器學習和 HPC 應用軟體

# 行銷相關
* Attribution歸因理論 == 說明和分析`人們活動因果關係`的理論
* Data-driven attribution 數據驅動 `人們活動因果關係`
* DDA 消費者轉換lifeCycle 路徑長度 && 轉換耗時 && 裝置路徑 &&  歸屬模式

# `並行程式語言`中`同步程式執行`的`構造` (future、promise、delay和deferred
* 由於某些計算（或者網路請求）尚未結束，我們需要一個物件來代理這個未知的結果
* 是指用於在某些`並行程式語言`中`同步程式`執行的構造。

# 裝飾子
```js
function isTestable(value) {
    return function (target) {
        target.isTestable = value;
        return target
    }
}
// isTestable 是個 function
// isTestable(true) 是個 decorator
@isTestable(true)
class MyComponent {
    // ...
}
console.log(MyComponent.isTestable) // true
```

# 抽象語法樹（Abstract Syntax Tree，AST）
* 一種資料結構
* 通常是編譯器要用到的東西 (分析程式碼語法)
* 不知可否跟NLP有啥結合

# 程式碼靜態分析
* [Sourcetrail](https://github.com/CoatiSoftware/Sourcetrail) OSS

# One-hot vs One-cold
* 數位電路 中 位元組合,只能有一個1(hot) == One-hot,只能有一個0(cold) == One-cold
* 機器學習 中 在一任意維度的向量，僅有一個維度的值是1，其餘爲0。ex:[0 0 0 0 0 1 0 0 0]

# XA == 分佈式事務的規範
```sh
# XA規範主要定義了(全局)事務管理器(Transaction Manager)和(局部)資源管理器(Resource Manager)之間的接口。
# XA接口是雙向的系統接口，
# 在事務管理器（Transaction Manager）以及一個或多個資源管理器（Resource Manager）之間形成通信橋樑。

(全局)事務管理器（Transaction Manager）<= XA接口 => (局部)多個資源管理器（Resource Manager）

# XA之所以需要引入事務管理器是因為
在分佈式系統中，從理論上講，兩台機器理論上無法達到一致的狀態，需要引入一個單點進行協調。
事務管理器控制著全局事務，管理事務生命週期，並協調資源。
資源管理器負責控制和管理實際資源（如數據庫或JMS隊列）。
```

# 分布式系统的2PC和3PC (2階段提交,3階段提交)
* 為了讓分散式系統保持ACID,一致性
* 2PC 的演算法思路可以概括為：`參與者`將`操作成敗`通知協調者，再由`協調者`根據所有`參與者`的`反饋`決定各`參與者`是否要`提交操作`還是`中止操作`。
* 第一階段：準備階段, 第二階段：提交階段
```
用以分散式交易的一種設計， 主要分為2個階段，
1 phase 由一個主要服務對其他服務發起請求交易
2 phase 收到所有服務回傳的結果，都成功則提交交易成功，或有失敗的結果則通知其他服務將剛剛的交易roll back
```

![](https://github.com/zero85258/MyNOTE/blob/master/img/2pc.png)

# Distributed Transaction Coordinator 分布式事務協調器(DTC)
* 協調 == 彙整多個投票結果
```
如資料庫、消息隊列、文件系統，跨應用程式域、進程、機器以至跨網絡的分布式事務處理的所有參與者的協調。
事務完成時，會啟動2PC協議：
```
* 第一階段提交：`root機器`上的DTC =notify=> 參與事務的所有`remote機器`上的DTC收集自己機器上所有資源管理器的投票結果，並返回給`root機器`上的DTC。
* 第二階段提交：`root機器`上的DTC綜合所有資源管理器的投票結果，然後notify參與事務的所有`remote機器`上的DTC通知自己機器上所有資源管理器提交事務或終止事務

# L4和L7負載平衡有什麼區別
* 越底層越輕,效能好,功能少,反之

# Distributed Lock快取同步
* Chubby == Distributed Lock Service
* Chubby是一個Lock Service也提供文件儲存。

# 開源實現
```
而Zookeeper其實就是Chubby的開源實現;
就像Hadoop是MapReduce的一種開源實現;
就像Kubernetes是Borg的開源實現一樣。
```

# [分散式系統](https://ithelp.ithome.com.tw/articles/10215645)，都會碰到的兩個問題就是
* 選Leader，分散式系統裡的節點要能夠選Leader，對誰是Leader有一個共識
* 儲存資料的一致性

# Atomic Broadcast 原子性廣播
* ZAB == Zookeeper Atomic Broadcast
```sh
在容錯 分佈式計算中，原子廣播或總順序廣播是一種廣播，
其中多個進程的系統中的所有正確進程都以相同的順序接收同一組消息；
也就是說，消息順序相同。
被稱為“原子”廣播，因為它要么最終在所有參與者處正確完成，要么所有參與者都終止而沒有副作用。原子廣播是重要的分佈式計算原語。
```

# [Zookeeper](https://segmentfault.com/a/1190000014642335)
* 協調用?
* `linkedin開源的KafkaMQ`和`阿里開源的metaq`都是通過zookeeper來做到生產者、消費者的負載均衡

# [Outbox Pattern(分散式原子性)](https://ithelp.ithome.com.tw/articles/10235821)
* 核心概念是把大事務轉變成小事務

# Saga Pattern(分散式一致性)
* 解決 微服務間的資料一致性 
```
會將交易所需要使用到的各個服務串起，
每個服務被呼叫的時候就會去更新自己的資料庫或儲存空間，
當某一個服務發生錯誤時就會進行補償機制，
對已經執行過的服務進行補償。
```

# [Saga, Choreography vs Orchestration](https://ithelp.ithome.com.tw/articles/10236411)
* [Choreography vs Orchestration](https://medium.com/skyler-record/%E5%BE%AE%E6%9C%8D%E5%8B%99%E6%9E%B6%E7%9A%84%E8%B3%87%E6%96%99%E4%B8%80%E8%87%B4%E6%80%A7-1-saga-pattern-cf05aed1307b)

# Saga長事務模型
* 一種用以取代2PC，避免2PC造成資源block的設計架構
* 感覺有點像拆分事務???

```sh
但其實Saga並不是什麼新事物，在我們傳統的系統設計中，
它有個更熟悉的名字——“ProcessManager”，
只是換了個馬甲，
還是乾同樣的事——組合一組邏輯處理複雜流程。
但它與我們平常理解的“ProgressManager”又有不同，

# 它的提出，
最早是是為了解決分佈式系統中長時間運行事務(long-running business process)的問題，
把單一的transaction按照步驟分成一組若干子transaction，
通過補償機制實現最終一致性。

# 舉個例子
在一個交易環節中有`下單`,`支付`2個步驟，

# 如果是傳統方式，
兩個步驟在一個事務裡，
統一成功或回滾，
然而如果支付時間很長，
那麼就會導致第一步，
即下單這裡所佔用的資源被長時間鎖定，
可能會對系統可用性造成影響。

# 如果用Saga來實現，
那麼下單是一個獨立事務，
下單的事務先提交，
提交成功後開始支付的事務，
如果支付成功，
則支付的事務也提交，
整個流程就算完成，
但是如果支付事務執行失敗，
那麼支付需要回滾，
因為這時下單事務已經提交，
則需要對下單操作進行補償操作（可能是回滾，也可能是變成新狀態）。

可以看到Saga是犧牲了數據的強一致性，
實現最終一致性。
```

# Try-Confirm-Cancel Pattern
* 分布式原子性


# EDM電子報行銷
* [benchmark](https://www.benchmarkemail.com/tw/pricing/)

# MDM行動裝置管理

# Portlet iframe
* liferay

# 演算法商店
* [Algorithmia](https://algorithmia.com/product)

# [e2e Recorder](https://github.com/puppeteer/recorder)
```sh
# 用Puppeteer,cli敲下這樣就他媽開始錄,打叉叉回傳腳本
npx @puppeteer/recorder www.google.com
```

# `共識Consensus`機制

|幣種|共識算法|
|---|---|
|BTC|POW|
|ETH|POW|
|LTC|POW|
|Peercoin|PoS|
|NXT|POS|
|ARDR|POS|
|Bitshare|DPOS|
|EOS|DPOS|
|LSK|DPOS|
|XAS|DPOS|
|NEO|DBFT|
|ZIL|PBFT|
|QTUM|POS+IPOS|
|AE|POS+POW|

# POP3
* 它規定怎樣將`個人計算機`連線到`Internet的郵件伺服器`和`下載電子郵件`的電子協議。

```sh
# 它是電子郵件的第一個離線協議標準,
# POP3 允許使用者 mv 伺服器/郵件 使用者的計算機/郵件 ,
POP3伺服器 == 接收郵件伺服器，用來接收電子郵件的。
```

# SMTP管『發』，POP3/IMAP管『收』
![](https://github.com/zero85258/MyNOTE/blob/master/img/smtp.png)

# [知識管理核心](https://rickhw.github.io/2019/01/21/Management/KM-and-Issue-Tracking/)
* `L0 口頭`：問題沒有回報流程、標準化、輕重緩急，不知道 Priority & Severity、Email 滿天飛，文件到處亂丟。
* `L1 有記錄`：用類似 excel / word 工具整理發現的問題，沒協作流程、議題沒有 生命週期規範
* `L2 有協作`：系統化紀錄，用類似 Redmine、Jira 協做, 但沒有標準化流程/回報標準格式，開始有 Priority 概念，但沒有 Severity 概念。
* `L3 用流程效率化作業`：有標準化流程、生命週期、回報格式、關連議題、有 Severity 概念, 知道如何判斷 Priority / Severity 的差異
* `L4 知識庫`：生命週期有管理，歷史資料成為有參考價質的知識庫。能控 S & P
* `L5 守護與探索標準化`：過去 Severity 1 的 bug 被寫成自動化測試，每次 release 前，在 regression 都能反複確認。有自動化測試開發程序。有專門團隊制定產品標準化流程，並切透過系統化實踐到現場。
* `L6 認證`：L5 守護整個產品的可靠性，提升產品價值，形成認證標準，輸出最佳實踐，形成體制化，輸出給其他團隊，創造價值。
* `L7 獨立成為營收單位`：可以對外輸出價值，產品化。

# NoOps
* [Buddy](https://buddy.works)

# GNU GRUB
* 是一個來自GNU專案的啟動載入程式(bios?)

# [Bootstrap Root Filesystem](https://b8807053.pixnet.net/blog/post/3611632)(嵌入式)
* 提供一個最簡單、陽春且可開機的環境；製作完成的系統可開機到shell模式，並可使用 busybox 提供的指令。
* 首先，您必須準備一台 host 開發環境，並安裝好 cross toolchain；
* 接著，由於本文是做實機測試，因此，如果您沒有 ARM9 開發板，可以考慮使用 Qemu 來做模擬測試。

# 資料探勘（DM）
* 一般流程（資料清洗，特徵提取，建模，調參）

# KNIME 
* ML,DL的 任務DAG + 可視化工具
* PMML轉換成對應的機器學習模型

# Data Science Studio (DSS)
* [Dataiku DSS 不得了的資料科學服務](https://hub.docker.com/r/dataiku/dss/)
* tableau 
```sh
docker run -p 10000:10000 -d dataiku/dss
```

# [Open Scoring](https://openscoring.io/) 在線預測服務
* 以 PMML 作為格式的模型文件部署`在線預測`服務，RESTful 客戶端/服務器端實現
```sh
curl -X PUT --data-binary @MyModel.pmml -H "Content-type: text/xml" http://localhost:8080/openscoring/model/MyModel
curl -X GET http://localhost:8080/openscoring/model/MyModel
curl -X POST --data-binary @input.csv -H "Content-type: text/plain; charset=UTF-8" http://localhost:8080/openscoring/model/MyModel/csv > output.csv
curl -X DELETE http://localhost:8080/openscoring/model/MyModel
```

# TensorFlow Serving (在線預測service
* 類似openscoring
* 比較屬於`深度學習`的


# 各BU報表設計
* 廣告:`流量趨勢`、`跳入/跳出頁面`、`廣告(含其他子公司導流)與行銷活動`、`站內搜尋`、`熱門功能與目標達成`
* 電商:

# 水晶報表
* 古老像是excel的報表工具,很貴

# 報表內嵌語言

# 資料科學名詞
* `資料角力Data Wrangling`:目的是為了視覺化或者機器學習模型需求，必須將資料整理成合乎需求的格式
* `資料滾動`:
* `數據傾斜`:就是我們在計算數據的時候，數據的分散度不夠，導致大量的數據集中到了一台或者幾台機器上計算，這些數據的計算速度遠遠低於平均計算速度，導致整個計算過程過慢。
* `資料遮罩Data Masking`例如電話號碼2562-2880會變成25*2-*8*0
* `數據質量`是指定性或定量信息的狀態，數據質量有很多定義，但是如果數據“適合於其在運營，決策和計劃中的預期用途”，則通常被認為是高質量的。
*  `資料清洗Data Cleansing` == 數據質量報告DQRepot + NoiseRemove(錯誤值,離群值) + MissingValueEnrichment 

# 迴歸Regression
* 迴歸regression == 可以理解就是拿`數值`理出`公式`(`公式` == 預測
* logistic迴歸

# 推薦系統種類(統計Visualization)
* fm, nfm, gcmc, mcrec, pinsage, cke, kgcn, ripplenet, kgat
* 推薦系統 ~= 過濾系統
* 大數據 | 推薦系統 | 小數據
* 一種過濾系統
* 基於內容推薦
* 協同過濾(collaborative filtering)

# Insight 洞見
* 大數據 + 過濾 == 洞見資料

# 評分卡(統計Visualization)
* 交叉表Cross Tabulations(少維度)
* 評分卡Scorecard (多維) (授信,行銷,信用

# 統計指標 (算法,決策的 取捨 指標)
* woe轉換(比率,在大自然裡 很難看出group level差異 感覺有點像取log
* 模型ks值(Kolmogorov和Smirnoff)衡量`模型的區分能力`的值 => `越大越棒棒`
* 吉尼係數(Gini Coefficient)衡量`數值分佈不均勻`狀況
* 洛倫滋曲線(Lorenz Curve)衡量 該曲線`東西的分配情況`。在這些應用當中，經濟學家經常把它用來衡量東西是否公平
* ROC曲線 `線越接近上方，表示真陽率越高，即判斷正確的比率越高`
* AUC:Area Under ROC Curve(ROC曲線下的面積)`效能越好` => `面積越大`,
* 單因子分析(==單變數分析) 

![](https://github.com/zero85258/MyNOTE/blob/master/img/roc-curve.png)

### 單因子分析 (==單變數分析)

```js
單因子分析 = [
  "母體穩定度指標(Population stability Index; PSI)",  // 所謂特徵穩定性，就是關注該特徵的取值隨着時間的推移會不會發生大的波動。
  "訊息價值(Information Value; IV)", // 變數的預測能力，
  "相關係數(Correlation Coefficient)", // 主要衡量兩變數間「線性」關聯性的高低程度。
  "變數篩選(Variables Selection)",
]

// 但是，其中最主要和最直接的衡量標準是變數的預測能力。
挑選入模變數考慮的因素 = [
  "變數的預測能力",
  "變數之間的相關性", // 判斷變數間的獨立性 == if 類別型 => 卡方檢定(pValue) else 數值型 => T檢定, anova檢定
  "變數的簡單性(容易生成和使用)",
  "變數的強壯性(不容易被繞過)",
  "變數在業務上的可解釋性(被挑戰時可以解釋的通)"
]
```

### 靈敏度、特異性、FPR和閾值之間的關係

```sh
靈敏度 <反比> 特異性
閾值 <反比> 靈敏度

當我們降低閾值時，我們會得到更多的正值(啥???)，從而增加了靈敏度並降低了特異性。
所以，當我們增加TPR時，FPR也會增加，反之亦然。
```

### 真陽性,真陰性,偽陽性,偽陰性, 率

```
幾何平均評估指標 (Geometric Mean，GM):目的在衡量真陽性率(TPR)與真陰性率(TNR)兩指標間的平衡。
F1:目的在衡量真陽性率(TPR)與陽性預測值(PPV)間的平衡。
陽性預測值(Positive Predictive Value，PPV) & 陰性預測值(Negative Predictive Value，NPV)

真陽性率(True Positive Rate，TPR) 衡量陽性樣本類別中被正確預測為陽性的比例(陽性準確率)，又稱召回率(Recall)；
真陰性率(True Negative Rate，TNR) 衡量陰性樣本類別中被正確預測為陰性的比例(陽性準確率)，又稱明確度(Specificity)

偽陽性率(False Positive Rate，FPR) 衡量陽性樣本類別中被錯誤預測為陽性的比例(陽性錯誤率)
偽陰性率(False Negative Rate，FNR) 衡量陰性樣本類別中被錯誤預測為陰性的比例(陰性錯誤率)

準確率(Accuracy Rate，ACR)
分類器預測正確的筆數佔所有樣本的比例。這是最常被選用的指標，尤其在沒有特別的關注類別，只是想盡量提升模型預測能力時
```

### 準確率(Accuracy)、精確率(Precision)、召回率(Recall)

# 小數據分析(百,千個樣本,[大學統計教的大概就以下為核心) 
* 常態分佈 <--> 中央極限定理
* `標準差Mean`:是一種距離,是描述對應的樣本平均數抽樣分布的離散程度及衡量對應樣本平均數抽樣誤差大小的尺度 
* `離群值outlier`:是指在數據中有一個或幾個數值與其他數值相比差異較大,通常指`超過+-3個標準差`(天選之人與普通民眾)
* 知道`母體`的`標準差` ? invoke`中央極限定理` : (樣本之間獨立 && 抽樣必須是隨機抽樣) ? invoke`T分佈`
* 檢定 標準差,變異數 ===> F分佈
* t檢定
* 選擇對的檢定方法 && 確認樣本隨機性 ==> 值得信賴的信賴區間
* [陳鍾誠slideshare](https://www.slideshare.net/ccckmit/r-63630366)

# 標準差Mean 
* 是描述對應的樣本平均數抽樣分布的離散程度及衡量對應樣本平均數抽樣誤差大小的尺度 
* 是一種距離
* 越小 資料越集中 ,越大 資料越分散
* 常態分佈圖

# 統計的啥鬼

```sh
矩陣分解 ==> 壓縮
informative 有意義的
redundant 
imbalancedData 	不平衡資料
Rescaling a Feature 特徵縮放 == Normalizing
Standardizing a Feature == Z-score Normalization
稀疏矩陣
特徵向量(Eigenvector) 及特徵值(Eigenvalue) 
z-score 
Scaler 縮放
indices指標
impute 估算的
discretization離散化
imputation 歸責
y_hat == ŷ == 估計值
混淆矩陣confusion matrix == 一種可視化工具 == 用於描述分類模型的性能。以模型得出的預測結果與真實世界的正解相互對應，分成四類（預測為真/假、正解為真/假）所組成的矩陣
boundary邊界
# Information Retrieval = IR(啥)
# Human-Computer Interaction = HCI(啥)
相關係數 == 相關程度 == 從大海中打撈起來的一瓶水，是否可以這瓶水，代表整片大海?
```

# 魯棒性 Robust
* 指系統在`擾動`或`不確定`的情況下`仍能保持`它們的特徵行為。
* 統計學：一種在其假定被數據產生在的真實模型所違背的情況下依然能工作良好的統計技術。

# 可解釋性 Explainable
* [tool](https://analyticsindiamag.com/8-explainable-ai-frameworks-driving-a-new-paradigm-for-transparency-in-ai/)

# 顯著性 Significance
* 在進行統計檢定（統計檢驗）時，根據檢驗過程中抽樣的樣本統計後得到的數字，掉到信賴區間之外（即出錯）的機率。

# [Normalization && Regularization && Standardization](https://www.zhihu.com/question/59939602)
* Normalization ~= Standardization : 都是把數據進行前處理，從而使數值都落入到統一的數值範圍，從而在建模過程中，各個特徵量沒差別對待(就是所謂的`線性轉換`???)
* Standardization return是個數字,一種`規約化結果Reduced`,通常就是Standardizing成z-score

```sh
Normalization一般是把數據限定在需要的範圍，比如一般都是【0，1】，從而消除了數據量綱對建模的影響。 
Standardization 一般是指將數據正態化，使平均值1方差為0. 
因此Normalization和Standardization 是針對數據而言的，
消除一些數值差異帶來的特種重要性偏見。
經過歸一化的數據，能加快訓練速度，促進算法的收斂。
```

* Regularization 對結果放大縮小,個人理解是 `調整tradeOff` 模型的 `fitting能力` 

```sh
是在cost function里面加惩罚项，
增加建模的模糊性，从而把捕捉到的趋势从局部细微趋势，调整到整体大概趋势。
虽然一定程度上的放宽了建模要求，
但是能有效防止over-fitting的问题，增加模型准确性。
因此，regularization是针对模型而言。
```


# z-score(一種常態分佈)
* 標準不一的東西無法比較
* 所以得把不同的 `???` 轉換成z-score, 做法上才可以`adapt`

# 統計常看到的 K
* knn,kmean,K-fold cross-validation 的 k 好像就是`幾個`
* k最好是怎樣 => 最佳化問題

# knn(監督式)
* 找過去類似的情況
* 找鄰居

# 集成學習(屬機器學習)
* 是一種「訓練思路」，並不是某種具體的方法或者算法。
* Bagging 的核心思路是 — — 民主。
* Boosting 的核心思路是 — — 挑選精英。

| | 樣本選擇上 | 樣例權重 | 預測函數 | 並行計算 |
| --- | --- | --- | --- | --- |
| Bagging | 訓練集是在原始集中有放回選取的<br>從原始集中選出的各輪訓練集之間是獨立的 | 使用均勻取樣，每個樣例的權重相等 | 所有預測函數的權重相等。 | 各個預測函數可以並行生成 |
| Boosting | 每一輪的訓練集不變，<br>只是訓練集中每個樣例在分類器中的權重發生變化。<br>而權值是根據上一輪的分類結果進行調整。 | 根據錯誤率不斷調整樣例的權值，<br>錯誤率越大則權重越大。 | 每個弱分類器都有相應的權重，<br>對於分類誤差小的分類器會有更大的權重。 | 各個預測函數只能順序生成，<br>因為後一個模型參數需要前一輪模型的結果。 |

# 遷移學習
* 著重圖像
* 拿過去訓練成果,移植到新的場景 (幾乎只能用於圖像)

# 殺必死
* google AutoML 側重`圖像分類`,`文本分類`,`機器翻譯`
* 阿里pai

# AutoML
* MLBox
* Auto-Sklearn
* H2O
* Auto-Keras
* [DataRobot](https://www.perform-global.com/product-datarobot/)

# 數據標註 
* [tool](http://www.awkvector.com/20191107-2/)

# [統計路由](https://hackmd.io/@cube/SkyvXYTqN?type=view)

![](https://github.com/zero85258/MyNOTE/blob/master/img/learn-map.png)

# ML名詞
* 分類(classification)：將未知的新訊息歸納進已知的資訊中。(`人為主觀`。`類`、`門檻`都是是人決定的
* 分群(clustering)：將`特徵`相似的資料歸類於同一組，事先並不知道會依那些特徵進行分組。(`系統客觀` `類`、`門檻`都不是人決定的
* 迴歸(regression)(可以理解就是拿`數值`預測`公式`
* 降維(Dimensionality reduction)基本上降維可分為2個目的，`變數選擇`以及`特徵提取`


# 訓練
* 從程式角度的話就是就是fit() 
* 通常長這樣`aiModel物件.fit(trainData,testData)` 
* 改變自身內部的狀態(訓練完成), 通常return `self`
* 不知道通常耗時的是不是就是fit動作

# Scikit-Learn
```sh
# 轉換器(理解是 轉換器==pipeline的一個step)
你需要讓自制的轉換器與 Scikit-Learn 元件（比如pipeline）無縫銜接工作，
因為 Scikit-Learn 是依賴鴨子型別的（而不是繼承）

# 估算器BaseEstimator、轉換器TransformerMixin
估計器（Estimator）：很多時候可以直接理解成分類器，主要包含兩個函式：fit(),predict()
裝換器（Transformer）：轉換器用於資料預處理和資料轉換，主要是三個方法：fit(),transform(),fit_transform()

# 所需做的是建立一個`轉換器類`並執行3個方法：fit()（返回self, transform(), fit_transform()。
fit() == 簡單來說，就是求得訓練集X的 方差,平均值,標準差,最大最小值 这些固有的属性。 可以理解為一個`訓練過程`
transform() == 對資料做 Standardization,Normalization,降维 等轉換(有ifelse通常不是純線性轉換)
fit_transform() == 是fit和transform的组合，既包括了训练又包含了转换

# 這還不懂
通過新增TransformerMixin作為基類，可以很容易地得到最後一個。
另外，如果你新增BaseEstimator作為基類(且構造器中避免使用args和kargs)，
你就能得到2個額外的方法( get_params() 和 set_params() )，二者可以方便地進行超引數自動微調*
```

# Modeling

```bash
電腦不認得 fit_transform 之前的東西
fit_transform 之後 == 能讓電腦理解 數字裡的意義

電腦知道答案的 == trainData,vaildData
電腦不知答案的 == testData
使用者都知道的 == trainData,testData,vaildData

原始Model == trainData 產出的 
vaildData == trainData 剪出的

# 校正
vaildData 校正 原始模型 == 目標模型 == 拿來predict 

# 驗證模型, 人工驗證
testDAta 丟 目標模型 做 predict == output 
最後一步 拿testData 比較 output == 知道模型好壞,看一下正確答案是否跟預測接近
```

# 最佳化（optimization）vs 泛化（generalization）(模型`好壞` 取捨tradeOff)
* 最佳化 == 很強型別的match ,泛化 == 弱型別的可容忍度

# 參數 & 超參數
* `參數`是訓練模型時`機器學習出的`，如`權重w`與`偏差值b`。 
* `超參數`則是則是由`人為給定`，例如`神經網路的層數`、`損失函數`、`卷積核`的大小、`學習率`等等。

# 鴨子型別風格
* `關注點在於物件的行為，能作什麼；而不是關注物件所屬的型別`

```sh
在程式設計中，鴨子型別（英語：duck typing）是動態型別的一種風格。
在這種風格中，一個物件有效的語義，不是由繼承自特定的類或實現特定的介面，
而是由"當前方法"方法 (電腦科學)")和屬性的集合"決定。這個概念的名字來源於由James Whitcomb Riley提出的鴨子測試，
“鴨子測試”可以這樣表述：“當看到一隻鳥走起來像鴨子、游泳起來像鴨子、叫起來也像鴨子，那麼這隻鳥就可以被稱為鴨子。
```

# 鴨子風格框架
* 感覺就是`沒那麼強型別`的框架
* mvc,etl,這些都是這種 

# 啞變數（Dummy Variable） 的概念
```
在構建迴歸模型時，如果自變數X為連續性變數，迴歸係數β可以解釋為：在其他自變數不變的條件下，X每改變一個單位，所引起的因變數Y的平均變化量；
如果自變數X為二分類變數，例如是否飲酒（1=是，0=否），
則迴歸係數β可以解釋為：其他自變數不變的條件下，X=1（飲酒者）與X=0（不飲酒者）相比，所引起的因變數Y的平均變化量。 

但是，當自變數X為多分類變數時，例如職業、學歷、血型、疾病嚴重程度等等，此時僅用一個`迴歸係數`來解釋多分類變數之間的變化關係，及其對因變數的影響，就顯得太不理想。 此時，我們通常會將原始的多分類變數轉化為啞變數，每個啞變數只代表某兩個級別或若干個級別間的差異，

通過構建迴歸模型，每一個啞變數都能得出一個估計的迴歸係數，從而使得迴歸的結果更易於解釋，更具有實際意義。 
```

# Binning 分箱
* 增加了`魯棒性`,`降低過擬合`的風險

```
離散特徵的增加和減少都很容易，易於模型的快速迭代；
稀疏向量內積乘法運算速度快，計算結果方便存儲，容易擴展；
離散化後的特徵對異常數據有很強的魯棒性：比如一個特徵是年齡>30是1，否則0。
如果特徵沒有離散化，一個異常數據“年齡300歲”會給模型造成很大的干擾；
邏輯回歸屬於廣義線性模型，表達能力受限；單變量離散化為N個後，每個變量有單獨的權重，相當於為模型引入了非線性，能夠提升模型表達能力，加大擬合；
離散化後可以進行特徵交叉，由M+N個變量變為M*N個變量，進一步引入非線性，提升表達能力；

特徵離散化後，模型會更穩定，
比如如果對用戶年齡離散化，20-30作為一個區間，不會因為一個用戶年齡長了一歲就變成一個完全不同的人。
當然處於區間相鄰處的樣本會剛好相反，所以怎麼劃分區間是門學問；
特徵離散化以後，起到了簡化了邏輯回歸模型的作用，降低了模型過擬合的風險。
可以將缺失作為獨立的一類帶入模型。
將所有變量變換到相似的尺度上。
```

# 驗證模型
```sh
aiModel.predict(testData) == output
通常比較test_label,預測值
看一下正確答案是否跟預測一樣：
```

# transfer VS transform
* transfer == 從一個地方移到另一個地方；
* transform == 改變某物/某人的形狀或性質

# 懲罰(統計)
* 目的是`降低模型複雜度`,做法是`限制參數空間的大小以`

# 用戶畫像 User Profile
* 要把用戶的基本屬性（年齡、性別、地域）、購買能力、行為特徵、興趣愛好、心理特徵、社交網絡大致地標籤化。
* 關於「標籤化」，一般採用多級標籤、多級分類，
* 比如第一級標籤是基本信息（姓名、性別），
* 比如第二級是消費習慣、用戶行為；
* 第一級分類有人口屬性，人口屬性又有基本信息、地理位置等二級分類，地理位置又分工作地址和家庭地址的三級分類。

# [DL]()
* tensorData的 classification, clustering, regression 多層網路處理
```sh
# 1. Basics
PyTorch Basics
Linear Regression
Logistic Regression
Feedforward Neural Network
# 2. Intermediate
Convolutional Neural Network
Deep Residual Network
Recurrent Neural Network
Bidirectional Recurrent Neural Network
Language Model (RNN-LM)
# 3. Advanced
Generative Adversarial Networks
Variational Auto-Encoder
Neural Style Transfer
Image Captioning (CNN-RNN)
```

# Perceptron感知器(一種[神經網路](https://github.com/zero85258/MyNOTE/blob/master/%E6%AD%B8%E7%B4%8D&%E7%B5%B1%E8%A8%88%20-%20%E7%A8%8B%E5%BC%8F%E6%A6%82%E5%BF%B5.md#neural-network-architectures))
* 2層cell的一種神經網路(1\*輸入層和1\*輸出層,非線性classification用)

# 層類型(神經網路)
* 包括 == 卷積、去卷積、擴張、全連接FC、池化、去池化、各種`規範化Normalization層`、激活函數、張量reshape、逐元素運算、RNN和LSTM功能

# 機器學習 && 統計 (`準確性`vs`可讀性` 的取捨)
* 機器學習著眼於預測結果
* 統計學在研究數據中不同內容的關係
```sh
統計學可以研究數據並建立出模型，並可以利用模型進行預測，而且這個模型我們大致看得懂是怎麼運作的。
而機器學習則是犧牲掉模型的可讀性而換取預測的準確度。
```

# 神經網絡結構搜索NAS,Efficient NAS(DFS版本的NAS)
* 感覺AutoML就是基於這個
* 不知所謂 `電腦explore全新演算法` 是否就是這個

# SSL 一對庫
* 鑰匙,證書,憑證,合格單位

# keystore密鑰庫/truststore信任庫
```sh
在SSL握手期間，server從 keyStore 中查找privateKey，並將其對應的publicKey和 證書 提供給client
在SSL握手期間，client從 trustStore 中查找關聯的 證書

密鑰庫 保留用於標識我們身份的證書，
信任庫 保留用於標識其他身份的證書。

keystore可以看成一個放key的庫
key就是公鑰，私鑰，數字簽名等組成的一個信息。
truststore是放信任的證書的一個store
```

# to 所有 子網域 的 cdn 上ssl
* CA商(ex:Comodo) 買子網域ssl
* DNS_Hosting商 (ex:cloudflare)買dns的 Business 或是 Enterprise 方案
* 上傳ssl到 各 CDN_Edge
```
自動發的 Wildcard SSL 憑證, 因為他只支援第一階萬用域名, 
你必須自己去向`憑證商CA`申請子網域的憑證, 
然後付錢給 Cloudflare (買 Business 或是 Enterprise 方案), 
上傳你自己買的憑證, 他就會幫你發布到 CDN 的 Edge 去
```

# [acme.sh](https://github.com/acmesh-official/acme.sh)
* 是一個 ACME(自動化證書管理環境) 腳本，可以從 letsencrypt 生成免費的證書。


# [PostgresDB (pgdb,pgsql)](https://www.enterprisedb.com/postgres-tutorials/postgresql-query-introduction-explanation-and-50-examples)
* [EnterpriseDB by Ansible](https://github.com/EnterpriseDB/edb-ansible)
* Perform(執行) Function
* [Pivot Query](https://ravenonhill.blogspot.com/2017/07/postgresql-pivot-table.html)
* UDF == user define function(DB)
* Foreign Data Wrapper(pgsql) 可以讓pgsql跟其他db溝通
* function `RETURN QUERY`(讓sql`可輸入參數`)

```sql
CREATE FUNCTION get(int) RETURNS SETOF integer AS
$BODY$
BEGIN
    RETURN QUERY SELECT age
                   FROM dummy_table
                  WHERE age >= $1  ;
    RETURN;
 END
$BODY$
LANGUAGE plpgsql;

select * from get(9);
```

# UDF(user define function(DB))
* 其實就是資料庫call外部function
* 可以用其他語言寫

# PL
* PL/Python
* PL/Container

# Nosql Join == lookup

# Ansible
* [itil驅動ansible](https://www.mdeditor.tw/pl/pLtF/zh-tw)
* collection == 感覺像是ansible專案的`目錄,文件規範`,`galaxy.yml`
* conf檔 == 把指令上的參數全部丟到檔案裡 ,conf檔吃得順序 == `./ansible.cfg` ?? `~/.ansible.cfg` ?? `/etc/ansible/ansible.cfg`
* inventories資產 == 其實就是`主機`,`群組`清單,可以用`./inventories`(ini格式),也可以用`hosts.yml` 
* [facts](https://tomme.me/facts-in-ansible/) == 可以把他想像成auto_discover, 它能夠幫你蒐集一些機器的基本訊息, 如硬盤,IP, 主機名稱 等等的, 並且註冊到playbook變數(register), 讓之後可以繼續使用
* role => reuse code 

```sh
ansible-inventory -i inventory --list
ansible canada --list-hosts
lab deploy-inventory start
ansible all --list-hosts
ansible ungrouped --list-hosts
```

# 程式 + 語言vm 包成exe
* 普通的Java程式做成真正的exe,也就是單一個exe就可以在沒有安裝JVM的機器上執行。這樣的工具常見的有JET和gcj.前者是收費的
* py的方案? `pyinstaller --clean -F ./進入點`
* bashTo執行檔,用`shc`

# 戰略分析
* Competitor Analysis 競爭對手分析 Why、What、How
* Gap Analysis 差異分析

# File Descriptor檔案描述符 (Linux)
* 功能上來說 是一層介面，可以讓我們去操作 file 和其他 input/output interface (例如 pipe & socket)
* 檔案描述符在形式上是一個非負整數(簡單的說 檔案描述符 就是 一種`數字`
* 個人理解其實就是 stdin, stdout ,stderr 對應的`數字` 0, 1, 2

# Redis Zrange 
返回有序集中，指定区间内的成员。

# 波形 的 動作
* `鉗位`:就是將信號強行鉗制到某一電位上，抬高或降低信號的基準電位，但不改變原信號的波形

# AMP
* 全名為Accelerated Mobile Pages
* 是一個由google開發設計的架構，創造一個符合手機瀏覽的網頁，可讓網站讀取速度更快，使用者開啟網頁的速度更快

# 大陸用語
```
數組 == 陣列
面向對象 == 物件導向
數據模型
屬性
成員變量
構造函數 == 建構子
析構 == 解構


光驅 == 光碟機
內存 == 記憶體ram
調制解調器 == 數據機

回車 == enter鍵
上檔 == shift鍵
換檔 == alt鍵

宏指令 == 巨集指令
批文件 == 批次檔
擴展名 == 副檔名
軟件狗 == 硬體鎖
外圍設備 == 週邊設備
子網掩碼 == 子網路遮罩
資源管理器 == 檔案總管
```

# Rolling Update

# Mirantis(公司)

# ionCube(資安)
加密 程式,鎖死網域 鎖系統 鎖期限,鎖設備

# 弱掃(資安)
* Nessus

# 肉雞(資安)
* 就是殭屍電腦

# 單次密碼(OTP)
* 通常是 手機簡訊. 接收一組一次性簡訊密碼
* U盾感覺也是

# [中間者劫持(資安)]()
* [用Kali的教學](https://kknews.cc/zh-tw/code/agllp2x.html)

# ROP(Return-Oriented Programming, 返回導向編程)(資安)
```
顧名思義，ROP就是使用返回指令ret連接代碼的一種技術
（同理還可以使用jmp系列指令和call指令，有時候也會對應地成為JOP/COP）。
一個程序中必然會存在函數，而有函數就會有ret指令。
我們知道，ret指令的本質是pop eip，即把當前棧頂的內容作為內存地址進行跳轉。

而ROP就是利用棧溢出在棧上佈置一系列內存地址，每個內存地址對應一個gadget，
即以ret/jmp/call等指令結尾的一小段彙編指令，通過一個接一個的跳轉執行某個功能。
由於這些彙編指令本來就存在於指令區，肯定可以執行，
而我們在棧上寫入的只是內存地址，屬於數據，所以這種方式可以有效繞過NX保護。
```

# 邊緣運算
* StarlingX Stack

# 服務可靠性
* 傳統電信網絡 == 6個9的等級（99.9999％），就是`每年約30秒`停機時間
* IT應用的企業級軟件平台 == 3個9的等級（99.9％），就是`每年約有9小時`停機時間

# CMS
* 架設網站,論壇導向 Wordpress,discuz!

# ERP
* 會計為導向的資訊系統  
```
國內前三大的ERP系統 鼎新、正航、鉅茂。
1.鼎新(為主)
2.SAP(大企業再用,小的養不起)
3.Oracle
```

# MES (extends CIM)
* 製造執行系統
![MES架構圖](http://140.124.76.70/wordpress/?page_id=36)
```
是用來幫助企業從接獲訂單、進行生產、流程控制一直到產品完成，
主動收集及監控製造過程中所產生的生產資料，以確保產品生產品質的應用軟體。
ASP.NET,JAVA
SQL Server及Oracle DB、VB6、Net及Java程式撰寫經驗
```

# CRM 
* 戶關係管理系統
![crm-dmp-cdp-diff](https://github.com/zero85258/MyNOTE/blob/master/img/crm-dmp-cdp-diff.jpg)

# npx
* npm 永久安裝，npx 安裝後即移除

```sh
# 直接執行 Github 檔案
npx https://gist.github.com/itsems/ed6cebf796a470059c7eb25fdfcaa085
```

# 監控工具
```
最好學Cacti、Nagios和Zibbix，
企業用得最多應該是Nagios和Zibbix。反正都學會這些吧，
但Nagios會有點難，因為會涉及到用腳本寫自動監控，那個地方很難。
```

# 主機監控工具
* smokeping
* cacti
* nagios
* zabbix
* ntop

# 容器可視化
```
kiali + istio,cilium + hubble,alcide
```

# fluentd vs prometheus (待釐清)
* 前者挨打收log
* 後者主動poll收log

# Journal
* 次世代Log管理系統
* 預設的情況下Systemd Journal會將Log記錄於記憶體之中，這將使得在系統重新開機之後其所記錄的Log完全消失

# HA架構種類
* active-active(輪詢) 
* active-passive(master掛點slave替補) 

# HA組件
* Failover (主從切換)
* proxy route [DAL(DataAccessLayer)訪問中間件](https://zhuanlan.zhihu.com/p/91742429) (代理路由工具) `代理`之餘`物理数据库` 和Nginx之餘cgi类似
* management (GUI?)

# 怎麼證明HA
* 數據庫的處理本身優化也是非常重要的。主從、熱備、分表分庫等都是系統發展遲早會遇到的技術問題問題。
* 高可用性驗證 == 可以不斷切換master(當然還是得等待一致性問題),可以試砍???
* 高可用復原 == Segment Node => 執行修復指令, Master Node => 重新加入Standby Master

# HA(高可用性架構)
* linux ha架構???
* Linux 的負載平衡套件(HAProxy) ha架構
* Layer 4 Switch調配 ha架構
* orchestration ha架構
* storage ha架構
* switch ha架構
* 防火牆ha架構
* DB ha架構(會有一致性問題,需要進階架構)

# FailOver故障轉移機制
* HA 架構 master 死掉 slave 頂替

# [MYSQL HA](https://zhuanlan.zhihu.com/p/33504555)(資料中間件)
* MySQLReplication: 保證資料 可用性A 和 分割槽容忍性P；
* PXC(Percona XtraDB Cluster) 保證資料 強一致性C 和 可用性A。
* Vitess(潮)
* [Mycat](https://www.cnblogs.com/joylee/p/7513038.html) 代理路由工具
* Replication, CQRS
### `複製`，就是讓slave知道master在哪,然後start下去
```sh
# master
mysql> CREATE USER 'test'@'%' IDENTIFIED BY '123456';
mysql> GRANT REPLICATION SLAVE ON *.* TO 'test'@'%';
# slave
mysql> CHANGE MASTER TO
           MASTER_HOST='10.108.111.14',
           MASTER_USER='test',
           MASTER_PASSWORD='123456',
           MASTER_LOG_FILE='mysql-bin.000003',
           MASTER_LOG_POS=120;
mysql> start slave #不確定要不要
```
### `恢復`，就是讓mysql將保存在binlog日誌中指定段落區間的sql語句逐個重新執行一次而已
```sh
# binlog恢复（指定pos点恢复/部分恢复）
mysqlbinlog --start-position=1847 --stop-position=2585 mysql-bin.000008  > test.sql	#取得區間sql
mysql> source /var/lib/mysql/3306/test.sql	# 執行區間
```

# Redis HA(資料中間件)
* [CacheCloud](https://github.com/sohutv/cachecloud) 管理redis集群 == 管理系统工具
* Codis(資料中間件) redis集群 == 路由工具
* Sentinel == FailOver工具

# Canal(資料中間件)
* 數據庫`增量日誌解析`,提供增量數據訂閱和消費,基於 MySQL,譯意為水道/管道/溝渠

# 增量 <---> 全量

# 增量計算
* 一種功能 。當一部分的數據產生了變化，僅對`產生變化的部分`進行計算和更新，以節省計算時間。

# 增量資料,增量更新,增量日誌解析,增量數據訂閱和消費
*  Mysql 的增量資料不停得丟擲到 Kafka ，而後再讓 storm 不停得從 Kafka 對應的 Topic 讀取資料並寫入到 Hdfs 中。
*  Maxwell's daemon蒐集binlog
```sh
# 將資料拋到 kafka 的命令列指令碼吧。
bin/maxwell --user='maxwell' --password='XXXXXX' --host='127.0.0.1' \
   --producer=kafka --kafka.bootstrap.servers=localhost:9092 --kafka_topic=maxwell --port=3306
```

# [SMP & MPP](https://blog.csdn.net/microatlas/article/details/51564756)
![](https://github.com/zero85258/MyNOTE/blob/master/img/BigDataHybrid.png)
* SMP(oracleDB)
* [MPP大規模並行處理](https://www.itread01.com/content/1544325194.html) 叢集規模100以內、併發小（50以下）MPP架構目前被並行資料庫廣泛採用，一般通過scan、sort和merge等操作符實時返回查詢結果
* NUMA
* Hadoop

# 分散鍵(MPP幾乎都有)
* 防止資料在各Segment資料傾斜

```sql
DISTRIBUTED BY column
DISTRIBUTED RANDOMLY
```

# [Greenplum DB(MPP資料庫)](https://github.com/greenplum-db/gpdb)
* [ansible](https://gpdb.docs.pivotal.io/6-0/install_guide/ansible-example.html)

```sh
Greenplum DB 號稱是世界上第一個開源的大規模並行數據倉庫，最初是基於 PostgreSQL，現在已經添加了大量資料庫方面的創新。
Greenplum 提供 PD 級別數據量的強大和快速分析能力，特別是面向大數據方面的分析能力，支持大數據的超高性能分析查詢。
在本次分享中，曾文旌從GPDB架構入手，輔助以SQL和優化器的案例以及對GPDB的硬體和性能的分析，對GPDB實現進行了詳細解析。
分享最後，他還對比了GPDB的優勢和局限性，並對GPDB的未來發展進行了展望。

# External table
gpfdist == greenplum external table 可以去讀本機的檔案

# ELT
* 可以保持所有的資料始終在資料庫當中(感覺就是資料不用落地,寫到檔案)
* 感覺課金,MPP資料庫 比較有這種功能 ex:gpcopy

# 多態存儲
Greenplum提供稱為“多態存儲”的靈活存儲方式。
多態存儲可以根據數據熱度或者訪問模式的不同而使用不同的存儲方式。
一張表的不同數據可以使用不同的物理存儲方式。支持的存儲方式包含：

# 行存儲：
行存儲是傳統數據庫常用的存儲方式，特點是訪問比較快，多列更新比較容易。

# 列存儲：
列存儲按列保存，不同列的數據存儲在不同的地方（通常是不同文件中）。適合一次只訪問寬表中某幾個字段的情況。列存儲的另外一個優勢是壓縮比高。

#外部表：
數據保存在其他系統中例如HDFS，數據庫只保留元數據信息。
```

```sh
# Segment Node 高可用復原
gpstate -e # 檢查資料庫狀況
gprecoverseg # 執行修復作業,並輸入 y 執行
gpstate -e # 檢查同步狀態，直到確認同步完成，並出現角色提示需要切換選項
gprecoverseg -r # 進行角色切換操作，注意此操作會造成線上作業重試或者失敗，請在離峰時間執行。
gpstate -e # 檢查同步狀態，出現 all segment running normally == 同步完成。


# Master Node 高可用性驗證
gpactivatestandby -f # 執行MASTER切換作業 ，並輸入 Y 執行。

# Master Node 高可用復原
gpinitstandby -s greenplum-master.dc.prod # 重新加入Standby Master，並輸入 Y 確認。
gpstate -f # 檢查MASTER同步狀態，確認DB已恢復正常狀態。
```

# 異地備援(tradeOff 成本 <==> 恢復時間,損失資料範圍)
* 熱備援,暖備援,冷備援

# 微軟SQL Server && Oracle SQL
* Oracle : SQLcl取代sqlplus
* [MSSQL Server docker](https://docs.microsoft.com/zh-tw/dotnet/architecture/microservices/multi-container-microservice-net-applications/database-server-container)

# DBA tool
```
Psql 
Gpcopy 
Pgdump 
```

# DW(感覺其實也算一種 資料庫中間件)
* Infobright == MySQL base DW
* RedShift == PgSQL base DW
* HAWQ == HDFS base DW, 是存儲與計算分離的，它的存儲放在HDFS上;GreenPlum是存儲(PGSQL)和計算合體的，標準的RDBMS系統；
* Exasol == in memory EDW
* Snowflake == 創新在於，它將存儲和計算完全分離，這從根本上解決了傳統DW架構的諸多詬病的問題，這也可以視為SaaS模式對傳統軟件數據庫的彎道超車。
* Apache Pinot™ (Incubating): Realtime distributed OLAP data storage
* Cognos == [IBM Analytics](https://www.ibm.com/tw-zh/products/cognos-analytics)
* BigQuery == Google ([isAnOlapCubeKiller????](https://medium.com/@chitre.ajay/is-bigquery-an-olap-cube-killer-6daddc1d0bf7)

# 數據中台

# IBM
* Katerra(Data Lake???)
* Netezza(DataWarehouse)

# API Style
* OpenAPI 2.0, 3.0, Swagger, RAML, API Blueprint 
* 設計API分頁
* [REST, GraphQL, gRPC 如何选型](https://zhuanlan.zhihu.com/p/44140864)

### RESTful概念
* [以冪等性區分post&get](https://juejin.im/entry/57fec6850e3dd90057e1e47e)
* 動詞httpMethod,名詞url商務邏輯

```bash
# RESTful API 充分地使用了 HTTP protocol (GET/POST/PUT/DELETE)，達到:
# 以直觀簡潔的資源 URI
# 並且善用 HTTP Verb
# 達到對resource的操作

# 冪等性操作
獲取使用者資料 /GET /users

# 非冪等性操作
新增INSERT使用者資料 /POST /user
更新UPDATE使用者資料 /PUT /user/1
獲取SELECT使用者資料 /PATCH /user/1
刪除DELETE使用者資料 /DELETE /user/1
```

### [GraphQL概念](https://medium.com/@evenchange4/2018-graphql-%E6%BC%B8%E9%80%B2%E5%BC%8F%E5%B0%8E%E5%85%A5%E7%9A%84%E6%9E%B6%E6%A7%8B-aeb2603f2223)
* type(這感覺就直接綁定ORM,所以非`海量型curd`應該不太會有問題)
* query 查
* mutation 增刪改

### RPC概念

### SOAP API
* 基於XML

# Cookie
通常 Cookie 有兩種類型：Persistent Cookie 與 Session Cookie
* Persistent Cookie:這種類型的 Cookie 可以設定存在 Browser 一段時間（明確指定 Cookie 的 Expires 時間），如果你設定的時間夠長（例如：一天），即便 Browser 全部關閉或重開機後再開啟也還會存在。
* Session Cookie:這種 Cookie 是當不特別指定 Expires (過期時間) 時，該 Cookie 只會存在目前這個 Browser 的續存期間(Session)，只要 Browser 全部關閉後 Cookie 會自動被清除。


# 加密
```
MD5訊息摘要演算法 128Bit(一種演算法){
	建議改用SHA1
}

SHA1安全雜湊演算法160Bit(一種演算法){
	2017年2月23日 被成功碰撞攻擊
}
RSA加密演算法(一種演算法)
SSL 加密協定(一種通訊協定)
```

base64 是可逆的編碼


# Orientation 方向

# IANAL 我不是律師但我聞到法律味

![](https://github.com/zero85258/MyNOTE/blob/master/img/OSS授權.jpg)

### [償責雅美](http://inspiregate.com/internet/trends/74-comparison-of-five-kinds-of-standard-open-source-license-bsd-apache-gpl-lgpl-mit.html)
* `GPL`: 出發點是代碼的開源/免費使用和引用/修改/衍生代碼的開源/免費使用，但`修改後`和`衍生`的code`不允許做為閉源`的商業軟件發佈和銷售。
* `BSD`: 代碼鼓勵代碼共享，但需要尊重代碼作者的著作權。BSD由於允許使用者修改和重新發佈代碼，也允許使用或在BSD代碼上開發商業軟件發佈和銷售，因此是對 商業集成很友好的協議。而很多的公司企業在選用開源產品的時候都首選BSD協議，因為可以完全控制這些第三方的代碼，在必要的時候可以修改或者二次開發。
* 旋轉門條款
* 競業條款(NCC or CNC)
* `NDA` ( Non-Disclosure Agreement ) 保密協定合約,保密協議

# SQL指令種類
* 資料定義語言 ( DDL ) : `create建立`,`alter更變`,`drop刪除`
* 資料操作語言 ( DML ) :`select`,`insert`,`update`,`delete`
* 資料控制語言 ( DCL ) : commit,rollback,`grant給予權限`,`revoke移除權限`

# Test

### 測試層級分為四層：
* 單元測試 Unit Testing：最基礎的測試單位，主要測試目標是單元，例如：Java裡的一個Class
* 整合測試 Integration Testing：也稱作組裝測試，叫做組裝，顧名思義，就是把單元組合起來後的測試，也就是針對系統介面和整合後的功能做測試
* 系統測試 System Testing：這是整合測試的再更上一階，針對功能、介面、可靠性、易用性和效能做測試
* 回歸測試 Operational Acceptance Testing：主要是上線後維護階段的測試，確保沒有因為功能

### 常用的測試方法：
* 黑箱測試 Black-box Testing：測試功能本身，而不是針對程式碼，測試案例要按照需求提供Input，來對比Output是否合乎預期，此方法適合用於整合測試、系統測試
* 白箱測試 White-box Testing：測試程式結構本身，針對程式碼、流程，不單單只看需求而已，適用於單元測試、整合測試

### 常安排的測試活動：
* Smoke Testing 煙霧測試：主要是針對每日更新的程式，消除表面的錯誤，減少後期的負擔，也就是類似確保其可以被建置，只要能Build成功，其他功能面測試就是其他測試的事情
* Alpha Testing：通常是系統有一定完成度後的第一階段測試，主要是內部進行的，下一階段為Beta測試
* Beta Testing：當Alpha測試完成之後會進行的，此階段會開放給外部使用者一同測試
* Automated Testing 自動化測試：當偵測到程式碼有異動調整時，自動將相關的測試內容開始測試
* Stress Testing 壓力測試：主要針對單一時間點可接收最大使用者使用的量做測試
* Performance Testing 效能測試：主要針對系統功能的回應速度做測試，一般常見網頁若回應時間超過3秒就算太久了
* Security Testing 安全性測試：針對一些資安部分以及駭客常用攻擊手法做測試
* A/B Testing：是提供兩套版本隨機給使用者使用，並觀測其回饋，已得到更進一步的使用者體驗改善空間

# diff Win && linux
||win|linux|註釋|
|---|---|---|---|
|最高權限賬戶|administrator|root||
|最高權限賬戶目錄|`C:\Windows`|`/root`||
|一般賬戶所在目錄|`C:\Users`|`/home`|軟件的 用戶級 配置文件就在該一般賬戶所對應的目錄下|
|系統中軟件所對應的`系統級`配置文件所對應的目錄|`C:\ProgramData`|`/etc`||
||`C:\Program Files`|`/usr`|系統下安裝軟件時的默認路徑|


# usr,bin,sbin,local,lib區別
* 注意 usr == Unix System Resource，而不是User，然後通常：
```
/usr/bin下面的都是系統預裝的可執行程序，會隨著系統升級而改變。
/usr/local/bin目錄是給用戶放置自己的可執行程序的地方，推薦放在這裡，不會被系統升級而覆蓋同名文件。
```
* /bin是系統的一些指令。 bin為binary的簡寫主要放置一些系統的必備執行檔例如:
`cat、cp、chmod df、dmesg、gzip、kill、ls、mkdir、more、mount、rm、su、tar等。`
* /sbin一般是指超級用戶指令。主要放置一些系統管理的必備程式例如:
`cfdisk、dhcpcd、dump、e2fsck、fdisk、halt、ifconfig、ifup、ifdown、init、insmod、lilo、lsmod、mke2fs、modprobe、quotacheck、reboot、rmmod、 runlevel、shutdown等。`
* /usr/bin　是你在後期安裝的一些軟件的運行腳本。主要放置一些應用軟體工具的必備執行檔例如
`c++、g++、gcc、chdrv、diff、dig、du、eject、elm、free、gnome*、 gzip、htpasswd、kfm、ktop、last、less、locale、m4 、make、man、mcopy、ncftp、 newaliases、nslookup passwd、quota、smb*、wget等。`


# [IEEE 754](https://kusakawazeusu.medium.com/javascript-%E8%A3%A1%E7%9A%84%E6%A6%82%E6%95%B8%E9%81%8B%E7%AE%97-ieee-754-%E7%9A%84%E6%A8%99%E6%BA%96%E5%85%B6%E5%AF%A6%E6%B2%92%E6%9C%89%E8%A2%AB%E5%AF%A6%E4%BD%9C-a007432804f3) && JS的爛型別 && Java strictfp
*  

# 生命週期LifeCycle(為了瞭解事情的運行流程,與每階段進行的動作)
* [框架]()
* [docker](https://joshhu.gitbooks.io/dockercommands/content/Containers/concepts.html)
* DNS,CDN生命週期
* 本地網路連線生命週期
* mysql sql 解析

# 專業排程工具
* [Control-M](https://www.gss.com.tw/control-m)
* [etl,排程 工具大車拼](https://www.itread01.com/content/1548373172.html)

# 3A測試
```
Arrange: 初始化的過程
Act: 執行測試的目標，並取得實際結果
Assert: 驗證結果
```

# NP-Complete
```
然後用《神諭》Oracle 的觀念去說明 
nondeterministic 非決定性圖靈機的路徑長度，
接著用《布林代數式》去將《非決定性圖靈機》編成 SAT 邏輯式，
那麼來上我課且用心聽的學生，大部分都可以理解何謂 NP-Complete 。
```

# ELF 可執行與可鏈結格式
* cat 執行檔裡面的那種亂碼???

# Browser Storage
* Local Storage 存儲一些需要刷新保存並且需要在頁面關閉後仍然留下的信息。可以用於保存購物車中的內容；在之前項目中，用於保存上一次的用戶瀏覽標籤，並跳轉到相應的路徑下。
* Session Storage 存儲一些當前頁面刷新需要存儲，且不需要在tab關閉時候留下的信息。可以用來檢測用戶是否是刷新進入的頁面，如音樂播放器恢復播放進度條的功能。非常適合SPA，可以方便在各業務模塊進行傳值。
* IndexedDB 像 nosql 直接使用 js 方法操作數據。
* WebSQL 像關係型數據庫，使用 sql 語句進行操作

# [死循環](https://kknews.cc/zh-tw/code/6396np3.html)
* 可用gdb來查
```sh
最典型的預期之內的無限循環是socketserver，進程不死，服務不止。
而死循環看起來很忙（CPU100%），但是沒有任何實質的作用。

# 死循環有不同的粒度，
最粗的粒度 == 是兩個進程之間的相互調用，比如RPC；
其次是 == 函數級別，較為常見的是沒有邊界條件的遞歸調用，或者在多個函數之間的相互調用；
最小的粒度 == 在一個函數內部，某一個代碼塊（code block）的死循環，最為常見的就是for，while語句。
```

# 災難,天降甘霖
* BIA:營運衝擊分析（Business Impact Assessment
* RTO:包括系統回復時間（Recovery Time Objective
* BCP:企業持續營運計畫（Business Continuity Planning


# 如何尻出
* 设计一个[推荐系统架构](http://rongzijing.win/index.php/archives/140/)(感覺是AI,統計分析導向的架構設計)
* 设计一个论坛
* [设计一个串流影音](https://straas.io/blog/archives/2726/)
* 设计一个[分布式唯一ID生成服务](https://juejin.im/post/5b3a23746fb9a024e15cad79)

```md
推薦系統架構在不同的業務情形下的設計也會有所區別，但必備的一些組件還是通用的。
總結了自己大半年來在資訊類個性推薦算法崗位的實習經驗，按照自己的理解給出了一個資訊類推薦系統架構圖。

首先是數據上報模塊，這個底層模塊用來上報業務數據、日誌數據等，比如用戶的點擊曝光行為記錄、分類記錄、地區時間記錄等，是算法的數據來源。


# pipeline特徵工程模塊，可以說是整個推薦架構的核心基礎服務。
* pipeline最開始是樣本設計模塊，包括正負樣本設計、日誌拼接、數據過濾等。

* 正負樣本設計需要結合具體的業務場景。
舉例來說，對於新聞類app，正負樣本的設計可以設計為用戶對點擊了看到的新聞A，那麼A為正樣本；但若A已曝光，也就是用戶看到了A但是未點擊，那麼A則為負樣本。
而對於短視頻類app，因為一些短視頻只有點進去了才知道喜歡不喜歡，有些視頻用戶點進去不到2秒就關了，有的則會認真看完，那麼此時正負樣本就不能簡單的認為是點擊行為是正樣本了，正負樣本的設計必須和用戶點擊視頻後的停留時間相關。
除了正負樣本設計外，數據過濾也很重要，惡意點擊、網絡爬蟲等造成的“臟”數據不僅會加大數據量浪費計算資源，而且對算法模型來講也是噪音數據，反而會影響模型效果。
接著pipeline對上一層的數據進行如特徵組合，生成用戶畫像(user pofile)、內容畫像(item profile)以及各種交叉類特徵。
還可以對特徵進行歸一化、離散化，從而滿足不同模型對數據類型的要求。


# 召回層和排序層，這兩個模塊將給用戶提供個性化推薦的結果。

* 召回層，召回層主要用來生成個性化的候選內容，即根據不同用戶生成不同的內容序列。
比如對於新聞類推薦來說，召回層根據用戶畫像和內容畫像，使用某種算法(協同過濾、熱榜推薦、user2vec、item2vec等)從候選池中選出一定數量的新聞內容。
喜歡軍事、體育的用戶A，喜歡動漫、音樂的用戶B，顯然用戶A的召回內容中軍事和體育占得比重會比動漫和音樂的比重大，而用戶B的召回內容中動漫和音樂的相關內容就會比較多。

* 排序層就是對召回內容再進行一次精排序。
排序層主要是訓練好一個排序模型，該模型能對候選集中的內容進行點擊率(ctr)預測，根據預測結果進行排序，ctr預測值越高意味著模型預測該用戶喜歡該內容的機率越高，那麼該內容就應該優先推薦。
召回層除了召回候選內容，有時也會使用某種算法進行一次粗排序為排序層服務，但排序層產生的結果會更加精確。


應用層最終給用戶產生和展示個性化推薦的結果，屬於線上(online)模塊。
當線上用戶請求發來後，首先要通過召回層從而根據該用戶的特點生成候選內容集，之後使用排序層的排序模型對候選內容集進行精排序，最後將精排後的結果展示給用戶完成整個個性化推薦過程。

```

# 連結
* `硬連結`數減為0時，kernal才會把檔案內容從磁碟上刪除(像檔案被複制了一份一樣)
* `軟連結`(捷徑)
